üîù Retour au [Sommaire](/SOMMAIRE.md)

# 8. Programmation Concurrente

## Introduction

Bienvenue dans le chapitre sur la **programmation concurrente** ! C'est un sujet qui peut sembler intimidant au premier abord, mais qui est essentiel pour cr√©er des programmes modernes, rapides et efficaces.

### Qu'est-ce que la programmation concurrente ?

La **programmation concurrente** permet √† un programme d'ex√©cuter plusieurs t√¢ches "en m√™me temps" (ou presque). C'est un peu comme jongler avec plusieurs balles : vous ne tenez jamais toutes les balles en m√™me temps, mais vous cr√©ez l'illusion de le faire en les manipulant tr√®s rapidement.

**En termes simples** : Au lieu de faire les choses une par une (s√©quentiellement), la programmation concurrente vous permet de faire plusieurs choses √† la fois (en parall√®le).

---

## Pourquoi la programmation concurrente ?

### Le monde est concurrent

Dans la vie r√©elle, les choses se passent en parall√®le :
- Dans un restaurant, plusieurs serveurs s'occupent de diff√©rents clients en m√™me temps
- Sur une route, des centaines de voitures circulent simultan√©ment
- Dans une entreprise, les employ√©s travaillent tous en parall√®le

Vos programmes doivent souvent refl√©ter cette r√©alit√© !

### Exemples concrets d'utilisation

**1. Serveur web**
```
Utilisateur A fait une requ√™te ‚Üí En traitement
Utilisateur B fait une requ√™te ‚Üí En traitement (en m√™me temps!)
Utilisateur C fait une requ√™te ‚Üí En traitement (en m√™me temps!)
```

Sans concurrence, l'utilisateur B devrait attendre que A soit servi, puis C devrait attendre B, etc. Avec concurrence, tous sont trait√©s simultan√©ment.

**2. T√©l√©chargement de fichiers**
```
Fichier 1: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 50%
Fichier 2: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë 70%
Fichier 3: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 30%
```

Au lieu de t√©l√©charger les fichiers un par un, vous les t√©l√©chargez tous en m√™me temps.

**3. Interface graphique**
```
Thread principal: G√®re l'interface (boutons, fen√™tres)
Thread secondaire: Effectue un calcul long
```

Sans concurrence, votre interface "g√®lerait" pendant les calculs longs. Avec concurrence, l'interface reste r√©active.

---

## Concepts fondamentaux

### 1. Programmation s√©quentielle (classique)

C'est la fa√ßon dont vous avez probablement toujours programm√© jusqu'ici.

```python
# Programmation s√©quentielle
def preparer_petit_dejeuner():
    faire_cafe()      # 3 minutes
    faire_toasts()    # 2 minutes
    faire_oeufs()     # 4 minutes
    # Total: 9 minutes
```

**Caract√©ristiques** :
- Simple √† comprendre et √† d√©boguer
- Les instructions s'ex√©cutent dans l'ordre
- Une instruction √† la fois

### 2. Programmation concurrente

Plusieurs t√¢ches progressent en m√™me temps (ou semblent le faire).

```python
# Programmation concurrente
def preparer_petit_dejeuner_concurrent():
    # Tout d√©marre en m√™me temps!
    lancer_cafe()     # En parall√®le
    lancer_toasts()   # En parall√®le
    lancer_oeufs()    # En parall√®le
    # Total: 4 minutes (le temps de la t√¢che la plus longue)
```

**Caract√©ristiques** :
- Plus complexe mais plus efficace
- Plusieurs choses se passent "en m√™me temps"
- Peut √™tre plus rapide

---

## Concurrence vs Parall√©lisme

Ces deux termes sont souvent confondus, mais ils sont diff√©rents :

### Concurrence

**D√©finition** : G√©rer plusieurs t√¢ches en m√™me temps (mais pas n√©cessairement en les ex√©cutant simultan√©ment).

**Analogie** : Un seul jongleur qui jongle avec plusieurs balles. Il ne tient jamais toutes les balles en m√™me temps, mais il passe rapidement de l'une √† l'autre.

```
Processeur unique qui bascule entre les t√¢ches:
Temps: |--A--|--B--|--A--|--C--|--B--|--A--|
```

### Parall√©lisme

**D√©finition** : Ex√©cuter plusieurs t√¢ches **vraiment** en m√™me temps, sur plusieurs processeurs.

**Analogie** : Plusieurs jongleurs, chacun jonglant avec ses propres balles.

```
Plusieurs processeurs travaillant simultan√©ment:
CPU 1: |------A------|------A------|
CPU 2: |------B------|------B------|
CPU 3: |------C------|------C------|
```

### Tableau comparatif

| Aspect | Concurrence | Parall√©lisme |
|--------|------------|--------------|
| **D√©finition** | G√©rer plusieurs t√¢ches | Ex√©cuter plusieurs t√¢ches simultan√©ment |
| **Ex√©cution** | Une t√¢che √† la fois (bascule rapide) | Plusieurs t√¢ches vraiment en m√™me temps |
| **Mat√©riel** | Fonctionne sur 1 CPU | N√©cessite plusieurs CPUs/c≈ìurs |
| **Exemple** | Serveur web g√©rant 1000 connexions | Calcul scientifique sur 8 c≈ìurs |
| **But** | G√©rer plusieurs choses, ne pas bloquer | Acc√©l√©rer les calculs |

---

## Les diff√©rentes approches en Python

Python offre plusieurs outils pour la programmation concurrente. Voici un aper√ßu :

### 1. Threading (Fils d'ex√©cution)

**Qu'est-ce que c'est ?** Des "fils" d'ex√©cution qui partagent la m√™me m√©moire.

**Id√©al pour** :
- ‚úÖ Op√©rations d'entr√©e/sortie (I/O) : fichiers, r√©seau, bases de donn√©es
- ‚úÖ T√¢ches qui attendent beaucoup (t√©l√©chargements, requ√™tes API)

**Pas id√©al pour** :
- ‚ùå Calculs intensifs (limit√© par le GIL de Python)

```python
import threading

def tache():
    print("T√¢che ex√©cut√©e")

# Cr√©er un thread
thread = threading.Thread(target=tache)
thread.start()
```

### 2. Multiprocessing (Multi-processus)

**Qu'est-ce que c'est ?** Plusieurs processus ind√©pendants, chacun avec sa propre m√©moire.

**Id√©al pour** :
- ‚úÖ Calculs intensifs (CPU-bound)
- ‚úÖ Exploiter plusieurs c≈ìurs du processeur

**Pas id√©al pour** :
- ‚ùå T√¢ches avec beaucoup de partage de donn√©es (communication co√ªteuse)

```python
import multiprocessing

def tache():
    print("T√¢che ex√©cut√©e dans un processus")

# Cr√©er un processus
process = multiprocessing.Process(target=tache)
process.start()
```

### 3. Asyncio (Asynchrone)

**Qu'est-ce que c'est ?** Programmation asynchrone avec `async`/`await`.

**Id√©al pour** :
- ‚úÖ Beaucoup d'op√©rations I/O simultan√©es
- ‚úÖ Applications r√©seau (serveurs, clients)
- ‚úÖ Scalabilit√© (des milliers de connexions)

**Pas id√©al pour** :
- ‚ùå Calculs intensifs

```python
import asyncio

async def tache():
    print("T√¢che asynchrone")
    await asyncio.sleep(1)

# Ex√©cuter
asyncio.run(tache())
```

---

## Comprendre le GIL (Global Interpreter Lock)

Le **GIL** est un verrou dans Python qui emp√™che plusieurs threads d'ex√©cuter du code Python en m√™me temps.

### Pourquoi le GIL existe ?

Le GIL prot√®ge les structures de donn√©es internes de Python et rend l'impl√©mentation plus simple. C'est une caract√©ristique de CPython (l'impl√©mentation standard de Python).

### Impact du GIL

```python
# Threading avec calculs (limit√© par le GIL)
# Les threads s'ex√©cutent l'un apr√®s l'autre pour les calculs
def calcul_intensif():
    for i in range(10000000):
        x = i * i

# ‚ùå Pas vraiment parall√®le √† cause du GIL
threads = [threading.Thread(target=calcul_intensif) for _ in range(4)]

# Multiprocessing (contourne le GIL)
# ‚úÖ Vraiment parall√®le car chaque processus a son propre interpr√©teur
processes = [multiprocessing.Process(target=calcul_intensif) for _ in range(4)]
```

### Tableau r√©capitulatif du GIL

| Type d'op√©ration | Threading | Multiprocessing |
|------------------|-----------|-----------------|
| **I/O** (fichiers, r√©seau) | ‚úÖ Efficace (GIL lib√©r√©) | ‚úÖ Efficace (mais overhead) |
| **Calculs** (CPU-bound) | ‚ùå Limit√© par le GIL | ‚úÖ Vraiment parall√®le |
| **Cr√©ation** | Rapide | Plus lent |
| **M√©moire** | Partag√©e | S√©par√©e |

---

## Types de t√¢ches : I/O-bound vs CPU-bound

Comprendre la diff√©rence est crucial pour choisir la bonne approche.

### I/O-bound (Limit√© par les entr√©es/sorties)

**D√©finition** : Le programme passe la majorit√© de son temps √† **attendre** des donn√©es.

**Exemples** :
- T√©l√©charger des fichiers depuis Internet
- Lire/√©crire dans des fichiers
- Requ√™tes √† une base de donn√©es
- Appels API

**Caract√©ristique** : Le CPU est souvent inactif, en attente.

**Solution recommand√©e** : Threading ou Asyncio

```python
import time

# Exemple I/O-bound
def telecharger_fichier(url):
    print(f"T√©l√©chargement de {url}...")
    time.sleep(2)  # Simule l'attente r√©seau
    print(f"{url} t√©l√©charg√©")
```

### CPU-bound (Limit√© par le processeur)

**D√©finition** : Le programme passe la majorit√© de son temps √† **calculer**.

**Exemples** :
- Calculs math√©matiques complexes
- Traitement d'images
- Encodage vid√©o
- Algorithmes de machine learning

**Caract√©ristique** : Le CPU travaille √† 100%.

**Solution recommand√©e** : Multiprocessing

```python
# Exemple CPU-bound
def calculer():
    total = 0
    for i in range(10000000):
        total += i * i  # Calcul intensif
    return total
```

---

## Quand utiliser quoi ? Guide de d√©cision

Voici un arbre de d√©cision simple pour choisir la bonne approche :

```
Vous avez besoin de concurrence ?
‚îÇ
‚îú‚îÄ Votre t√¢che est I/O-bound (beaucoup d'attente) ?
‚îÇ  ‚îÇ
‚îÇ  ‚îú‚îÄ Oui ‚Üí Beaucoup de connexions simultan√©es ?
‚îÇ  ‚îÇ  ‚îú‚îÄ Oui ‚Üí Asyncio (milliers de connexions)
‚îÇ  ‚îÇ  ‚îî‚îÄ Non ‚Üí Threading (dizaines de connexions)
‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ Non ‚Üí Votre t√¢che est CPU-bound (calculs) ?
‚îÇ     ‚îî‚îÄ Oui ‚Üí Multiprocessing
‚îÇ
‚îî‚îÄ Besoin de synchronisation complexe ?
   ‚îî‚îÄ Patterns de concurrence (chapitre 8.4)
```

### Tableau r√©capitulatif

| Crit√®re | Threading | Multiprocessing | Asyncio |
|---------|-----------|-----------------|---------|
| **Type de t√¢che** | I/O-bound | CPU-bound | I/O-bound |
| **Nombre de t√¢ches** | Dizaines | Limit√© par CPUs | Milliers |
| **Complexit√©** | ‚≠ê‚≠ê Moyenne | ‚≠ê‚≠ê Moyenne | ‚≠ê‚≠ê‚≠ê Plus √©lev√©e |
| **Overhead** | Faible | √âlev√© | Tr√®s faible |
| **Partage m√©moire** | ‚úÖ Facile | ‚ùå Difficile | ‚úÖ Facile |
| **D√©bogage** | ‚≠ê‚≠ê Moyen | ‚≠ê‚≠ê Moyen | ‚≠ê‚≠ê‚≠ê Plus difficile |

---

## Les d√©fis de la programmation concurrente

La programmation concurrente n'est pas magique. Elle apporte son lot de d√©fis :

### 1. Race Conditions (Conditions de course)

Quand plusieurs threads acc√®dent aux m√™mes donn√©es sans coordination.

```python
# Probl√®me potentiel
compteur = 0

def incrementer():
    global compteur
    compteur += 1  # Pas atomique!

# Deux threads peuvent lire la m√™me valeur et √©craser leurs modifications
```

### 2. Deadlocks (Interblocages)

Quand des threads s'attendent mutuellement et se bloquent.

```
Thread A d√©tient la ressource 1, veut la ressource 2
Thread B d√©tient la ressource 2, veut la ressource 1
‚Üí Les deux threads sont bloqu√©s ind√©finiment!
```

### 3. Complexit√© du d√©bogage

Les bugs concurrents sont difficiles √† reproduire car ils d√©pendent du timing.

```python
# Ce bug peut appara√Ætre 1 fois sur 1000 ex√©cutions
# Tr√®s difficile √† d√©boguer!
```

### 4. Overhead (Surcharge)

Cr√©er des threads/processus a un co√ªt en temps et en m√©moire.

```python
# ‚ùå Mauvais : Cr√©er 10000 threads
for i in range(10000):
    Thread(target=tache).start()

# ‚úÖ Bon : Pool de workers
with ThreadPoolExecutor(max_workers=10) as executor:
    executor.map(tache, range(10000))
```

---

## Exemples comparatifs

Pour bien comprendre l'impact de la concurrence, voici quelques exemples comparatifs.

### Exemple 1 : T√©l√©chargement de fichiers

**Sans concurrence** :
```python
import time

def telecharger_sequentiel(urls):
    for url in urls:
        print(f"T√©l√©chargement {url}...")
        time.sleep(2)  # Simule le t√©l√©chargement
    # 5 URLs √ó 2s = 10 secondes
```

**Avec threading** :
```python
import threading
import time

def telecharger_concurrent(urls):
    threads = []
    for url in urls:
        t = threading.Thread(target=telecharger_un, args=(url,))
        threads.append(t)
        t.start()

    for t in threads:
        t.join()
    # 5 URLs en parall√®le = ~2 secondes!
```

### Exemple 2 : Calculs intensifs

**Sans concurrence** :
```python
def calculer_sequentiel(nombres):
    resultats = []
    for n in nombres:
        resultats.append(n ** 2)
    # 100 calculs en s√©quence
```

**Avec multiprocessing** :
```python
from multiprocessing import Pool

def calculer_parallele(nombres):
    with Pool() as pool:
        resultats = pool.map(lambda x: x ** 2, nombres)
    # 100 calculs r√©partis sur 8 c≈ìurs = 8√ó plus rapide!
```

---

## Performance : Mesurer l'am√©lioration

Il est important de **mesurer** avant d'optimiser. La concurrence n'est pas toujours plus rapide !

### Loi d'Amdahl

**Principe** : Le gain de performance est limit√© par la partie s√©quentielle du programme.

Si seulement 50% de votre programme peut √™tre parall√©lis√©, vous ne pourrez jamais obtenir plus de 2√ó d'am√©lioration, m√™me avec 1000 CPUs.

```
Speedup maximal = 1 / (S + P/N)

O√π:
S = Partie s√©quentielle (0.5 = 50%)
P = Partie parall√©lisable (0.5 = 50%)
N = Nombre de processeurs
```

### Quand la concurrence est contre-productive

```python
# ‚ùå Mauvais : Overhead plus co√ªteux que le gain
def tache_rapide():
    return 2 + 2

# Cr√©er un thread pour √ßa est plus lent que l'ex√©cution directe!
```

**R√®gle d'or** : La concurrence est utile quand le temps de la t√¢che >> temps de cr√©ation du thread/processus.

---

## Structure du chapitre

Ce chapitre est organis√© en 4 sections principales :

### 8.1 Threading et Multiprocessing
- Les bases du threading
- Utilisation du multiprocessing
- Quand utiliser l'un ou l'autre
- Pool de workers avec `concurrent.futures`

### 8.2 Programmation asynchrone avec asyncio
- Concepts : async/await
- Event loop
- Coroutines et t√¢ches
- Biblioth√®ques asynchrones

### 8.3 Gestion des verrous et synchronisation
- Lock, RLock, Semaphore
- Event et Condition
- √âviter les race conditions et deadlocks
- Patterns de synchronisation

### 8.4 Patterns de concurrence
- Producer-Consumer
- Worker Pool
- Pipeline
- Map-Reduce
- Et plus encore...

---

## Conseils pour d√©buter

### 1. Commencez simple

Ne vous lancez pas directement dans la programmation concurrente pour tout. Commencez par du code s√©quentiel, puis optimisez si n√©cessaire.

```python
# √âtape 1: Version simple qui fonctionne
def traiter_donnees(donnees):
    return [traiter_item(item) for item in donnees]

# √âtape 2: Identifier le goulot d'√©tranglement
# √âtape 3: Ajouter la concurrence seulement si b√©n√©fique
```

### 2. Mesurez toujours

Utilisez des outils pour mesurer les performances :

```python
import time

def mesurer_temps(fonction):
    debut = time.time()
    resultat = fonction()
    duree = time.time() - debut
    print(f"Temps: {duree:.2f}s")
    return resultat
```

### 3. Comprenez le type de votre t√¢che

Avant de choisir une approche :
- ‚ùì Ma t√¢che est-elle I/O-bound ou CPU-bound ?
- ‚ùì Combien de t√¢ches ai-je besoin d'ex√©cuter ?
- ‚ùì Ai-je besoin de partager des donn√©es ?

### 4. Utilisez des abstractions de haut niveau

Pr√©f√©rez les outils modernes qui cachent la complexit√© :

```python
# ‚úÖ Bon : Utilise concurrent.futures
from concurrent.futures import ThreadPoolExecutor

with ThreadPoolExecutor() as executor:
    resultats = executor.map(fonction, donnees)

# ‚ùå Moins bon : Gestion manuelle des threads
threads = []
for donnee in donnees:
    t = threading.Thread(target=fonction, args=(donnee,))
    threads.append(t)
    t.start()
# ... g√©rer la synchronisation manuellement
```

### 5. G√©rez les erreurs

La gestion d'erreurs est encore plus importante en concurrent :

```python
def worker_robuste():
    try:
        # Code qui peut √©chouer
        resultat = tache_risquee()
    except Exception as e:
        print(f"Erreur: {e}")
        # Log, notification, retry...
```

---

## Vocabulaire essentiel

Avant de continuer, voici les termes cl√©s que vous rencontrerez :

| Terme | D√©finition |
|-------|------------|
| **Thread** | Fil d'ex√©cution au sein d'un processus |
| **Processus** | Programme en cours d'ex√©cution avec sa propre m√©moire |
| **Concurrence** | G√©rer plusieurs t√¢ches (pas forc√©ment simultan√©es) |
| **Parall√©lisme** | Ex√©cuter plusieurs t√¢ches vraiment en m√™me temps |
| **I/O-bound** | Limit√© par les entr√©es/sorties (attente) |
| **CPU-bound** | Limit√© par la puissance de calcul |
| **Race condition** | R√©sultat d√©pendant de l'ordre d'ex√©cution |
| **Deadlock** | Blocage mutuel de threads/processus |
| **Lock** | Verrou pour prot√©ger l'acc√®s √† une ressource |
| **Coroutine** | Fonction qui peut √™tre mise en pause et reprise |
| **Event loop** | Boucle qui g√®re l'ex√©cution des t√¢ches asynchrones |
| **GIL** | Global Interpreter Lock (limite le threading en Python) |

---

## Cas d'usage r√©els

Pour vous inspirer, voici quelques applications concr√®tes de la programmation concurrente :

### Applications web
- **Flask/Django** : G√©rer des milliers de requ√™tes HTTP simultan√©es
- **FastAPI** : API haute performance avec asyncio

### Traitement de donn√©es
- **Web scraping** : T√©l√©charger des centaines de pages en parall√®le
- **ETL** : Extract, Transform, Load de donn√©es

### Calcul scientifique
- **NumPy/Pandas** : Op√©rations vectoris√©es sur de grandes matrices
- **Machine Learning** : Entra√Ænement de mod√®les sur plusieurs c≈ìurs

### Syst√®mes temps-r√©el
- **Jeux vid√©o** : Rendu graphique, physique, IA en parall√®le
- **Trading** : Traiter des millions de transactions par seconde

### IoT et automatisation
- **Monitoring** : Surveiller des centaines de capteurs simultan√©ment
- **Domotique** : G√©rer plusieurs appareils en temps r√©el

---

## √Ä quoi s'attendre dans ce chapitre

### Ce que vous allez apprendre

‚úÖ Les trois approches principales : Threading, Multiprocessing, Asyncio
‚úÖ Comment choisir la bonne approche pour votre probl√®me
‚úÖ Les m√©canismes de synchronisation (locks, semaphores, etc.)
‚úÖ Des patterns √©prouv√©s pour r√©soudre des probl√®mes courants
‚úÖ Comment √©viter les pi√®ges et les bugs concurrents
‚úÖ Des exemples pratiques et r√©alistes

### Ce que vous serez capable de faire

√Ä la fin de ce chapitre, vous pourrez :
- Acc√©l√©rer vos programmes avec threading et multiprocessing
- Cr√©er des applications web asynchrones performantes
- G√©rer correctement le partage de donn√©es entre threads
- Impl√©menter des patterns de concurrence courants
- D√©boguer les probl√®mes concurrents basiques

---

## Pr√©requis

Avant de plonger dans ce chapitre, assurez-vous d'√™tre √† l'aise avec :

‚úÖ **Python de base** : fonctions, classes, modules
‚úÖ **Gestion d'erreurs** : try/except
‚úÖ **Compr√©hension des boucles** : for, while
‚úÖ **Concepts de programmation** : variables, types de donn√©es

**Pas besoin** :
‚ùå Connaissances en syst√®mes d'exploitation
‚ùå Exp√©rience pr√©alable en concurrence
‚ùå Math√©matiques avanc√©es

---

## Ressources compl√©mentaires

Pour approfondir vos connaissances en programmation concurrente :

### Documentation officielle Python
- `threading` : https://docs.python.org/3/library/threading.html
- `multiprocessing` : https://docs.python.org/3/library/multiprocessing.html
- `asyncio` : https://docs.python.org/3/library/asyncio.html
- `concurrent.futures` : https://docs.python.org/3/library/concurrent.futures.html

### Livres recommand√©s
- "Python Concurrency with asyncio" de Matthew Fowler
- "High Performance Python" de Micha Gorelick et Ian Ozsvald

### Outils de mesure de performance
- `time` : Mesure de temps basique
- `cProfile` : Profilage de code
- `line_profiler` : Profilage ligne par ligne

---

## Pr√™t √† commencer ?

La programmation concurrente peut sembler complexe, mais avec une approche progressive et des exemples concrets, vous ma√Ætriserez rapidement ces concepts puissants.

**Conseil final** : Ne vous pr√©cipitez pas. Prenez le temps de comprendre chaque concept avant de passer au suivant. La programmation concurrente demande une r√©flexion diff√©rente, mais une fois que vous "l'avez", c'est un super-pouvoir qui transformera vos programmes !

Dans la section suivante (8.1), nous commencerons par les bases du **Threading et Multiprocessing** avec des exemples pratiques et progressifs.

**Bonne lecture et bon codage ! üöÄ**

‚è≠Ô∏è [Threading et multiprocessing](/08-programmation-concurrente/01-threading-et-multiprocessing.md)
