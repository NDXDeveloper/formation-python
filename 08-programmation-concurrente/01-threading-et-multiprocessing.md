üîù Retour au [Sommaire](/SOMMAIRE.md)

# 8.1 : Threading et multiprocessing

## Introduction

Dans cette section, nous allons explorer les deux principales approches pour la programmation concurrente en Python : les threads et les processus. Nous verrons comment cr√©er, g√©rer et synchroniser ces t√¢ches concurrentes.

### Analogie pratique
Imaginez que vous devez **nettoyer une maison** :
- **S√©quentiel** : Vous nettoyez pi√®ce par pi√®ce, une √† la fois
- **Threading** : Vous et votre famille nettoyez en m√™me temps, en vous passant les outils
- **Multiprocessing** : Chaque personne nettoie avec ses propres outils, ind√©pendamment

## Module threading : Threads en Python

Les threads permettent d'ex√©cuter plusieurs t√¢ches de fa√ßon concurrente dans le m√™me processus.

### Cr√©ation d'un thread simple

```python
import threading
import time

def tache_longue(nom, duree):
    """Simule une t√¢che qui prend du temps."""
    print(f"üöÄ {nom} commenc√©e")

    for i in range(duree):
        print(f"‚è≥ {nom}: √©tape {i+1}/{duree}")
        time.sleep(1)

    print(f"‚úÖ {nom} termin√©e")

# Ex√©cution s√©quentielle (lente)
print("=== EX√âCUTION S√âQUENTIELLE ===")
start_time = time.time()

tache_longue("T√¢che A", 3)
tache_longue("T√¢che B", 3)

sequential_time = time.time() - start_time
print(f"Temps total s√©quentiel: {sequential_time:.1f}s\n")

# Ex√©cution avec threads (plus rapide)
print("=== EX√âCUTION AVEC THREADS ===")
start_time = time.time()

# Cr√©er les threads
thread1 = threading.Thread(target=tache_longue, args=("T√¢che A", 3))
thread2 = threading.Thread(target=tache_longue, args=("T√¢che B", 3))

# D√©marrer les threads
thread1.start()
thread2.start()

# Attendre que tous les threads se terminent
thread1.join()
thread2.join()

concurrent_time = time.time() - start_time
print(f"Temps total concurrent: {concurrent_time:.1f}s")
print(f"Acc√©l√©ration: {sequential_time/concurrent_time:.1f}x")
```

### Thread avec classe personnalis√©e

```python
import threading
import time
import random

class TelechargerFichier(threading.Thread):
    """Thread personnalis√© pour t√©l√©charger un fichier."""

    def __init__(self, nom_fichier, taille_mo):
        super().__init__()
        self.nom_fichier = nom_fichier
        self.taille_mo = taille_mo
        self.progression = 0
        self.termine = False

    def run(self):
        """M√©thode principale du thread."""
        print(f"üì• D√©but t√©l√©chargement: {self.nom_fichier}")

        # Simuler le t√©l√©chargement
        for i in range(self.taille_mo):
            time.sleep(random.uniform(0.1, 0.3))  # Vitesse variable
            self.progression = (i + 1) / self.taille_mo * 100
            print(f"üìä {self.nom_fichier}: {self.progression:.1f}%")

        self.termine = True
        print(f"‚úÖ {self.nom_fichier} t√©l√©charg√©!")

    def get_statut(self):
        """Retourne le statut actuel du t√©l√©chargement."""
        if self.termine:
            return "Termin√©"
        elif self.progression > 0:
            return f"En cours ({self.progression:.1f}%)"
        else:
            return "En attente"

# Test des t√©l√©chargements concurrents
def demo_telechargements():
    fichiers = [
        ("video.mp4", 5),
        ("document.pdf", 2),
        ("image.jpg", 1),
        ("archive.zip", 3)
    ]

    threads = []

    # Cr√©er et d√©marrer les threads
    for nom, taille in fichiers:
        thread = TelechargerFichier(nom, taille)
        threads.append(thread)
        thread.start()

    # Surveillance p√©riodique
    while any(not t.termine for t in threads):
        time.sleep(1)
        print(f"\nüìã Statut des t√©l√©chargements:")
        for t in threads:
            print(f"  {t.nom_fichier}: {t.get_statut()}")

    # Attendre la fin de tous les threads
    for t in threads:
        t.join()

    print("\nüéâ Tous les t√©l√©chargements termin√©s!")

demo_telechargements()
```

### Synchronisation avec Lock

```python
import threading
import time

# Variable partag√©e (dangereuse sans synchronisation)
compteur = 0
lock = threading.Lock()

def incrementer_dangereux(nb_iterations):
    """Incr√©mente sans protection (race condition)."""
    global compteur
    for _ in range(nb_iterations):
        # Op√©ration non-atomique ! Danger !
        temp = compteur
        temp += 1
        compteur = temp

def incrementer_securise(nb_iterations):
    """Incr√©mente avec protection par lock."""
    global compteur
    for _ in range(nb_iterations):
        with lock:  # Acquisition automatique du verrou
            temp = compteur
            temp += 1
            compteur = temp

def test_synchronisation():
    """Teste la diff√©rence avec et sans synchronisation."""
    global compteur

    # Test sans synchronisation
    print("üî• Test SANS synchronisation (race condition)")
    compteur = 0
    threads = []

    for i in range(5):
        t = threading.Thread(target=incrementer_dangereux, args=(1000,))
        threads.append(t)
        t.start()

    for t in threads:
        t.join()

    print(f"R√©sultat attendu: 5000")
    print(f"R√©sultat obtenu: {compteur}")
    print(f"Diff√©rence: {5000 - compteur} (race condition!)\n")

    # Test avec synchronisation
    print("üîí Test AVEC synchronisation (s√©curis√©)")
    compteur = 0
    threads = []

    for i in range(5):
        t = threading.Thread(target=incrementer_securise, args=(1000,))
        threads.append(t)
        t.start()

    for t in threads:
        t.join()

    print(f"R√©sultat attendu: 5000")
    print(f"R√©sultat obtenu: {compteur}")
    print("‚úÖ R√©sultat correct avec synchronisation!")

test_synchronisation()
```

### Communication avec Queue

```python
import threading
import queue
import time
import random

def producteur(q, nom, nb_items):
    """Produit des √©l√©ments et les place dans la queue."""
    for i in range(nb_items):
        item = f"{nom}_item_{i+1}"

        # Simuler du travail
        time.sleep(random.uniform(0.1, 0.5))

        q.put(item)
        print(f"üì¶ Produit: {item}")

    print(f"‚úÖ {nom} a termin√© la production")

def consommateur(q, nom):
    """Consomme des √©l√©ments de la queue."""
    while True:
        try:
            # Attendre un √©l√©ment (timeout pour √©viter de bloquer)
            item = q.get(timeout=2)

            print(f"üîÑ {nom} traite: {item}")

            # Simuler le traitement
            time.sleep(random.uniform(0.2, 0.8))

            print(f"‚úÖ {nom} a termin√©: {item}")
            q.task_done()

        except queue.Empty:
            print(f"‚è∞ {nom}: timeout, arr√™t")
            break

def demo_producer_consumer():
    """D√©monstration du pattern Producteur-Consommateur."""
    print("üè≠ PATTERN PRODUCTEUR-CONSOMMATEUR")
    print("-" * 40)

    # Cr√©er une queue thread-safe
    q = queue.Queue(maxsize=5)  # Limite de 5 √©l√©ments

    # Cr√©er les producteurs
    producteur1 = threading.Thread(target=producteur, args=(q, "Prod1", 3))
    producteur2 = threading.Thread(target=producteur, args=(q, "Prod2", 4))

    # Cr√©er les consommateurs
    consommateur1 = threading.Thread(target=consommateur, args=(q, "Cons1"))
    consommateur2 = threading.Thread(target=consommateur, args=(q, "Cons2"))

    # D√©marrer tous les threads
    producteur1.start()
    producteur2.start()
    consommateur1.start()
    consommateur2.start()

    # Attendre que les producteurs terminent
    producteur1.join()
    producteur2.join()

    # Attendre que tous les √©l√©ments soient trait√©s
    q.join()

    print("üéâ Tous les √©l√©ments ont √©t√© trait√©s!")

demo_producer_consumer()
```

## Module multiprocessing : Processus parall√®les

Le multiprocessing permet un vrai parall√©lisme en cr√©ant des processus s√©par√©s.

### Processus simple

```python
import multiprocessing
import time
import os

def calcul_intensif(nom, debut, fin):
    """Calcul CPU-intensif (somme des carr√©s)."""
    pid = os.getpid()
    print(f"üîÑ {nom} (PID {pid}): calcul de {debut} √† {fin}")

    total = 0
    for i in range(debut, fin):
        total += i * i

    print(f"‚úÖ {nom} (PID {pid}): r√©sultat = {total}")
    return total

def demo_multiprocessing():
    """Compare s√©quentiel vs parall√®le pour calculs CPU."""

    # T√¢ches √† effectuer
    taches = [
        ("T√¢che 1", 0, 1000000),
        ("T√¢che 2", 1000000, 2000000),
        ("T√¢che 3", 2000000, 3000000),
        ("T√¢che 4", 3000000, 4000000)
    ]

    print("üíª COMPARAISON S√âQUENTIEL vs PARALL√àLE")
    print("-" * 45)

    # Ex√©cution s√©quentielle
    print("\nüêå Ex√©cution s√©quentielle:")
    start_time = time.time()

    resultats_seq = []
    for nom, debut, fin in taches:
        resultat = calcul_intensif(nom, debut, fin)
        resultats_seq.append(resultat)

    temps_seq = time.time() - start_time
    print(f"Temps s√©quentiel: {temps_seq:.2f}s")

    # Ex√©cution parall√®le
    print(f"\nüöÄ Ex√©cution parall√®le:")
    start_time = time.time()

    with multiprocessing.Pool() as pool:
        # Lancer tous les calculs en parall√®le
        resultats_par = pool.starmap(calcul_intensif, taches)

    temps_par = time.time() - start_time
    print(f"Temps parall√®le: {temps_par:.2f}s")
    print(f"Acc√©l√©ration: {temps_seq/temps_par:.1f}x")

    # V√©rifier que les r√©sultats sont identiques
    print(f"\nR√©sultats identiques: {resultats_seq == resultats_par}")

if __name__ == "__main__":
    demo_multiprocessing()
```

### Communication entre processus

```python
import multiprocessing
import time
import random

def travailleur(nom, queue_entree, queue_sortie):
    """Processus travailleur qui traite des t√¢ches."""
    pid = multiprocessing.current_process().pid
    print(f"üë∑ {nom} (PID {pid}) d√©marr√©")

    while True:
        try:
            tache = queue_entree.get(timeout=2)

            if tache is None:  # Signal d'arr√™t
                print(f"üõë {nom} arr√™t√©")
                break

            print(f"üîÑ {nom} traite: {tache}")

            # Simuler du travail
            temps_travail = random.uniform(1, 3)
            time.sleep(temps_travail)

            resultat = f"R√©sultat de {tache}"
            queue_sortie.put((nom, resultat))

            print(f"‚úÖ {nom} termin√©: {tache}")

        except multiprocessing.TimeoutError:
            print(f"‚è∞ {nom} timeout")
            break

def demo_communication_processus():
    """D√©monstration de communication entre processus."""
    print("üîÑ COMMUNICATION ENTRE PROCESSUS")
    print("-" * 35)

    # Cr√©er les queues pour communication
    queue_entree = multiprocessing.Queue()
    queue_sortie = multiprocessing.Queue()

    # Ajouter des t√¢ches
    taches = [f"T√¢che_{i}" for i in range(1, 8)]
    for tache in taches:
        queue_entree.put(tache)

    # Cr√©er et d√©marrer les processus
    nb_workers = 3
    processus = []

    for i in range(nb_workers):
        p = multiprocessing.Process(
            target=travailleur,
            args=(f"Worker-{i+1}", queue_entree, queue_sortie)
        )
        processus.append(p)
        p.start()

    # Collecter les r√©sultats
    resultats = []
    for _ in range(len(taches)):
        worker, resultat = queue_sortie.get()
        resultats.append((worker, resultat))
        print(f"üì• Re√ßu de {worker}: {resultat}")

    # Arr√™ter les processus
    for _ in range(nb_workers):
        queue_entree.put(None)  # Signal d'arr√™t

    # Attendre la fin de tous les processus
    for p in processus:
        p.join()

    print(f"\nüéâ Traitement termin√©! {len(resultats)} r√©sultats collect√©s")

if __name__ == "__main__":
    demo_communication_processus()
```

## Exercices pratiques

### Exercice 1 : T√©l√©chargeur d'URLs

```python
import threading
import requests
import time

def telecharger_url(url, resultats, index):
    """T√©l√©charge une URL et stocke le r√©sultat."""
    try:
        print(f"üì• T√©l√©chargement de {url}")
        start_time = time.time()

        response = requests.get(url, timeout=10)
        duree = time.time() - start_time

        resultats[index] = {
            'url': url,
            'status': response.status_code,
            'taille': len(response.content),
            'duree': duree
        }

        print(f"‚úÖ {url}: {response.status_code} ({len(response.content)} bytes)")

    except Exception as e:
        print(f"‚ùå {url}: Erreur - {e}")
        resultats[index] = {'url': url, 'erreur': str(e)}

def telecharger_urls_concurrent(urls):
    """T√©l√©charge plusieurs URLs en parall√®le."""
    resultats = [None] * len(urls)
    threads = []

    # Cr√©er et d√©marrer les threads
    for i, url in enumerate(urls):
        t = threading.Thread(target=telecharger_url, args=(url, resultats, i))
        threads.append(t)
        t.start()

    # Attendre tous les threads
    for t in threads:
        t.join()

    return resultats

# Test
urls_test = [
    "https://httpbin.org/delay/1",
    "https://httpbin.org/status/200",
    "https://httpbin.org/json",
    "https://httpbin.org/user-agent"
]

print("üåê T√©l√©chargement concurrent d'URLs")
resultats = telecharger_urls_concurrent(urls_test)

print("\nüìä R√©sultats:")
for r in resultats:
    if 'erreur' in r:
        print(f"  ‚ùå {r['url']}: {r['erreur']}")
    else:
        print(f"  ‚úÖ {r['url']}: {r['status']} ({r['duree']:.2f}s)")
```

### Exercice 2 : Processeur d'images parall√®le

```python
import multiprocessing
from PIL import Image
import os

def redimensionner_image(info_image):
    """Redimensionne une image (fonction pour multiprocessing)."""
    chemin_entree, chemin_sortie, taille = info_image

    try:
        # Ouvrir et redimensionner l'image
        with Image.open(chemin_entree) as img:
            img_redimensionnee = img.resize(taille, Image.Resampling.LANCZOS)
            img_redimensionnee.save(chemin_sortie)

        return f"‚úÖ {os.path.basename(chemin_entree)} ‚Üí {taille}"

    except Exception as e:
        return f"‚ùå {os.path.basename(chemin_entree)}: {e}"

def traiter_images_parallele(dossier_images, taille_cible=(800, 600)):
    """Traite toutes les images d'un dossier en parall√®le."""

    if not os.path.exists(dossier_images):
        print(f"‚ùå Dossier non trouv√©: {dossier_images}")
        return

    # Pr√©parer les t√¢ches
    taches = []
    dossier_sortie = os.path.join(dossier_images, "redimensionnees")
    os.makedirs(dossier_sortie, exist_ok=True)

    for fichier in os.listdir(dossier_images):
        if fichier.lower().endswith(('.png', '.jpg', '.jpeg')):
            chemin_entree = os.path.join(dossier_images, fichier)
            chemin_sortie = os.path.join(dossier_sortie, f"thumb_{fichier}")
            taches.append((chemin_entree, chemin_sortie, taille_cible))

    if not taches:
        print("‚ùå Aucune image trouv√©e")
        return

    print(f"üñºÔ∏è Traitement de {len(taches)} images...")

    # Traitement parall√®le
    with multiprocessing.Pool() as pool:
        resultats = pool.map(redimensionner_image, taches)

    # Afficher les r√©sultats
    for resultat in resultats:
        print(f"  {resultat}")

# Test (cr√©er d'abord quelques images de test)
# traiter_images_parallele("./images")
```

### Exercice 3 : Monitor de syst√®me

```python
import threading
import time
import psutil
from collections import deque

class MonitorSysteme:
    """Monitor syst√®me avec threads pour collecte continue."""

    def __init__(self):
        self.actif = False
        self.donnees = {
            'cpu': deque(maxlen=60),      # 60 derni√®res mesures
            'memoire': deque(maxlen=60),
            'disque': deque(maxlen=60)
        }
        self.lock = threading.Lock()

    def collecter_metriques(self):
        """Thread de collecte des m√©triques."""
        while self.actif:
            cpu = psutil.cpu_percent(interval=1)
            memoire = psutil.virtual_memory().percent
            disque = psutil.disk_usage('/').percent

            with self.lock:
                self.donnees['cpu'].append(cpu)
                self.donnees['memoire'].append(memoire)
                self.donnees['disque'].append(disque)

            print(f"üìä CPU: {cpu:5.1f}% | RAM: {memoire:5.1f}% | Disque: {disque:5.1f}%")

    def detecter_alertes(self):
        """Thread de d√©tection d'alertes."""
        seuils = {'cpu': 80, 'memoire': 85, 'disque': 90}

        while self.actif:
            time.sleep(5)  # V√©rifier toutes les 5 secondes

            with self.lock:
                for metrique, valeurs in self.donnees.items():
                    if valeurs and valeurs[-1] > seuils[metrique]:
                        print(f"üö® ALERTE {metrique.upper()}: {valeurs[-1]:.1f}%")

    def demarrer(self, duree=30):
        """D√©marre le monitoring."""
        print(f"üñ•Ô∏è D√©marrage du monitoring ({duree}s)...")
        self.actif = True

        # D√©marrer les threads
        thread_collecte = threading.Thread(target=self.collecter_metriques)
        thread_alertes = threading.Thread(target=self.detecter_alertes)

        thread_collecte.start()
        thread_alertes.start()

        # Arr√™ter apr√®s la dur√©e sp√©cifi√©e
        time.sleep(duree)
        self.actif = False

        thread_collecte.join()
        thread_alertes.join()

        print("‚úÖ Monitoring termin√©")

        # Afficher un r√©sum√©
        with self.lock:
            for metrique, valeurs in self.donnees.items():
                if valeurs:
                    moyenne = sum(valeurs) / len(valeurs)
                    maximum = max(valeurs)
                    print(f"  {metrique.capitalize()}: moy={moyenne:.1f}%, max={maximum:.1f}%")

# Test
# monitor = MonitorSysteme()
# monitor.demarrer(15)  # 15 secondes de monitoring
```

## Bonnes pratiques

### **1. Threading**
```python
# ‚úÖ Bon : Utiliser with pour les locks
with lock:
    shared_data += 1

# ‚úÖ Bon : join() pour attendre les threads
for thread in threads:
    thread.join()

# ‚ùå √âviter : acc√®s non prot√©g√© aux donn√©es partag√©es
# shared_counter += 1  # Race condition !
```

### **2. Multiprocessing**
```python
# ‚úÖ Bon : Protection avec if __name__ == "__main__"
if __name__ == "__main__":
    with multiprocessing.Pool() as pool:
        results = pool.map(worker_function, tasks)

# ‚úÖ Bon : Utiliser des queues pour la communication
queue = multiprocessing.Queue()

# ‚ùå √âviter : partage direct de variables
# global_var = 0  # Ne fonctionne pas entre processus
```

### **3. Gestion d'erreurs**
```python
def worker_securise(task):
    try:
        return process_task(task)
    except Exception as e:
        logging.error(f"Erreur dans worker: {e}")
        return None
```

## Quand utiliser quoi ?

### **Threading** üßµ
- **I/O-bound** : fichiers, r√©seau, bases de donn√©es
- **Interfaces utilisateur** : garder la responsivit√©
- **T√¢ches courtes** et fr√©quentes

### **Multiprocessing** ‚ö°
- **CPU-bound** : calculs, traitement d'images, ML
- **Isolation** : t√¢ches ind√©pendantes
- **Utiliser tous les c≈ìurs** du processeur

## R√©sum√©

Dans cette section, nous avons appris :

1. **Threading** : Concurrence pour I/O-bound tasks
2. **Multiprocessing** : Parall√©lisme pour CPU-bound tasks
3. **Synchronisation** : Locks, Queues pour √©viter les race conditions
4. **Patterns** : Producer-Consumer, Worker Pool
5. **Bonnes pratiques** : S√©curit√©, gestion d'erreurs

La programmation concurrente peut grandement am√©liorer les performances, mais n√©cessite attention et rigueur pour √©viter les pi√®ges.

Dans la prochaine section, nous explorerons `asyncio` pour la programmation asynchrone.

‚è≠Ô∏è
