ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 8.4 Patterns de Concurrence

## Introduction aux patterns de concurrence

Les **patterns de concurrence** sont des solutions Ã©prouvÃ©es pour rÃ©soudre des problÃ¨mes courants en programmation parallÃ¨le. Ce sont des "recettes" que vous pouvez rÃ©utiliser dans vos projets.

**Analogie** : Comme les recettes de cuisine, les patterns de concurrence fournissent une structure testÃ©e pour rÃ©soudre un problÃ¨me spÃ©cifique. Vous n'avez pas Ã  rÃ©inventer la roue !

### Pourquoi utiliser des patterns ?

âœ… **Avantages** :
- Solutions Ã©prouvÃ©es et testÃ©es
- Code plus maintenable et comprÃ©hensible
- Ã‰vitent les erreurs courantes
- Facilitent la communication entre dÃ©veloppeurs

âŒ **Sans patterns** :
- Code complexe et difficile Ã  dÃ©boguer
- Risques de deadlocks et race conditions
- RÃ©invention de solutions existantes

---

## Pattern 1 : Producer-Consumer (Producteur-Consommateur)

Le pattern **Producer-Consumer** sÃ©pare la production de donnÃ©es de leur consommation via une file d'attente (queue).

### Analogie

Imaginez une chaÃ®ne de production :
- **Producteurs** : Ouvriers qui fabriquent des piÃ¨ces
- **Queue** : Tapis roulant qui stocke les piÃ¨ces
- **Consommateurs** : Ouvriers qui assemblent les piÃ¨ces

Les producteurs et consommateurs travaillent Ã  leur propre rythme sans se bloquer mutuellement.

### Quand l'utiliser ?

âœ… Utilisez Producer-Consumer quand :
- Les tÃ¢ches de production et consommation ont des vitesses diffÃ©rentes
- Vous voulez dÃ©coupler la crÃ©ation de donnÃ©es de leur traitement
- Vous avez besoin d'un buffer entre deux parties du systÃ¨me

### ImplÃ©mentation avec Threading

```python
import threading
import queue
import time
import random

def producteur(q, producteur_id, nombre_items):
    """Produit des items et les met dans la queue"""
    for i in range(nombre_items):
        item = f"P{producteur_id}-Item{i}"

        # Simuler le temps de production
        time.sleep(random.uniform(0.1, 0.5))

        q.put(item)
        print(f"âœ… Producteur {producteur_id}: produit {item} (queue: {q.qsize()})")

    print(f"ğŸ Producteur {producteur_id}: terminÃ©")

def consommateur(q, consommateur_id):
    """Consomme des items de la queue"""
    while True:
        try:
            # Timeout pour Ã©viter de bloquer indÃ©finiment
            item = q.get(timeout=2)

            print(f"ğŸ”§ Consommateur {consommateur_id}: traite {item}")

            # Simuler le temps de traitement
            time.sleep(random.uniform(0.2, 0.8))

            q.task_done()

        except queue.Empty:
            print(f"â¸ï¸  Consommateur {consommateur_id}: queue vide, arrÃªt")
            break

# Utilisation
file_attente = queue.Queue(maxsize=10)

# CrÃ©er les threads
producteurs = [
    threading.Thread(target=producteur, args=(file_attente, i, 5))
    for i in range(2)
]

consommateurs = [
    threading.Thread(target=consommateur, args=(file_attente, i))
    for i in range(3)
]

# DÃ©marrer tous les threads
print("ğŸš€ DÃ©marrage du systÃ¨me Producer-Consumer\n")
for p in producteurs:
    p.start()
for c in consommateurs:
    c.start()

# Attendre la fin
for p in producteurs:
    p.join()
file_attente.join()  # Attendre que tous les items soient traitÃ©s

print("\nâœ… Tous les items ont Ã©tÃ© produits et consommÃ©s")
```

### ImplÃ©mentation avec Asyncio

```python
import asyncio
import random

async def producteur_async(q, producteur_id, nombre_items):
    """Producteur asynchrone"""
    for i in range(nombre_items):
        item = f"P{producteur_id}-Item{i}"
        await asyncio.sleep(random.uniform(0.1, 0.5))
        await q.put(item)
        print(f"âœ… Producteur {producteur_id}: produit {item}")

    print(f"ğŸ Producteur {producteur_id}: terminÃ©")

async def consommateur_async(q, consommateur_id, nb_producteurs):
    """Consommateur asynchrone"""
    items_traites = 0

    while True:
        try:
            item = await asyncio.wait_for(q.get(), timeout=2.0)
            print(f"ğŸ”§ Consommateur {consommateur_id}: traite {item}")
            await asyncio.sleep(random.uniform(0.2, 0.8))
            items_traites += 1
            q.task_done()

        except asyncio.TimeoutError:
            print(f"â¸ï¸  Consommateur {consommateur_id}: arrÃªt ({items_traites} items)")
            break

async def main():
    """Point d'entrÃ©e principal"""
    q = asyncio.Queue(maxsize=10)

    # CrÃ©er producteurs et consommateurs
    nb_producteurs = 2
    producteurs = [producteur_async(q, i, 5) for i in range(nb_producteurs)]
    consommateurs = [consommateur_async(q, i, nb_producteurs) for i in range(3)]

    # ExÃ©cuter
    await asyncio.gather(*producteurs, *consommateurs)
    print("\nâœ… Pipeline terminÃ©")

asyncio.run(main())
```

---

## Pattern 2 : Worker Pool (Pool de Workers)

Le **Worker Pool** maintient un ensemble de workers prÃªts Ã  traiter des tÃ¢ches.

### Analogie

Un centre d'appels avec plusieurs opÃ©rateurs :
- **Manager** : Distribue les appels entrants
- **Workers** : OpÃ©rateurs qui rÃ©pondent aux appels
- **Queue** : File d'attente des appels

Quand un opÃ©rateur est libre, il prend le prochain appel dans la file.

### Quand l'utiliser ?

âœ… Utilisez Worker Pool quand :
- Vous avez beaucoup de tÃ¢ches similaires Ã  exÃ©cuter
- Vous voulez limiter le nombre de threads/processus
- Les tÃ¢ches sont indÃ©pendantes les unes des autres

### ImplÃ©mentation avec concurrent.futures

```python
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
import random

def traiter_tache(tache_id):
    """Traite une tÃ¢che"""
    print(f"ğŸ”§ Worker {threading.current_thread().name}: dÃ©marre tÃ¢che {tache_id}")

    # Simuler le traitement
    duree = random.uniform(1, 3)
    time.sleep(duree)

    resultat = f"RÃ©sultat-{tache_id}"
    print(f"âœ… Worker {threading.current_thread().name}: terminÃ© tÃ¢che {tache_id}")

    return resultat

# CrÃ©er un pool de 3 workers
with ThreadPoolExecutor(max_workers=3) as executor:
    print("ğŸš€ Pool de workers dÃ©marrÃ© (3 workers)\n")

    # Soumettre 10 tÃ¢ches
    futures = [executor.submit(traiter_tache, i) for i in range(10)]

    # RÃ©cupÃ©rer les rÃ©sultats au fur et Ã  mesure
    for future in as_completed(futures):
        resultat = future.result()
        print(f"ğŸ“¦ RÃ©sultat reÃ§u: {resultat}")

print("\nâœ… Toutes les tÃ¢ches sont terminÃ©es")
```

### Worker Pool avec map()

```python
from concurrent.futures import ThreadPoolExecutor
import time

def calculer_carre(nombre):
    """Calcule le carrÃ© d'un nombre"""
    time.sleep(0.5)  # Simule un calcul
    return nombre ** 2

nombres = list(range(1, 11))

# Utiliser map pour traiter la liste
with ThreadPoolExecutor(max_workers=4) as executor:
    resultats = list(executor.map(calculer_carre, nombres))

print(f"Nombres: {nombres}")
print(f"CarrÃ©s: {resultats}")
```

### Worker Pool avec Asyncio

```python
import asyncio
import random

async def worker(nom, queue_taches, queue_resultats):
    """Worker asynchrone qui traite des tÃ¢ches"""
    while True:
        try:
            tache = await asyncio.wait_for(queue_taches.get(), timeout=1.0)

            print(f"ğŸ”§ {nom}: traite tÃ¢che {tache}")
            await asyncio.sleep(random.uniform(0.5, 1.5))

            resultat = f"RÃ©sultat-{tache}"
            await queue_resultats.put(resultat)

            queue_taches.task_done()

        except asyncio.TimeoutError:
            print(f"â¸ï¸  {nom}: aucune tÃ¢che, arrÃªt")
            break

async def main():
    """Gestionnaire de pool"""
    queue_taches = asyncio.Queue()
    queue_resultats = asyncio.Queue()

    # Remplir la queue de tÃ¢ches
    for i in range(15):
        await queue_taches.put(f"TÃ¢che-{i}")

    # CrÃ©er un pool de 5 workers
    workers = [
        asyncio.create_task(worker(f"Worker-{i}", queue_taches, queue_resultats))
        for i in range(5)
    ]

    # Attendre que toutes les tÃ¢ches soient traitÃ©es
    await queue_taches.join()

    # Attendre que tous les workers terminent
    await asyncio.gather(*workers)

    # Afficher les rÃ©sultats
    print(f"\nğŸ“Š {queue_resultats.qsize()} rÃ©sultats obtenus")

asyncio.run(main())
```

---

## Pattern 3 : Pipeline

Le **Pipeline** enchaÃ®ne plusieurs Ã©tapes de traitement, oÃ¹ la sortie d'une Ã©tape devient l'entrÃ©e de la suivante.

### Analogie

Une chaÃ®ne d'assemblage automobile :
1. **Ã‰tape 1** : Construire le chÃ¢ssis
2. **Ã‰tape 2** : Installer le moteur
3. **Ã‰tape 3** : Peindre la voiture
4. **Ã‰tape 4** : Installer les roues

Chaque Ã©tape travaille en parallÃ¨le sur diffÃ©rentes voitures.

### Quand l'utiliser ?

âœ… Utilisez Pipeline quand :
- Vous avez plusieurs Ã©tapes de traitement sÃ©quentielles
- Chaque Ã©tape peut travailler indÃ©pendamment
- Vous voulez maximiser le dÃ©bit (throughput)

### ImplÃ©mentation

```python
import threading
import queue
import time
import random

def etape_1_collecte(queue_sortie, nombre_items):
    """Ã‰tape 1: Collecte des donnÃ©es"""
    print("ğŸ“¥ Ã‰tape 1: Collecte des donnÃ©es")
    for i in range(nombre_items):
        donnee = f"Data-{i}"
        time.sleep(random.uniform(0.1, 0.3))
        queue_sortie.put(donnee)
        print(f"  â†’ CollectÃ©: {donnee}")

    queue_sortie.put(None)  # Signal de fin
    print("ğŸ Ã‰tape 1: TerminÃ©e")

def etape_2_nettoyage(queue_entree, queue_sortie):
    """Ã‰tape 2: Nettoyage des donnÃ©es"""
    print("ğŸ§¹ Ã‰tape 2: Nettoyage des donnÃ©es")
    while True:
        donnee = queue_entree.get()
        if donnee is None:
            queue_sortie.put(None)
            break

        time.sleep(random.uniform(0.2, 0.4))
        donnee_nettoyee = f"Clean-{donnee}"
        queue_sortie.put(donnee_nettoyee)
        print(f"  â†’ NettoyÃ©: {donnee_nettoyee}")

    print("ğŸ Ã‰tape 2: TerminÃ©e")

def etape_3_traitement(queue_entree, queue_sortie):
    """Ã‰tape 3: Traitement des donnÃ©es"""
    print("âš™ï¸  Ã‰tape 3: Traitement des donnÃ©es")
    while True:
        donnee = queue_entree.get()
        if donnee is None:
            queue_sortie.put(None)
            break

        time.sleep(random.uniform(0.3, 0.5))
        donnee_traitee = f"Processed-{donnee}"
        queue_sortie.put(donnee_traitee)
        print(f"  â†’ TraitÃ©: {donnee_traitee}")

    print("ğŸ Ã‰tape 3: TerminÃ©e")

def etape_4_sauvegarde(queue_entree):
    """Ã‰tape 4: Sauvegarde des rÃ©sultats"""
    print("ğŸ’¾ Ã‰tape 4: Sauvegarde des rÃ©sultats")
    resultats = []
    while True:
        donnee = queue_entree.get()
        if donnee is None:
            break

        time.sleep(random.uniform(0.1, 0.2))
        resultats.append(donnee)
        print(f"  â†’ SauvegardÃ©: {donnee}")

    print(f"ğŸ Ã‰tape 4: TerminÃ©e ({len(resultats)} items)")
    return resultats

# CrÃ©er les queues entre les Ã©tapes
q1_to_2 = queue.Queue(maxsize=5)
q2_to_3 = queue.Queue(maxsize=5)
q3_to_4 = queue.Queue(maxsize=5)

# CrÃ©er les threads pour chaque Ã©tape
threads = [
    threading.Thread(target=etape_1_collecte, args=(q1_to_2, 10)),
    threading.Thread(target=etape_2_nettoyage, args=(q1_to_2, q2_to_3)),
    threading.Thread(target=etape_3_traitement, args=(q2_to_3, q3_to_4)),
    threading.Thread(target=etape_4_sauvegarde, args=(q3_to_4,))
]

# DÃ©marrer le pipeline
print("ğŸš€ DÃ©marrage du pipeline\n")
debut = time.time()

for t in threads:
    t.start()
for t in threads:
    t.join()

duree = time.time() - debut
print(f"\nâœ… Pipeline complet en {duree:.2f}s")
```

---

## Pattern 4 : Fan-Out / Fan-In

**Fan-Out** : Une tÃ¢che distribue le travail Ã  plusieurs workers
**Fan-In** : Plusieurs workers envoient leurs rÃ©sultats Ã  un collecteur

### Analogie

Un restaurant :
- **Fan-Out** : Le chef (dispatcher) distribue les commandes Ã  plusieurs cuisiniers
- **Fan-In** : Tous les plats prÃ©parÃ©s arrivent au mÃªme serveur

### Quand l'utiliser ?

âœ… Utilisez Fan-Out/Fan-In quand :
- Une tÃ¢che peut Ãªtre divisÃ©e en sous-tÃ¢ches indÃ©pendantes
- Vous voulez parallÃ©liser puis agrÃ©ger les rÃ©sultats
- Exemple : Recherche dans plusieurs sources puis fusion

### ImplÃ©mentation

```python
import threading
import queue
import time
import random

def dispatcher(taches, queues_workers):
    """Fan-Out: Distribue les tÃ¢ches aux workers"""
    print("ğŸ“¤ Dispatcher: Distribution des tÃ¢ches")

    for i, tache in enumerate(taches):
        # Distribuer en round-robin
        worker_id = i % len(queues_workers)
        queues_workers[worker_id].put(tache)
        print(f"  â†’ TÃ¢che {tache} â†’ Worker {worker_id}")

    # Signal de fin pour tous les workers
    for q in queues_workers:
        q.put(None)

    print("ğŸ Dispatcher: TerminÃ©")

def worker(worker_id, queue_entree, queue_resultats):
    """Worker qui traite des tÃ¢ches"""
    print(f"ğŸ”§ Worker {worker_id}: DÃ©marrÃ©")

    while True:
        tache = queue_entree.get()
        if tache is None:
            break

        # Traiter la tÃ¢che
        time.sleep(random.uniform(0.5, 1.5))
        resultat = f"RÃ©sultat-{tache}-by-W{worker_id}"

        queue_resultats.put(resultat)
        print(f"  âœ… Worker {worker_id}: {tache} â†’ {resultat}")

    print(f"ğŸ Worker {worker_id}: TerminÃ©")

def collecteur(queue_resultats, nombre_taches):
    """Fan-In: Collecte tous les rÃ©sultats"""
    print("ğŸ“¥ Collecteur: En attente des rÃ©sultats")
    resultats = []

    for _ in range(nombre_taches):
        resultat = queue_resultats.get()
        resultats.append(resultat)
        print(f"  â† ReÃ§u: {resultat}")

    print(f"ğŸ Collecteur: TerminÃ© ({len(resultats)} rÃ©sultats)")
    return resultats

# Configuration
taches = [f"TÃ¢che-{i}" for i in range(12)]
nombre_workers = 4

# CrÃ©er les queues
queues_workers = [queue.Queue() for _ in range(nombre_workers)]
queue_resultats = queue.Queue()

# CrÃ©er les threads
thread_dispatcher = threading.Thread(
    target=dispatcher,
    args=(taches, queues_workers)
)

threads_workers = [
    threading.Thread(target=worker, args=(i, queues_workers[i], queue_resultats))
    for i in range(nombre_workers)
]

thread_collecteur = threading.Thread(
    target=collecteur,
    args=(queue_resultats, len(taches))
)

# DÃ©marrer
print("ğŸš€ DÃ©marrage Fan-Out/Fan-In\n")
debut = time.time()

thread_dispatcher.start()
for t in threads_workers:
    t.start()
thread_collecteur.start()

# Attendre la fin
thread_dispatcher.join()
for t in threads_workers:
    t.join()
thread_collecteur.join()

duree = time.time() - debut
print(f"\nâœ… Fan-Out/Fan-In complet en {duree:.2f}s")
```

---

## Pattern 5 : Future / Promise

Le pattern **Future** reprÃ©sente le rÃ©sultat d'une opÃ©ration asynchrone qui sera disponible dans le futur.

### Analogie

Comme un ticket de pressing :
- Vous dÃ©posez vos vÃªtements (soumission de la tÃ¢che)
- On vous donne un ticket (Future)
- Vous revenez plus tard avec le ticket pour rÃ©cupÃ©rer vos vÃªtements (rÃ©sultat)

### Quand l'utiliser ?

âœ… Utilisez Future quand :
- Vous lancez une tÃ¢che longue et voulez continuer autre chose
- Vous voulez rÃ©cupÃ©rer le rÃ©sultat plus tard
- Vous avez besoin de gÃ©rer plusieurs tÃ¢ches asynchrones

### ImplÃ©mentation avec concurrent.futures

```python
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
import random

def tache_longue(nom, duree):
    """Simule une tÃ¢che qui prend du temps"""
    print(f"ğŸ”§ DÃ©marrage: {nom}")
    time.sleep(duree)
    resultat = f"RÃ©sultat de {nom}"
    print(f"âœ… TerminÃ©: {nom}")
    return resultat

# CrÃ©er un executor
executor = ThreadPoolExecutor(max_workers=3)

# Soumettre plusieurs tÃ¢ches et obtenir des Futures
print("ğŸ“¤ Soumission des tÃ¢ches\n")
future1 = executor.submit(tache_longue, "TÃ¢che-A", 2)
future2 = executor.submit(tache_longue, "TÃ¢che-B", 1)
future3 = executor.submit(tache_longue, "TÃ¢che-C", 3)

print("ğŸ’¼ Les tÃ¢ches sont lancÃ©es, on peut faire autre chose...\n")
time.sleep(0.5)
print("ğŸ’¼ Autre travail en cours...\n")

# RÃ©cupÃ©rer les rÃ©sultats quand ils sont prÃªts
print("ğŸ“¥ RÃ©cupÃ©ration des rÃ©sultats:")
print(f"  â€¢ Future1 terminÃ©? {future1.done()}")
print(f"  â€¢ Future2 terminÃ©? {future2.done()}")

# Attendre et rÃ©cupÃ©rer les rÃ©sultats
print(f"  â€¢ RÃ©sultat 1: {future1.result()}")  # Bloque si pas encore prÃªt
print(f"  â€¢ RÃ©sultat 2: {future2.result()}")
print(f"  â€¢ RÃ©sultat 3: {future3.result()}")

executor.shutdown()
print("\nâœ… Toutes les futures rÃ©solues")
```

### Gestion d'erreurs avec Future

```python
from concurrent.futures import ThreadPoolExecutor
import time

def tache_avec_erreur(numero):
    """TÃ¢che qui peut Ã©chouer"""
    time.sleep(1)
    if numero == 3:
        raise ValueError(f"Erreur avec le numÃ©ro {numero}")
    return f"SuccÃ¨s {numero}"

with ThreadPoolExecutor(max_workers=3) as executor:
    futures = [executor.submit(tache_avec_erreur, i) for i in range(1, 6)]

    for i, future in enumerate(futures, 1):
        try:
            resultat = future.result()
            print(f"âœ… TÃ¢che {i}: {resultat}")
        except Exception as e:
            print(f"âŒ TÃ¢che {i}: Erreur - {e}")
```

### Avec as_completed() - Traiter au fur et Ã  mesure

```python
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
import random

def telecharger_fichier(url):
    """Simule le tÃ©lÃ©chargement d'un fichier"""
    duree = random.uniform(1, 4)
    time.sleep(duree)
    return f"{url} tÃ©lÃ©chargÃ© en {duree:.1f}s"

urls = [f"https://example.com/file{i}.zip" for i in range(8)]

with ThreadPoolExecutor(max_workers=4) as executor:
    # Soumettre toutes les tÃ¢ches
    futures = {executor.submit(telecharger_fichier, url): url for url in urls}

    # Traiter les rÃ©sultats au fur et Ã  mesure qu'ils arrivent
    for future in as_completed(futures):
        url = futures[future]
        try:
            resultat = future.result()
            print(f"âœ… {resultat}")
        except Exception as e:
            print(f"âŒ {url}: Erreur - {e}")
```

---

## Pattern 6 : Map-Reduce

**Map-Reduce** traite de grandes quantitÃ©s de donnÃ©es en deux phases :
1. **Map** : Transforme chaque Ã©lÃ©ment en parallÃ¨le
2. **Reduce** : AgrÃ¨ge les rÃ©sultats

### Analogie

Comptage des votes dans une Ã©lection :
- **Map** : Chaque bureau de vote compte ses bulletins
- **Reduce** : Les totaux de tous les bureaux sont additionnÃ©s

### Quand l'utiliser ?

âœ… Utilisez Map-Reduce quand :
- Vous traitez de grandes collections de donnÃ©es
- Les traitements sont indÃ©pendants (embarrassingly parallel)
- Vous avez besoin d'agrÃ©ger les rÃ©sultats

### ImplÃ©mentation simple

```python
from concurrent.futures import ProcessPoolExecutor
import time

def map_function(nombre):
    """Phase Map: Calcule le carrÃ©"""
    return nombre ** 2

def reduce_function(resultats):
    """Phase Reduce: Somme tous les carrÃ©s"""
    return sum(resultats)

# DonnÃ©es
nombres = list(range(1, 101))

# Phase Map (parallÃ¨le)
with ProcessPoolExecutor() as executor:
    debut = time.time()
    carres = list(executor.map(map_function, nombres))
    duree_map = time.time() - debut

# Phase Reduce
debut = time.time()
total = reduce_function(carres)
duree_reduce = time.time() - debut

print(f"ğŸ“Š Map-Reduce:")
print(f"  â€¢ Nombres: 1-100")
print(f"  â€¢ Somme des carrÃ©s: {total}")
print(f"  â€¢ Temps Map: {duree_map:.3f}s")
print(f"  â€¢ Temps Reduce: {duree_reduce:.3f}s")
```

### Exemple avancÃ© : Analyse de texte

```python
from concurrent.futures import ProcessPoolExecutor
from collections import Counter
import re

def compter_mots(texte):
    """Phase Map: Compte les mots dans un texte"""
    mots = re.findall(r'\w+', texte.lower())
    return Counter(mots)

def fusionner_compteurs(compteurs):
    """Phase Reduce: Fusionne tous les compteurs"""
    resultat = Counter()
    for compteur in compteurs:
        resultat.update(compteur)
    return resultat

# DonnÃ©es: plusieurs documents
documents = [
    "Python est un langage de programmation. Python est facile.",
    "La programmation est amusante. Python est populaire.",
    "Le langage Python est utilisÃ© en science des donnÃ©es.",
    "Python est un excellent langage pour dÃ©buter.",
]

# Phase Map: Compter les mots de chaque document en parallÃ¨le
with ProcessPoolExecutor() as executor:
    compteurs = list(executor.map(compter_mots, documents))

# Phase Reduce: Fusionner tous les compteurs
compteur_total = fusionner_compteurs(compteurs)

# Afficher les 5 mots les plus frÃ©quents
print("ğŸ“Š Analyse Map-Reduce:")
print("\nTop 5 des mots les plus frÃ©quents:")
for mot, compte in compteur_total.most_common(5):
    print(f"  â€¢ {mot}: {compte} fois")
```

---

## Pattern 7 : Actor Model (ModÃ¨le d'Acteur)

Le **Actor Model** encapsule l'Ã©tat et la logique dans des "acteurs" qui communiquent par messages.

### Analogie

Des employÃ©s dans une entreprise :
- Chaque acteur est un employÃ© avec sa propre boÃ®te de rÃ©ception
- Les acteurs communiquent en s'envoyant des emails (messages)
- Chaque acteur traite ses messages dans l'ordre

### Quand l'utiliser ?

âœ… Utilisez Actor Model quand :
- Vous avez besoin d'entitÃ©s avec leur propre Ã©tat
- La communication par messages est naturelle
- Vous voulez isoler les Ã©tats pour Ã©viter les race conditions

### ImplÃ©mentation simple

```python
import threading
import queue
import time
from typing import Any

class Actor:
    """Acteur simple avec sa propre queue de messages"""

    def __init__(self, nom):
        self.nom = nom
        self.queue = queue.Queue()
        self.running = True
        self.thread = threading.Thread(target=self._run)
        self.thread.start()

    def _run(self):
        """Boucle principale de l'acteur"""
        print(f"ğŸ­ {self.nom}: DÃ©marrÃ©")
        while self.running:
            try:
                message = self.queue.get(timeout=0.5)
                self._handle_message(message)
            except queue.Empty:
                continue
        print(f"ğŸ {self.nom}: ArrÃªtÃ©")

    def _handle_message(self, message):
        """Traite un message (Ã  surcharger)"""
        print(f"ğŸ“¨ {self.nom} reÃ§oit: {message}")

    def send(self, message):
        """Envoie un message Ã  cet acteur"""
        self.queue.put(message)

    def stop(self):
        """ArrÃªte l'acteur"""
        self.running = False
        self.thread.join()

# Exemple d'acteur spÃ©cialisÃ©
class CalculatorActor(Actor):
    """Acteur qui effectue des calculs"""

    def _handle_message(self, message):
        operation, a, b = message
        if operation == "add":
            resultat = a + b
            print(f"ğŸ”¢ {self.nom}: {a} + {b} = {resultat}")
        elif operation == "multiply":
            resultat = a * b
            print(f"ğŸ”¢ {self.nom}: {a} Ã— {b} = {resultat}")

class LoggerActor(Actor):
    """Acteur qui log des messages"""

    def _handle_message(self, message):
        timestamp = time.strftime("%H:%M:%S")
        print(f"ğŸ“ [{timestamp}] {message}")

# Utilisation
calculator = CalculatorActor("Calculatrice")
logger = LoggerActor("Logger")

# Envoyer des messages
logger.send("SystÃ¨me dÃ©marrÃ©")
calculator.send(("add", 5, 3))
calculator.send(("multiply", 4, 7))
logger.send("Calculs terminÃ©s")

time.sleep(2)

# ArrÃªter les acteurs
calculator.stop()
logger.stop()
```

---

## Pattern 8 : Scatter-Gather

**Scatter-Gather** envoie une requÃªte Ã  plusieurs services et collecte toutes les rÃ©ponses.

### Analogie

Comparer les prix dans plusieurs magasins :
- **Scatter** : Demander le prix Ã  tous les magasins en mÃªme temps
- **Gather** : Attendre toutes les rÃ©ponses et choisir la meilleure

### Quand l'utiliser ?

âœ… Utilisez Scatter-Gather quand :
- Vous interrogez plusieurs sources de donnÃ©es
- Vous voulez la rÃ©ponse la plus rapide ou toutes les rÃ©ponses
- Exemple : Recherche dans plusieurs APIs

### ImplÃ©mentation

```python
import asyncio
import random

async def interroger_service(nom_service, requete):
    """Interroge un service distant"""
    print(f"ğŸ“¤ RequÃªte vers {nom_service}")

    # Simuler la latence du rÃ©seau
    latence = random.uniform(0.5, 3.0)
    await asyncio.sleep(latence)

    # Simuler une rÃ©ponse
    reponse = {
        'service': nom_service,
        'resultat': f"DonnÃ©es de {nom_service}",
        'latence': latence,
        'prix': random.randint(50, 150)
    }

    print(f"ğŸ“¥ RÃ©ponse de {nom_service} ({latence:.2f}s)")
    return reponse

async def scatter_gather_all(requete, services):
    """Scatter-Gather: Attend toutes les rÃ©ponses"""
    print(f"ğŸš€ Scatter: Envoi vers {len(services)} services\n")

    # Scatter: Lancer toutes les requÃªtes en parallÃ¨le
    taches = [interroger_service(service, requete) for service in services]

    # Gather: Attendre toutes les rÃ©ponses
    reponses = await asyncio.gather(*taches)

    print(f"\nâœ… Gather: {len(reponses)} rÃ©ponses reÃ§ues")
    return reponses

async def scatter_gather_first(requete, services):
    """Retourne la premiÃ¨re rÃ©ponse"""
    print(f"ğŸš€ Scatter: Envoi vers {len(services)} services\n")

    taches = [interroger_service(service, requete) for service in services]

    # Attendre la premiÃ¨re rÃ©ponse
    done, pending = await asyncio.wait(taches, return_when=asyncio.FIRST_COMPLETED)

    # Annuler les tÃ¢ches restantes
    for tache in pending:
        tache.cancel()

    reponse = done.pop().result()
    print(f"\nâš¡ PremiÃ¨re rÃ©ponse: {reponse['service']}")
    return reponse

# Utilisation
async def main():
    services = ["ServiceA", "ServiceB", "ServiceC", "ServiceD"]
    requete = "Chercher produit XYZ"

    # StratÃ©gie 1: Attendre toutes les rÃ©ponses
    print("=== StratÃ©gie: Toutes les rÃ©ponses ===")
    reponses = await scatter_gather_all(requete, services)

    # Trouver le meilleur prix
    meilleur = min(reponses, key=lambda r: r['prix'])
    print(f"\nğŸ’° Meilleur prix: {meilleur['prix']}â‚¬ ({meilleur['service']})")

    print("\n" + "="*50 + "\n")

    # StratÃ©gie 2: PremiÃ¨re rÃ©ponse seulement
    print("=== StratÃ©gie: PremiÃ¨re rÃ©ponse ===")
    reponse = await scatter_gather_first(requete, services)
    print(f"ğŸ“¦ RÃ©sultat: {reponse['resultat']}")

asyncio.run(main())
```

---

## Pattern 9 : Rate Limiting (Limitation de dÃ©bit)

Le **Rate Limiting** contrÃ´le le nombre d'opÃ©rations par unitÃ© de temps.

### Analogie

Un barrage qui rÃ©gule le dÃ©bit d'eau :
- Trop d'eau d'un coup â†’ inondation (surcharge)
- Le barrage laisse passer un dÃ©bit contrÃ´lÃ©

### Quand l'utiliser ?

âœ… Utilisez Rate Limiting quand :
- Vous appelez une API avec des limites de requÃªtes
- Vous voulez Ã©viter de surcharger un service
- Vous devez respecter des quotas

### ImplÃ©mentation simple

```python
import asyncio
import time

class RateLimiter:
    """Limiteur de dÃ©bit simple"""

    def __init__(self, max_calls, period):
        """
        Args:
            max_calls: Nombre max d'appels
            period: PÃ©riode en secondes
        """
        self.max_calls = max_calls
        self.period = period
        self.calls = []
        self.lock = asyncio.Lock()

    async def acquire(self):
        """Acquiert le droit de faire un appel"""
        async with self.lock:
            now = time.time()

            # Nettoyer les anciens appels
            self.calls = [c for c in self.calls if now - c < self.period]

            if len(self.calls) >= self.max_calls:
                # Attendre
                sleep_time = self.period - (now - self.calls[0])
                print(f"â³ Rate limit atteint, attente de {sleep_time:.2f}s")
                await asyncio.sleep(sleep_time)
                self.calls = []

            self.calls.append(time.time())

async def appeler_api(api_id, rate_limiter):
    """Appelle une API avec rate limiting"""
    await rate_limiter.acquire()
    print(f"ğŸ“ Appel API {api_id} Ã  {time.strftime('%H:%M:%S')}")
    await asyncio.sleep(0.1)  # Simule l'appel
    return f"RÃ©sultat-{api_id}"

async def main():
    # Limite: 5 appels par 2 secondes
    rate_limiter = RateLimiter(max_calls=5, period=2.0)

    # Faire 15 appels
    taches = [appeler_api(i, rate_limiter) for i in range(15)]
    resultats = await asyncio.gather(*taches)

    print(f"\nâœ… {len(resultats)} appels effectuÃ©s avec respect du rate limit")

asyncio.run(main())
```

### ImplÃ©mentation avec Semaphore et dÃ©lai

```python
import asyncio
import time

class TokenBucket:
    """ImplÃ©mentation Token Bucket pour rate limiting"""

    def __init__(self, rate, capacity):
        self.rate = rate  # Tokens par seconde
        self.capacity = capacity
        self.tokens = capacity
        self.last_update = time.time()
        self.lock = asyncio.Lock()

    async def acquire(self, tokens=1):
        """Acquiert des tokens"""
        async with self.lock:
            await self._refill()

            while self.tokens < tokens:
                sleep_time = (tokens - self.tokens) / self.rate
                await asyncio.sleep(sleep_time)
                await self._refill()

            self.tokens -= tokens

    async def _refill(self):
        """Remplit le bucket avec de nouveaux tokens"""
        now = time.time()
        elapsed = now - self.last_update
        new_tokens = elapsed * self.rate
        self.tokens = min(self.capacity, self.tokens + new_tokens)
        self.last_update = now

async def tache_limitee(task_id, bucket):
    """TÃ¢che avec rate limiting"""
    await bucket.acquire()
    print(f"âœ… TÃ¢che {task_id} exÃ©cutÃ©e Ã  {time.strftime('%H:%M:%S')}")
    await asyncio.sleep(0.1)

async def main():
    # 3 tokens par seconde, capacitÃ© max 5
    bucket = TokenBucket(rate=3.0, capacity=5)

    taches = [tache_limitee(i, bucket) for i in range(12)]
    await asyncio.gather(*taches)

asyncio.run(main())
```

---

## Choisir le bon pattern

Voici un guide pour choisir le pattern appropriÃ© selon votre situation :

| Situation | Pattern recommandÃ© |
|-----------|-------------------|
| Produire et consommer Ã  des vitesses diffÃ©rentes | Producer-Consumer |
| Beaucoup de tÃ¢ches similaires, limiter les threads | Worker Pool |
| Plusieurs Ã©tapes sÃ©quentielles de traitement | Pipeline |
| Distribuer puis collecter des rÃ©sultats | Fan-Out/Fan-In |
| Lancer des tÃ¢ches et rÃ©cupÃ©rer rÃ©sultats plus tard | Future/Promise |
| Traiter de grandes collections de donnÃ©es | Map-Reduce |
| EntitÃ©s avec Ã©tat et communication par messages | Actor Model |
| Interroger plusieurs sources simultanÃ©ment | Scatter-Gather |
| Respecter des limites d'API | Rate Limiting |

---

## Exemple complet : SystÃ¨me de scraping web

Voici un exemple rÃ©aliste qui combine plusieurs patterns :

```python
import asyncio
import aiohttp
import time
from typing import List, Dict
from collections import Counter

class WebScraperSystem:
    """SystÃ¨me de scraping combinant plusieurs patterns"""

    def __init__(self, max_concurrent=5, rate_limit=10):
        self.semaphore = asyncio.Semaphore(max_concurrent)
        self.rate_limiter = RateLimiter(rate_limit, period=1.0)
        self.resultats = []
        self.lock = asyncio.Lock()

    async def fetch_url(self, session, url):
        """
        Fetch une URL avec rate limiting et semaphore
        Pattern: Rate Limiting + Worker Pool
        """
        async with self.semaphore:
            await self.rate_limiter.acquire()

            try:
                print(f"ğŸ“¥ TÃ©lÃ©chargement: {url}")
                await asyncio.sleep(0.5)  # Simule le tÃ©lÃ©chargement

                # Simuler le contenu
                contenu = f"Contenu simulÃ© de {url}"
                return {'url': url, 'contenu': contenu, 'status': 'success'}

            except Exception as e:
                return {'url': url, 'erreur': str(e), 'status': 'error'}

    async def extraire_donnees(self, page_data):
        """
        Extrait les donnÃ©es d'une page
        Pattern: Pipeline (Ã©tape 2)
        """
        await asyncio.sleep(0.2)  # Simule l'extraction

        # Simuler l'extraction de mots
        mots = page_data['contenu'].split()
        return {
            'url': page_data['url'],
            'mots': mots,
            'nb_mots': len(mots)
        }

    async def worker_pipeline(self, session, url):
        """
        Worker complet qui fait fetch + extraction
        Pattern: Pipeline
        """
        # Ã‰tape 1: TÃ©lÃ©charger
        page_data = await self.fetch_url(session, url)

        if page_data['status'] == 'error':
            return page_data

        # Ã‰tape 2: Extraire
        donnees_extraites = await self.extraire_donnees(page_data)

        # Stocker les rÃ©sultats
        async with self.lock:
            self.resultats.append(donnees_extraites)

        return donnees_extraites

    async def scraper_urls(self, urls: List[str]):
        """
        Scrape plusieurs URLs
        Pattern: Fan-Out/Fan-In + Worker Pool
        """
        print(f"ğŸš€ DÃ©marrage du scraping de {len(urls)} URLs")
        print(f"ğŸ“Š Config: max {self.semaphore._value} concurrent, rate limit {self.rate_limiter.max_calls}/s\n")

        debut = time.time()

        # Simuler une session HTTP
        session = None  # En vrai: aiohttp.ClientSession()

        # Fan-Out: CrÃ©er toutes les tÃ¢ches
        taches = [self.worker_pipeline(session, url) for url in urls]

        # Fan-In: Collecter tous les rÃ©sultats
        resultats = await asyncio.gather(*taches, return_exceptions=True)

        duree = time.time() - debut

        # Statistiques
        succes = sum(1 for r in resultats if isinstance(r, dict) and r.get('status') != 'error')
        echecs = len(resultats) - succes

        print(f"\nâœ… Scraping terminÃ© en {duree:.2f}s")
        print(f"ğŸ“Š RÃ©sultats: {succes} succÃ¨s, {echecs} Ã©checs")

        return resultats

    def analyser_resultats(self):
        """
        Analyse les rÃ©sultats collectÃ©s
        Pattern: Map-Reduce
        """
        print("\nğŸ“Š Analyse des rÃ©sultats (Map-Reduce):")

        # Map: Extraire tous les mots
        tous_les_mots = []
        for resultat in self.resultats:
            if 'mots' in resultat:
                tous_les_mots.extend(resultat['mots'])

        # Reduce: Compter les occurrences
        compteur = Counter(tous_les_mots)

        print(f"  â€¢ Total de mots: {len(tous_les_mots)}")
        print(f"  â€¢ Mots uniques: {len(compteur)}")
        print(f"  â€¢ Top 5 mots:")
        for mot, count in compteur.most_common(5):
            print(f"    - {mot}: {count} fois")

class RateLimiter:
    """Rate limiter simple pour l'exemple"""
    def __init__(self, max_calls, period):
        self.max_calls = max_calls
        self.period = period
        self.calls = []
        self.lock = asyncio.Lock()

    async def acquire(self):
        async with self.lock:
            now = time.time()
            self.calls = [c for c in self.calls if now - c < self.period]

            if len(self.calls) >= self.max_calls:
                sleep_time = self.period - (now - self.calls[0])
                await asyncio.sleep(sleep_time)
                self.calls = []

            self.calls.append(time.time())

async def main():
    """DÃ©monstration du systÃ¨me complet"""

    # CrÃ©er les URLs Ã  scraper
    urls = [f"https://example.com/page{i}" for i in range(20)]

    # CrÃ©er le systÃ¨me
    scraper = WebScraperSystem(max_concurrent=5, rate_limit=10)

    # Lancer le scraping
    resultats = await scraper.scraper_urls(urls)

    # Analyser les rÃ©sultats
    scraper.analyser_resultats()

if __name__ == '__main__':
    asyncio.run(main())
```

---

## Bonnes pratiques pour les patterns

### 1. Commencez simple

```python
# âœ… Bon - Commencer avec le plus simple
def traiter_donnees_simple(donnees):
    return [traiter_item(item) for item in donnees]

# Si nÃ©cessaire, ajouter la parallÃ©lisation
from concurrent.futures import ThreadPoolExecutor

def traiter_donnees_parallele(donnees):
    with ThreadPoolExecutor() as executor:
        return list(executor.map(traiter_item, donnees))
```

### 2. Mesurez avant d'optimiser

```python
import time

def mesurer_performance(fonction, *args):
    """Mesure le temps d'exÃ©cution"""
    debut = time.time()
    resultat = fonction(*args)
    duree = time.time() - debut
    print(f"â±ï¸  {fonction.__name__}: {duree:.2f}s")
    return resultat

# Comparer les approches
donnees = list(range(1000))
mesurer_performance(traiter_sequentiel, donnees)
mesurer_performance(traiter_parallele, donnees)
```

### 3. GÃ©rez les erreurs proprement

```python
async def worker_robuste(tache):
    """Worker avec gestion d'erreurs"""
    try:
        resultat = await traiter_tache(tache)
        return {'status': 'success', 'resultat': resultat}
    except Exception as e:
        return {'status': 'error', 'erreur': str(e), 'tache': tache}
```

### 4. Utilisez des timeouts

```python
import asyncio

async def avec_timeout(coroutine, timeout=10.0):
    """Ajoute un timeout Ã  une coroutine"""
    try:
        return await asyncio.wait_for(coroutine, timeout=timeout)
    except asyncio.TimeoutError:
        print(f"â±ï¸  Timeout aprÃ¨s {timeout}s")
        return None
```

### 5. Limitez la concurrence

```python
# âœ… Bon - Limiter la concurrence
semaphore = asyncio.Semaphore(10)

async def tache_limitee():
    async with semaphore:
        await traiter()

# âŒ Mauvais - Concurrence illimitÃ©e
# Peut crÃ©er des milliers de connexions
for i in range(10000):
    asyncio.create_task(traiter())
```

---

## RÃ©sumÃ© des patterns

| Pattern | ComplexitÃ© | Performance | Cas d'usage typique |
|---------|-----------|-------------|-------------------|
| Producer-Consumer | â­â­ | âœ…âœ… | DÃ©coupler production/consommation |
| Worker Pool | â­ | âœ…âœ… | Traiter beaucoup de tÃ¢ches similaires |
| Pipeline | â­â­â­ | âœ…âœ…âœ… | Traitement en plusieurs Ã©tapes |
| Fan-Out/Fan-In | â­â­ | âœ…âœ…âœ… | Distribuer et collecter |
| Future/Promise | â­ | âœ…âœ… | RÃ©sultats asynchrones |
| Map-Reduce | â­â­ | âœ…âœ…âœ… | Traitement de grandes donnÃ©es |
| Actor Model | â­â­â­ | âœ…âœ… | EntitÃ©s avec Ã©tat isolÃ© |
| Scatter-Gather | â­â­ | âœ…âœ… | Interroger plusieurs sources |
| Rate Limiting | â­â­ | âœ… | Respecter quotas API |

---

## Points clÃ©s Ã  retenir

1. **Choisir le bon pattern** selon le problÃ¨me spÃ©cifique
2. **Commencer simple** puis optimiser si nÃ©cessaire
3. **Mesurer les performances** avant et aprÃ¨s
4. **GÃ©rer les erreurs** dans tous les workers
5. **Limiter la concurrence** pour Ã©viter les surcharges
6. **Utiliser des timeouts** pour Ã©viter les blocages
7. **Documenter** quel pattern vous utilisez et pourquoi
8. **Combiner les patterns** quand c'est appropriÃ©

---

## Ressources et prochaines Ã©tapes

**Pour aller plus loin** :
- Explorez `asyncio` pour des patterns asynchrones
- Ã‰tudiez `concurrent.futures` pour des abstractions de haut niveau
- Regardez les frameworks : Celery (tÃ¢ches distribuÃ©es), Ray (calcul distribuÃ©)
- Apprenez les queues distribuÃ©es : RabbitMQ, Redis

**Chapitres liÃ©s** :
- 8.1 Threading et Multiprocessing (bases de la concurrence)
- 8.2 Programmation asynchrone avec asyncio
- 8.3 Gestion des verrous et synchronisation

---

## Conclusion

Les patterns de concurrence sont des outils puissants qui, une fois maÃ®trisÃ©s, vous permettront de construire des systÃ¨mes performants et robustes. Commencez par les patterns simples comme Worker Pool et Producer-Consumer, puis progressez vers des patterns plus avancÃ©s selon vos besoins.

**RÃ¨gle d'or** : Toujours privilÃ©gier la simplicitÃ© et la clartÃ© du code, sauf si les mesures de performance justifient l'ajout de complexitÃ©.

â­ï¸ [Gestion des erreurs et dÃ©bogage](/09-erreurs-et-debogage/README.md)
