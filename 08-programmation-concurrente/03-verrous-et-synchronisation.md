üîù Retour au [Sommaire](/SOMMAIRE.md)

# 8.3 Gestion des Verrous et Synchronisation

## Introduction √† la synchronisation

Quand plusieurs threads ou processus travaillent ensemble, ils doivent parfois se **coordonner** pour √©viter des probl√®mes. C'est ce qu'on appelle la **synchronisation**.

### Pourquoi synchroniser ?

Imaginez une banque avec plusieurs guichets qui acc√®dent au m√™me compte bancaire :

**Sans synchronisation** :
1. Guichet A lit le solde : 1000‚Ç¨
2. Guichet B lit le solde : 1000‚Ç¨
3. Guichet A retire 100‚Ç¨ et √©crit : 900‚Ç¨
4. Guichet B retire 200‚Ç¨ et √©crit : 800‚Ç¨

**R√©sultat** : Le solde est 800‚Ç¨ mais devrait √™tre 700‚Ç¨ ! üò±

**Avec synchronisation** :
1. Guichet A **verrouille** le compte
2. Guichet A lit : 1000‚Ç¨, retire 100‚Ç¨, √©crit : 900‚Ç¨
3. Guichet A **d√©verrouille**
4. Guichet B **verrouille** le compte
5. Guichet B lit : 900‚Ç¨, retire 200‚Ç¨, √©crit : 700‚Ç¨
6. Guichet B **d√©verrouille**

**R√©sultat** : Le solde est correct : 700‚Ç¨ ‚úÖ

---

## Les probl√®mes de concurrence

### Race Condition (Condition de course)

Une **race condition** se produit quand le r√©sultat d√©pend de l'ordre d'ex√©cution des threads.

```python
import threading

compteur = 0

def incrementer():
    global compteur
    for _ in range(100000):
        # Cette op√©ration n'est pas atomique!
        compteur += 1  # Lecture, addition, √©criture

# Sans synchronisation
threads = [threading.Thread(target=incrementer) for _ in range(5)]
for t in threads:
    t.start()
for t in threads:
    t.join()

print(f"Compteur: {compteur}")  # R√©sultat impr√©visible!
# Devrait √™tre 500000, mais sera probablement moins
```

**R√©sultat typique** : `Compteur: 347823` (au lieu de 500000)

### Deadlock (Interblocage)

Un **deadlock** se produit quand deux threads attendent chacun une ressource d√©tenue par l'autre.

**Analogie** : Deux personnes veulent passer une porte √©troite, chacune attend que l'autre recule.

```python
import threading
import time

verrou_a = threading.Lock()
verrou_b = threading.Lock()

def thread1():
    with verrou_a:
        print("Thread 1: verrou A acquis")
        time.sleep(0.1)
        with verrou_b:  # Attend verrou B
            print("Thread 1: verrou B acquis")

def thread2():
    with verrou_b:
        print("Thread 2: verrou B acquis")
        time.sleep(0.1)
        with verrou_a:  # Attend verrou A
            print("Thread 2: verrou A acquis")

# Les deux threads se bloquent mutuellement! ‚ö†Ô∏è
```

---

## Les m√©canismes de synchronisation

Python propose plusieurs outils pour synchroniser les threads et les coroutines :

| M√©canisme | Usage | Threading | Asyncio |
|-----------|-------|-----------|---------|
| **Lock** | Acc√®s exclusif √† une ressource | ‚úÖ | ‚úÖ |
| **RLock** | Lock r√©entrant (m√™me thread) | ‚úÖ | ‚ùå |
| **Semaphore** | Limiter le nombre d'acc√®s | ‚úÖ | ‚úÖ |
| **Event** | Signaler un √©v√©nement | ‚úÖ | ‚úÖ |
| **Condition** | Attendre une condition | ‚úÖ | ‚úÖ |
| **Barrier** | Synchroniser plusieurs threads | ‚úÖ | ‚ùå |

---

## Lock (Verrou simple)

Le **Lock** est le m√©canisme de synchronisation le plus basique. Il garantit qu'un seul thread √† la fois peut ex√©cuter une section de code.

### Avec Threading

```python
import threading
import time

compteur = 0
verrou = threading.Lock()  # Cr√©er un verrou

def incrementer_avec_lock():
    global compteur
    for _ in range(100000):
        with verrou:  # Acqu√©rir le verrou
            compteur += 1
        # Le verrou est automatiquement lib√©r√©

# Avec synchronisation
threads = [threading.Thread(target=incrementer_avec_lock) for _ in range(5)]
for t in threads:
    t.start()
for t in threads:
    t.join()

print(f"Compteur avec lock: {compteur}")  # Toujours 500000 ‚úÖ
```

### Syntaxe alternative (moins recommand√©e)

```python
verrou = threading.Lock()

def incrementer_manuel():
    global compteur
    verrou.acquire()  # Acqu√©rir manuellement
    try:
        compteur += 1
    finally:
        verrou.release()  # Toujours lib√©rer!
```

**Recommandation** : Utilisez toujours `with verrou:` pour √©viter d'oublier de lib√©rer.

### Exemple pratique : Gestion de fichier partag√©

```python
import threading
import time

class GestionnaireFichier:
    """G√®re l'√©criture dans un fichier par plusieurs threads"""

    def __init__(self, nom_fichier):
        self.nom_fichier = nom_fichier
        self.verrou = threading.Lock()

    def ecrire(self, message, thread_id):
        """√âcrit dans le fichier de mani√®re s√©curis√©e"""
        with self.verrou:
            # Section critique prot√©g√©e
            print(f"[Thread {thread_id}] √âcriture en cours...")
            with open(self.nom_fichier, 'a') as f:
                f.write(f"{message}\n")
            time.sleep(0.1)  # Simule une op√©ration lente
            print(f"[Thread {thread_id}] √âcriture termin√©e")

def worker(gestionnaire, thread_id):
    """Thread qui √©crit dans le fichier"""
    for i in range(3):
        gestionnaire.ecrire(f"Message {i} du thread {thread_id}", thread_id)

# Utilisation
gestionnaire = GestionnaireFichier("log.txt")
threads = [threading.Thread(target=worker, args=(gestionnaire, i)) for i in range(3)]

for t in threads:
    t.start()
for t in threads:
    t.join()

print("‚úÖ Toutes les √©critures sont termin√©es")
```

### Avec Asyncio

```python
import asyncio

compteur = 0
verrou = asyncio.Lock()  # Verrou asynchrone

async def incrementer_async():
    global compteur
    for _ in range(100000):
        async with verrou:  # async with pour asyncio
            compteur += 1

async def main():
    # Cr√©er plusieurs t√¢ches
    taches = [incrementer_async() for _ in range(5)]
    await asyncio.gather(*taches)
    print(f"Compteur avec asyncio.Lock: {compteur}")

asyncio.run(main())
```

---

## RLock (Verrou R√©entrant)

Un **RLock** (Reentrant Lock) peut √™tre acquis plusieurs fois par le **m√™me thread** sans se bloquer.

### Quand utiliser RLock ?

Utilisez RLock quand une fonction qui utilise un verrou peut appeler une autre fonction qui utilise le m√™me verrou.

```python
import threading

class CompteBancaire:
    """Compte bancaire avec m√©thodes synchronis√©es"""

    def __init__(self, solde):
        self.solde = solde
        self.verrou = threading.RLock()  # RLock au lieu de Lock

    def retirer(self, montant):
        """Retire de l'argent"""
        with self.verrou:
            if self.solde >= montant:
                self.solde -= montant
                return True
            return False

    def transferer(self, autre_compte, montant):
        """Transf√®re vers un autre compte"""
        with self.verrou:  # Premier lock
            if self.retirer(montant):  # Appelle retirer qui utilise aussi le lock!
                autre_compte.deposer(montant)
                return True
            return False

    def deposer(self, montant):
        """D√©pose de l'argent"""
        with self.verrou:
            self.solde += montant

# Utilisation
compte1 = CompteBancaire(1000)
compte2 = CompteBancaire(500)

# Sans RLock, ceci causerait un deadlock car transferer()
# et retirer() tentent d'acqu√©rir le m√™me lock
compte1.transferer(compte2, 200)
print(f"Compte 1: {compte1.solde}‚Ç¨")  # 800‚Ç¨
print(f"Compte 2: {compte2.solde}‚Ç¨")  # 700‚Ç¨
```

**Avec un Lock normal**, `transferer()` se serait bloqu√© en essayant d'acqu√©rir le lock une deuxi√®me fois.

---

## Semaphore (S√©maphore)

Un **Semaphore** limite le nombre de threads qui peuvent acc√©der simultan√©ment √† une ressource.

**Analogie** : Un parking avec 5 places. Quand il est plein, les voitures attendent qu'une place se lib√®re.

### Avec Threading

```python
import threading
import time
import random

# S√©maphore qui autorise max 3 threads simultan√©s
semaphore = threading.Semaphore(3)

def acceder_ressource(thread_id):
    """Acc√®de √† une ressource limit√©e"""
    print(f"[Thread {thread_id}] Attend l'acc√®s...")

    with semaphore:
        print(f"[Thread {thread_id}] üü¢ Acc√®s obtenu")
        duree = random.uniform(1, 3)
        time.sleep(duree)  # Utilise la ressource
        print(f"[Thread {thread_id}] üî¥ Lib√®re l'acc√®s")

# Cr√©er 10 threads mais max 3 peuvent acc√©der en m√™me temps
threads = [threading.Thread(target=acceder_ressource, args=(i,)) for i in range(10)]

for t in threads:
    t.start()
for t in threads:
    t.join()

print("‚úÖ Tous les threads ont termin√©")
```

### Exemple pratique : Pool de connexions

```python
import threading
import time

class PoolConnexions:
    """G√®re un pool limit√© de connexions √† une base de donn√©es"""

    def __init__(self, max_connexions):
        self.semaphore = threading.Semaphore(max_connexions)
        self.connexions_actives = 0
        self.verrou_compteur = threading.Lock()

    def executer_requete(self, requete, thread_id):
        """Ex√©cute une requ√™te avec une connexion du pool"""
        print(f"[Thread {thread_id}] Demande de connexion...")

        with self.semaphore:
            # Obtenir une connexion (max atteint = attendre)
            with self.verrou_compteur:
                self.connexions_actives += 1
                print(f"[Thread {thread_id}] ‚úÖ Connexion obtenue ({self.connexions_actives} actives)")

            # Ex√©cuter la requ√™te
            print(f"[Thread {thread_id}] Ex√©cution: {requete}")
            time.sleep(2)  # Simule le temps de la requ√™te

            # Lib√©rer la connexion
            with self.verrou_compteur:
                self.connexions_actives -= 1
                print(f"[Thread {thread_id}] üî¥ Connexion lib√©r√©e ({self.connexions_actives} actives)")

# Pool avec maximum 3 connexions
pool = PoolConnexions(max_connexions=3)

def worker(thread_id):
    """Thread qui ex√©cute une requ√™te"""
    pool.executer_requete(f"SELECT * FROM table WHERE id={thread_id}", thread_id)

# 8 threads veulent acc√©der, mais max 3 en m√™me temps
threads = [threading.Thread(target=worker, args=(i,)) for i in range(8)]

for t in threads:
    t.start()
for t in threads:
    t.join()

print("‚úÖ Toutes les requ√™tes sont termin√©es")
```

### Avec Asyncio

```python
import asyncio
import random

async def tache_limitee(semaphore, numero):
    """T√¢che qui utilise un s√©maphore"""
    async with semaphore:
        print(f"[T√¢che {numero}] D√©marrage")
        await asyncio.sleep(random.uniform(1, 2))
        print(f"[T√¢che {numero}] Termin√©e")

async def main():
    # Maximum 3 t√¢ches simultan√©es
    semaphore = asyncio.Semaphore(3)

    # Cr√©er 10 t√¢ches
    taches = [tache_limitee(semaphore, i) for i in range(10)]
    await asyncio.gather(*taches)

asyncio.run(main())
```

---

## Event (√âv√©nement)

Un **Event** permet √† un thread d'attendre qu'un √©v√©nement se produise, signal√© par un autre thread.

**Analogie** : Un feu de signalisation. Les threads attendent que le feu passe au vert.

### Avec Threading

```python
import threading
import time

# Cr√©er un √©v√©nement
event = threading.Event()

def attendre_signal(thread_id):
    """Thread qui attend un signal"""
    print(f"[Thread {thread_id}] En attente du signal...")
    event.wait()  # Bloque jusqu'√† ce que l'event soit set
    print(f"[Thread {thread_id}] üü¢ Signal re√ßu! D√©marrage du travail")
    time.sleep(1)
    print(f"[Thread {thread_id}] Travail termin√©")

def envoyer_signal():
    """Thread qui envoie le signal"""
    print("[Contr√¥leur] Pr√©paration...")
    time.sleep(3)  # Simule une pr√©paration
    print("[Contr√¥leur] üì¢ Envoi du signal!")
    event.set()  # D√©clenche l'√©v√©nement

# Cr√©er les threads
workers = [threading.Thread(target=attendre_signal, args=(i,)) for i in range(3)]
controleur = threading.Thread(target=envoyer_signal)

# D√©marrer tous les threads
for w in workers:
    w.start()
controleur.start()

# Attendre la fin
for w in workers:
    w.join()
controleur.join()

print("‚úÖ Tous les threads ont termin√©")
```

### Exemple pratique : Syst√®me de t√©l√©chargement

```python
import threading
import time

class GestionnaireTelechargement:
    """G√®re le t√©l√©chargement et le traitement de fichiers"""

    def __init__(self):
        self.fichier_pret = threading.Event()
        self.fichier = None

    def telecharger(self):
        """T√©l√©charge un fichier"""
        print("üì• T√©l√©chargement en cours...")
        time.sleep(3)  # Simule le t√©l√©chargement

        self.fichier = "data.csv"
        print(f"‚úÖ T√©l√©chargement termin√©: {self.fichier}")

        # Signaler que le fichier est pr√™t
        self.fichier_pret.set()

    def traiter(self, traitement_id):
        """Attend le fichier puis le traite"""
        print(f"[Traitement {traitement_id}] En attente du fichier...")

        # Attendre que le fichier soit t√©l√©charg√©
        self.fichier_pret.wait()

        print(f"[Traitement {traitement_id}] üîß Traitement de {self.fichier}")
        time.sleep(2)
        print(f"[Traitement {traitement_id}] ‚úÖ Traitement termin√©")

# Utilisation
gestionnaire = GestionnaireTelechargement()

# Thread de t√©l√©chargement
thread_download = threading.Thread(target=gestionnaire.telecharger)

# Threads de traitement (attendent le t√©l√©chargement)
threads_traitement = [
    threading.Thread(target=gestionnaire.traiter, args=(i,))
    for i in range(3)
]

# D√©marrer tous les threads
thread_download.start()
for t in threads_traitement:
    t.start()

# Attendre la fin
thread_download.join()
for t in threads_traitement:
    t.join()

print("‚úÖ Pipeline complet termin√©")
```

### M√©thodes d'Event

| M√©thode | Description |
|---------|-------------|
| `set()` | Active l'√©v√©nement (feu vert) |
| `clear()` | D√©sactive l'√©v√©nement (feu rouge) |
| `wait(timeout)` | Attend l'√©v√©nement (bloque jusqu'√† set()) |
| `is_set()` | V√©rifie si l'√©v√©nement est actif |

### Avec Asyncio

```python
import asyncio

async def attendre_async(event, numero):
    """Attend un √©v√©nement asynchrone"""
    print(f"[T√¢che {numero}] En attente...")
    await event.wait()
    print(f"[T√¢che {numero}] üü¢ √âv√©nement re√ßu!")

async def declencher_async(event):
    """D√©clenche l'√©v√©nement apr√®s un d√©lai"""
    await asyncio.sleep(2)
    print("üì¢ D√©clenchement de l'√©v√©nement!")
    event.set()

async def main():
    event = asyncio.Event()

    # Cr√©er les t√¢ches
    taches = [attendre_async(event, i) for i in range(3)]
    taches.append(declencher_async(event))

    await asyncio.gather(*taches)

asyncio.run(main())
```

---

## Condition (Variable conditionnelle)

Une **Condition** permet d'attendre qu'une condition sp√©cifique soit vraie.

**Analogie** : Une salle d'attente o√π les patients attendent que leur nom soit appel√©.

### Avec Threading

```python
import threading
import time
import random

class BufferPartage:
    """Buffer partag√© avec producteur/consommateur"""

    def __init__(self, taille_max=5):
        self.buffer = []
        self.taille_max = taille_max
        self.condition = threading.Condition()

    def produire(self, item):
        """Ajoute un item au buffer"""
        with self.condition:
            # Attendre que le buffer ne soit pas plein
            while len(self.buffer) >= self.taille_max:
                print(f"üì¶ Buffer plein, producteur attend...")
                self.condition.wait()

            self.buffer.append(item)
            print(f"‚úÖ Produit: {item} (buffer: {len(self.buffer)})")

            # Notifier les consommateurs
            self.condition.notify()

    def consommer(self):
        """Retire un item du buffer"""
        with self.condition:
            # Attendre que le buffer ne soit pas vide
            while len(self.buffer) == 0:
                print(f"üì≠ Buffer vide, consommateur attend...")
                self.condition.wait()

            item = self.buffer.pop(0)
            print(f"üîß Consomm√©: {item} (buffer: {len(self.buffer)})")

            # Notifier les producteurs
            self.condition.notify()

            return item

def producteur(buffer, nombre_items):
    """Produit des items"""
    for i in range(nombre_items):
        time.sleep(random.uniform(0.1, 0.5))
        buffer.produire(f"Item-{i}")

def consommateur(buffer, nombre_items):
    """Consomme des items"""
    for _ in range(nombre_items):
        time.sleep(random.uniform(0.2, 0.8))
        buffer.consommer()

# Utilisation
buffer = BufferPartage(taille_max=3)

# 2 producteurs, 2 consommateurs
prod1 = threading.Thread(target=producteur, args=(buffer, 5))
prod2 = threading.Thread(target=producteur, args=(buffer, 5))
cons1 = threading.Thread(target=consommateur, args=(buffer, 5))
cons2 = threading.Thread(target=consommateur, args=(buffer, 5))

prod1.start()
prod2.start()
cons1.start()
cons2.start()

prod1.join()
prod2.join()
cons1.join()
cons2.join()

print("‚úÖ Production/consommation termin√©e")
```

### M√©thodes de Condition

| M√©thode | Description |
|---------|-------------|
| `wait()` | Lib√®re le lock et attend une notification |
| `notify()` | R√©veille un thread en attente |
| `notify_all()` | R√©veille tous les threads en attente |

---

## Barrier (Barri√®re)

Une **Barrier** synchronise plusieurs threads pour qu'ils atteignent un point en m√™me temps.

**Analogie** : Une course o√π tous les coureurs doivent attendre que tout le monde soit pr√™t avant le d√©part.

### Avec Threading

```python
import threading
import time
import random

def travailleur(barrier, thread_id):
    """Thread qui travaille puis attend les autres"""
    # Phase 1: Pr√©paration
    duree = random.uniform(1, 3)
    print(f"[Thread {thread_id}] Pr√©paration pendant {duree:.1f}s...")
    time.sleep(duree)
    print(f"[Thread {thread_id}] ‚úÖ Pr√©paration termin√©e, attente des autres...")

    # Attendre que tous les threads soient pr√™ts
    barrier.wait()

    # Phase 2: Ex√©cution synchrone
    print(f"[Thread {thread_id}] üöÄ D√©marrage synchronis√©!")
    time.sleep(1)
    print(f"[Thread {thread_id}] ‚úÖ Travail termin√©")

# Cr√©er une barri√®re pour 5 threads
barrier = threading.Barrier(5)

threads = [threading.Thread(target=travailleur, args=(barrier, i)) for i in range(5)]

for t in threads:
    t.start()
for t in threads:
    t.join()

print("‚úÖ Tous les threads ont termin√© de mani√®re synchronis√©e")
```

### Exemple pratique : Simulation parall√®le

```python
import threading
import time

class SimulationParallele:
    """Simule un syst√®me avec plusieurs composants synchronis√©s"""

    def __init__(self, nombre_composants):
        self.barrier = threading.Barrier(nombre_composants)
        self.iteration = 0

    def composant(self, nom, nombre_iterations):
        """Simule un composant"""
        for i in range(nombre_iterations):
            # Calculer l'√©tat du composant
            print(f"[{nom}] Calcul it√©ration {i+1}...")
            time.sleep(0.5)

            # Attendre que tous les composants finissent l'it√©ration
            print(f"[{nom}] Attente synchronisation...")
            self.barrier.wait()

            # Tous les composants sont synchronis√©s
            if threading.current_thread().name == "Thread-1":
                self.iteration += 1
                print(f"\nüîÑ === It√©ration {self.iteration} termin√©e ===\n")

# Simulation avec 3 composants
sim = SimulationParallele(3)

threads = [
    threading.Thread(target=sim.composant, args=(f"Composant-{i}", 3), name=f"Thread-{i}")
    for i in range(3)
]

for t in threads:
    t.start()
for t in threads:
    t.join()

print("‚úÖ Simulation termin√©e")
```

---

## Comparaison Threading vs Asyncio

### Synchronisation en Threading

```python
import threading
import time

verrou = threading.Lock()
compteur = 0

def incrementer_threading():
    global compteur
    for _ in range(10000):
        with verrou:
            compteur += 1

threads = [threading.Thread(target=incrementer_threading) for _ in range(5)]
debut = time.time()

for t in threads:
    t.start()
for t in threads:
    t.join()

print(f"Threading: {compteur} en {time.time() - debut:.2f}s")
```

### Synchronisation en Asyncio

```python
import asyncio

verrou_async = asyncio.Lock()
compteur_async = 0

async def incrementer_asyncio():
    global compteur_async
    for _ in range(10000):
        async with verrou_async:
            compteur_async += 1

async def main():
    debut = time.time()

    taches = [incrementer_asyncio() for _ in range(5)]
    await asyncio.gather(*taches)

    print(f"Asyncio: {compteur_async} en {time.time() - debut:.2f}s")

asyncio.run(main())
```

### Tableau comparatif

| M√©canisme | Threading | Asyncio |
|-----------|-----------|---------|
| **Lock** | `threading.Lock()` | `asyncio.Lock()` |
| **Semaphore** | `threading.Semaphore(n)` | `asyncio.Semaphore(n)` |
| **Event** | `threading.Event()` | `asyncio.Event()` |
| **Condition** | `threading.Condition()` | `asyncio.Condition()` |
| **Syntaxe** | `with lock:` | `async with lock:` |
| **Attente** | `event.wait()` | `await event.wait()` |

---

## Bonnes pratiques

### 1. Toujours utiliser des gestionnaires de contexte

```python
# ‚úÖ Bon - lib√©ration automatique
with verrou:
    # Section critique
    pass

# ‚ùå Mauvais - risque d'oublier release()
verrou.acquire()
# Section critique
verrou.release()
```

### 2. Limiter la taille des sections critiques

```python
# ‚úÖ Bon - section critique minimale
def traiter_donnees():
    # Travail sans lock
    resultat = calcul_complexe()

    # Lock uniquement pour la modification
    with verrou:
        donnees_partagees.append(resultat)

# ‚ùå Mauvais - section critique trop large
def traiter_donnees_mauvais():
    with verrou:
        # Tout est lock√©, m√™me le calcul
        resultat = calcul_complexe()
        donnees_partagees.append(resultat)
```

### 3. Ordre d'acquisition coh√©rent pour √©viter les deadlocks

```python
# D√©finir un ordre fixe pour les locks
def transfert_securise(compte_a, compte_b, montant):
    """Transfert sans risque de deadlock"""
    # Toujours acqu√©rir les locks dans le m√™me ordre
    premier = min(compte_a, compte_b, key=id)
    second = max(compte_a, compte_b, key=id)

    with premier.verrou:
        with second.verrou:
            if compte_a.solde >= montant:
                compte_a.solde -= montant
                compte_b.solde += montant
```

### 4. Utiliser des timeout

```python
import threading

verrou = threading.Lock()

def tentative_avec_timeout():
    """Essaie d'acqu√©rir avec timeout"""
    if verrou.acquire(timeout=5.0):
        try:
            # Section critique
            pass
        finally:
            verrou.release()
    else:
        print("‚ùå Impossible d'acqu√©rir le verrou dans le d√©lai")
```

### 5. Documenter les invariants

```python
class CompteBancaire:
    """Compte bancaire thread-safe

    Invariant: self.solde >= 0 toujours maintenu sous le verrou
    """

    def __init__(self, solde):
        self.solde = solde
        self.verrou = threading.Lock()

    def retirer(self, montant):
        """Retire de l'argent (thread-safe)"""
        with self.verrou:
            # L'invariant est v√©rifi√© sous le verrou
            if self.solde >= montant:
                self.solde -= montant
                return True
            return False
```

---

## Erreurs courantes et solutions

### Erreur 1 : Oublier de lib√©rer un verrou

```python
# ‚ùå Probl√®me
verrou = threading.Lock()

def mauvaise_fonction():
    verrou.acquire()
    if condition_erreur:
        return  # Verrou jamais lib√©r√©!
    verrou.release()

# ‚úÖ Solution
def bonne_fonction():
    with verrou:
        if condition_erreur:
            return  # Verrou automatiquement lib√©r√©
```

### Erreur 2 : Deadlock par ordre d'acquisition

```python
# ‚ùå Probl√®me - deadlock possible
def thread_1():
    with lock_a:
        with lock_b:
            pass

def thread_2():
    with lock_b:  # Ordre diff√©rent!
        with lock_a:
            pass

# ‚úÖ Solution - ordre coh√©rent
def thread_1():
    with lock_a:
        with lock_b:
            pass

def thread_2():
    with lock_a:  # M√™me ordre
        with lock_b:
            pass
```

### Erreur 3 : Race condition subtile

```python
# ‚ùå Probl√®me
if len(liste_partagee) > 0:  # Check sans lock
    with verrou:
        element = liste_partagee.pop()  # Peut √©chouer!

# ‚úÖ Solution
with verrou:
    if len(liste_partagee) > 0:  # Check sous le lock
        element = liste_partagee.pop()
```

### Erreur 4 : Utiliser Lock au lieu de RLock

```python
# ‚ùå Probl√®me avec Lock
class Compteur:
    def __init__(self):
        self.valeur = 0
        self.verrou = threading.Lock()

    def incrementer(self):
        with self.verrou:
            self.valeur += 1

    def incrementer_deux_fois(self):
        with self.verrou:
            self.incrementer()  # Deadlock! Tente d'acqu√©rir le lock 2x
            self.incrementer()

# ‚úÖ Solution avec RLock
class Compteur:
    def __init__(self):
        self.valeur = 0
        self.verrou = threading.RLock()  # RLock au lieu de Lock

    def incrementer(self):
        with self.verrou:
            self.valeur += 1

    def incrementer_deux_fois(self):
        with self.verrou:
            self.incrementer()  # OK avec RLock
            self.incrementer()
```

---

## Exemple complet : Syst√®me de cache thread-safe

```python
import threading
import time
from typing import Any, Optional

class CacheThreadSafe:
    """Cache thread-safe avec expiration automatique"""

    def __init__(self, duree_vie: int = 60):
        self.cache = {}  # {cl√©: (valeur, timestamp)}
        self.duree_vie = duree_vie
        self.verrou = threading.RLock()
        self.stats = {'hits': 0, 'misses': 0, 'expirations': 0}
        self.verrou_stats = threading.Lock()

    def get(self, cle: str) -> Optional[Any]:
        """R√©cup√®re une valeur du cache"""
        with self.verrou:
            if cle not in self.cache:
                self._incrementer_stat('misses')
                return None

            valeur, timestamp = self.cache[cle]

            # V√©rifier l'expiration
            if time.time() - timestamp > self.duree_vie:
                del self.cache[cle]
                self._incrementer_stat('expirations')
                self._incrementer_stat('misses')
                return None

            self._incrementer_stat('hits')
            return valeur

    def set(self, cle: str, valeur: Any):
        """Ajoute une valeur au cache"""
        with self.verrou:
            self.cache[cle] = (valeur, time.time())

    def clear(self):
        """Vide le cache"""
        with self.verrou:
            self.cache.clear()

    def get_stats(self) -> dict:
        """R√©cup√®re les statistiques"""
        with self.verrou_stats:
            return self.stats.copy()

    def _incrementer_stat(self, stat: str):
        """Incr√©mente une statistique (thread-safe)"""
        with self.verrou_stats:
            self.stats[stat] += 1

    def nettoyer_expires(self):
        """Nettoie les entr√©es expir√©es"""
        with self.verrou:
            cles_a_supprimer = []
            temps_actuel = time.time()

            for cle, (_, timestamp) in self.cache.items():
                if temps_actuel - timestamp > self.duree_vie:
                    cles_a_supprimer.append(cle)

            for cle in cles_a_supprimer:
                del self.cache[cle]

            return len(cles_a_supprimer)

def travailleur_cache(cache, worker_id, operations):
    """Thread qui utilise le cache"""
    for i in range(operations):
        cle = f"data_{i % 10}"  # 10 cl√©s diff√©rentes

        # Tenter de r√©cup√©rer
        valeur = cache.get(cle)

        if valeur is None:
            # Cache miss - calculer et stocker
            valeur = f"R√©sultat_calcul√©_par_{worker_id}_{i}"
            cache.set(cle, valeur)
            print(f"[Worker {worker_id}] Miss - Calcul√©: {cle}")
        else:
            print(f"[Worker {worker_id}] Hit - Trouv√©: {cle}")

        time.sleep(0.1)

# Utilisation
cache = CacheThreadSafe(duree_vie=5)

# Cr√©er plusieurs workers
threads = [
    threading.Thread(target=travailleur_cache, args=(cache, i, 20))
    for i in range(3)
]

print("üöÄ D√©marrage des workers")
debut = time.time()

for t in threads:
    t.start()
for t in threads:
    t.join()

duree = time.time() - debut

# Afficher les statistiques
stats = cache.get_stats()
print(f"\nüìä Statistiques finales:")
print(f"  ‚Ä¢ Hits: {stats['hits']}")
print(f"  ‚Ä¢ Misses: {stats['misses']}")
print(f"  ‚Ä¢ Expirations: {stats['expirations']}")
print(f"  ‚Ä¢ Taux de hit: {stats['hits']/(stats['hits']+stats['misses'])*100:.1f}%")
print(f"  ‚Ä¢ Dur√©e totale: {duree:.2f}s")
```

---

## Patterns avanc√©s

### Pattern 1 : Double-checked locking

```python
import threading

class Singleton:
    """Singleton thread-safe avec double-checked locking"""

    _instance = None
    _lock = threading.Lock()

    def __new__(cls):
        # Premier check sans lock (rapide)
        if cls._instance is None:
            # Second check avec lock (s√ªr)
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance
```

### Pattern 2 : Read-Write Lock

```python
import threading

class ReadWriteLock:
    """Lock optimis√© pour lectures multiples, √©criture exclusive"""

    def __init__(self):
        self.lecteurs = 0
        self.verrou_lecteurs = threading.Lock()
        self.verrou_ecrivain = threading.Lock()

    def acquire_read(self):
        """Acquiert en lecture (partageable)"""
        with self.verrou_lecteurs:
            self.lecteurs += 1
            if self.lecteurs == 1:
                self.verrou_ecrivain.acquire()

    def release_read(self):
        """Lib√®re la lecture"""
        with self.verrou_lecteurs:
            self.lecteurs -= 1
            if self.lecteurs == 0:
                self.verrou_ecrivain.release()

    def acquire_write(self):
        """Acquiert en √©criture (exclusif)"""
        self.verrou_ecrivain.acquire()

    def release_write(self):
        """Lib√®re l'√©criture"""
        self.verrou_ecrivain.release()

# Utilisation
rwlock = ReadWriteLock()

def lecteur(donnees, reader_id):
    """Lit les donn√©es (plusieurs lecteurs ok)"""
    rwlock.acquire_read()
    try:
        print(f"[Lecteur {reader_id}] Lecture: {donnees}")
        time.sleep(0.5)
    finally:
        rwlock.release_read()

def ecrivain(donnees, writer_id, nouvelle_valeur):
    """√âcrit les donn√©es (exclusif)"""
    rwlock.acquire_write()
    try:
        print(f"[√âcrivain {writer_id}] √âcriture: {nouvelle_valeur}")
        donnees.clear()
        donnees.append(nouvelle_valeur)
        time.sleep(1)
    finally:
        rwlock.release_write()
```

---

## R√©sum√© des m√©canismes

| M√©canisme | Quand l'utiliser | Exemple d'usage |
|-----------|------------------|-----------------|
| **Lock** | Acc√®s exclusif simple | Modifier une variable partag√©e |
| **RLock** | Lock r√©entrant (appels imbriqu√©s) | M√©thodes qui s'appellent mutuellement |
| **Semaphore** | Limiter le nombre d'acc√®s | Pool de connexions, bande passante |
| **Event** | Signaler un √©v√©nement | Notification de fin de t√¢che |
| **Condition** | Attendre une condition sp√©cifique | Producer/Consumer avec buffer |
| **Barrier** | Synchroniser plusieurs threads | Simulation en phases |

---

## Points cl√©s √† retenir

1. **Lock** = Protection basique pour l'acc√®s exclusif √† une ressource
2. **RLock** = Lock qui peut √™tre acquis plusieurs fois par le m√™me thread
3. **Semaphore** = Limite le nombre d'acc√®s concurrent
4. **Event** = Notification simple entre threads
5. **Condition** = Attente d'une condition avec notification
6. **Barrier** = Synchronisation de groupe
7. **Toujours utiliser `with`** pour garantir la lib√©ration
8. **Minimiser les sections critiques** pour les performances
9. **Ordre coh√©rent** d'acquisition pour √©viter les deadlocks
10. **Documenter** les invariants et les contraintes de synchronisation

---

## Ressources et prochaines √©tapes

**Pour aller plus loin** :
- Documentation officielle : `threading` et `asyncio.locks`
- Explorez `concurrent.futures` pour une abstraction plus haute
- √âtudiez les patterns de concurrence avanc√©s
- Apprenez les structures de donn√©es thread-safe : `queue.Queue`

**Dans la prochaine section** (8.4), nous explorerons les **patterns de concurrence** pour construire des syst√®mes robustes et scalables.

---

## Glossaire

- **Synchronisation** : Coordination entre threads/processus
- **Race Condition** : R√©sultat d√©pendant de l'ordre d'ex√©cution
- **Deadlock** : Blocage mutuel de threads
- **Section Critique** : Code n√©cessitant un acc√®s exclusif
- **Verrou (Lock)** : M√©canisme d'exclusion mutuelle
- **Atomicit√©** : Op√©ration indivisible
- **R√©entrant** : Peut √™tre appel√© r√©cursivement par le m√™me thread
- **Invariant** : Condition toujours vraie (sous protection)

‚è≠Ô∏è [Patterns de concurrence](/08-programmation-concurrente/04-patterns-de-concurrence.md)
