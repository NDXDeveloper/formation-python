üîù Retour au [Sommaire](/SOMMAIRE.md)

# 13.2 Manipulation de donn√©es avec Pandas

## Introduction

Bienvenue dans le monde de la manipulation de donn√©es avec **Pandas** ! Si NumPy est le fondement du calcul num√©rique en Python, Pandas est la biblioth√®que de r√©f√©rence pour l'analyse et la manipulation de donn√©es structur√©es. Son nom vient de "Panel Data" (donn√©es de panel), un terme d'√©conom√©trie, et de "Python Data Analysis".

Pandas est devenue l'outil incontournable pour les data scientists, les analystes de donn√©es, et tous ceux qui travaillent avec des donn√©es tabulaires en Python.

## Qu'est-ce que Pandas ?

Pandas est une biblioth√®que open-source qui fournit des structures de donn√©es puissantes et des outils d'analyse pour Python. Elle est particuli√®rement adapt√©e pour :

- **Donn√©es tabulaires** : comme des feuilles de calcul Excel ou des tables de bases de donn√©es
- **S√©ries temporelles** : donn√©es horodat√©es avec fr√©quence r√©guli√®re ou irr√©guli√®re
- **Donn√©es √©tiquet√©es** : chaque ligne et colonne peut avoir un nom
- **Donn√©es h√©t√©rog√®nes** : les colonnes peuvent contenir diff√©rents types de donn√©es

### Petite histoire

Pandas a √©t√© cr√©√©e en 2008 par Wes McKinney alors qu'il travaillait chez AQR Capital Management, un fonds d'investissement quantitatif. Il avait besoin d'un outil performant pour analyser des donn√©es financi√®res. Le projet est devenu open-source en 2009 et est aujourd'hui maintenu par une large communaut√©.

En 2017, Wes McKinney a publi√© le livre "Python for Data Analysis", devenu une r√©f√©rence pour apprendre Pandas.

## Pourquoi utiliser Pandas ?

### 1. Manipulation de donn√©es intuitive

Pandas rend la manipulation de donn√©es aussi simple qu'avec Excel, mais avec la puissance du code :

```python
import pandas as pd

# Imaginez que vous avez un tableau de ventes
ventes = pd.DataFrame({
    'Produit': ['Laptop', 'Souris', 'Clavier', '√âcran'],
    'Prix': [800, 25, 60, 250],
    'Quantit√©': [10, 50, 30, 15]
})

# Calculer le total en une ligne
ventes['Total'] = ventes['Prix'] * ventes['Quantit√©']

# Filtrer les produits chers
produits_chers = ventes[ventes['Prix'] > 100]

print(produits_chers)
```

### 2. Lecture et √©criture de multiples formats

Pandas peut lire et √©crire de nombreux formats de fichiers :

```python
# Lire depuis diff√©rents formats
df_csv = pd.read_csv('donnees.csv')
df_excel = pd.read_excel('donnees.xlsx')
df_json = pd.read_json('donnees.json')
df_sql = pd.read_sql('SELECT * FROM table', connection)
df_html = pd.read_html('https://example.com/table.html')

# √âcrire vers diff√©rents formats
df.to_csv('sortie.csv', index=False)
df.to_excel('sortie.xlsx', sheet_name='Donn√©es')
df.to_json('sortie.json')
df.to_sql('table_name', connection)
df.to_html('sortie.html')
```

### 3. Nettoyage de donn√©es efficace

Les donn√©es r√©elles sont rarement propres. Pandas facilite leur nettoyage :

```python
# G√©rer les valeurs manquantes
df.dropna()  # Supprimer les lignes avec valeurs manquantes
df.fillna(0)  # Remplir les valeurs manquantes avec 0

# Supprimer les doublons
df.drop_duplicates()

# Changer les types de donn√©es
df['Date'] = pd.to_datetime(df['Date'])

# Renommer les colonnes
df.rename(columns={'ancien_nom': 'nouveau_nom'})
```

### 4. Analyses puissantes

Pandas offre des fonctions d'analyse statistique int√©gr√©es :

```python
# Statistiques descriptives
print(df.describe())

# Grouper et agr√©ger
ventes_par_ville = df.groupby('Ville')['Ventes'].sum()

# Pivoter les donn√©es
pivot = df.pivot_table(values='Ventes', index='Mois', columns='Produit')

# Fusionner des DataFrames
resultat = pd.merge(clients, commandes, on='client_id')
```

### 5. Int√©gration avec l'√©cosyst√®me Python

Pandas s'int√®gre parfaitement avec d'autres biblioth√®ques :

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Utiliser NumPy avec Pandas
df['log_values'] = np.log(df['values'])

# Visualiser directement depuis Pandas
df['Ventes'].plot()
plt.show()

# Compatible avec scikit-learn pour le Machine Learning
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(df[features], df[target])
```

## Installation de Pandas

### Avec pip (recommand√©)

```bash
pip install pandas
```

Pandas sera install√© avec ses d√©pendances principales (NumPy, python-dateutil, pytz).

### Avec conda

```bash
conda install pandas
```

### D√©pendances optionnelles

Pour certaines fonctionnalit√©s, vous aurez besoin de biblioth√®ques suppl√©mentaires :

```bash
# Pour lire/√©crire Excel
pip install openpyxl xlrd

# Pour lire HTML
pip install lxml html5lib beautifulsoup4

# Pour le clipboard
pip install pyperclip

# Pour de meilleures performances
pip install bottleneck numexpr
```

### V√©rifier l'installation

```python
import pandas as pd
print("Version de Pandas:", pd.__version__)

# Afficher les informations de configuration
pd.show_versions()
```

## Importation de Pandas

Par convention universelle, Pandas est import√© avec l'alias `pd` :

```python
import pandas as pd
import numpy as np  # Souvent utilis√© ensemble
```

**Pourquoi `pd` ?**
- C'est la convention standard dans toute la communaut√©
- Rend le code plus concis
- Facilite le partage et la lecture de code

**‚ùå √Ä √©viter :**
```python
from pandas import *  # Pollue l'espace de noms
import pandas          # Trop long √† √©crire
```

**‚úÖ Recommand√© :**
```python
import pandas as pd
```

## Vue d'ensemble des concepts Pandas

### Les deux structures principales

Pandas repose sur deux structures de donn√©es fondamentales :

#### 1. Series (1D)
Une Series est comme une colonne d'un tableur - un tableau unidimensionnel √©tiquet√©.

```python
# Exemple de Series
temperatures = pd.Series([15, 18, 22, 20, 17],
                         index=['Lundi', 'Mardi', 'Mercredi', 'Jeudi', 'Vendredi'])
print(temperatures)
```

**Sortie :**
```
Lundi        15
Mardi        18
Mercredi     22
Jeudi        20
Vendredi     17
dtype: int64
```

#### 2. DataFrame (2D)
Un DataFrame est comme un tableur complet - un tableau bidimensionnel avec des lignes et des colonnes √©tiquet√©es.

```python
# Exemple de DataFrame
employes = pd.DataFrame({
    'Nom': ['Alice', 'Bob', 'Charlie'],
    '√Çge': [25, 30, 35],
    'Ville': ['Paris', 'Lyon', 'Marseille'],
    'Salaire': [35000, 42000, 48000]
})
print(employes)
```

**Sortie :**
```
       Nom  √Çge       Ville  Salaire
0    Alice   25       Paris    35000
1      Bob   30        Lyon    42000
2  Charlie   35  Marseille    48000
```

### Analogies utiles

Pour mieux comprendre Pandas :

- **Series** ‚âà Colonne Excel / Liste Python avec √©tiquettes
- **DataFrame** ‚âà Feuille Excel / Table SQL / Dictionnaire de listes
- **Index** ‚âà Num√©ros de lignes dans Excel (mais peut √™tre personnalis√©)
- **Colonnes** ‚âà En-t√™tes de colonnes dans Excel

## Premier programme avec Pandas

Cr√©ons un petit programme qui illustre les capacit√©s de Pandas :

```python
import pandas as pd
import numpy as np

# Cr√©er des donn√©es de ventes
ventes = pd.DataFrame({
    'Date': pd.date_range('2024-01-01', periods=7, freq='D'),
    'Produit': ['Laptop', 'Souris', 'Clavier', '√âcran', 'Webcam', 'Casque', 'Clavier'],
    'Prix': [800, 25, 60, 250, 80, 50, 65],
    'Quantit√©': [2, 10, 5, 3, 4, 8, 3],
    'Ville': ['Paris', 'Lyon', 'Paris', 'Marseille', 'Lyon', 'Paris', 'Marseille']
})

print("=== Donn√©es de ventes ===")
print(ventes)

# Calculer le montant total
ventes['Montant'] = ventes['Prix'] * ventes['Quantit√©']

# Statistiques de base
print("\n=== Statistiques ===")
print(f"Chiffre d'affaires total: {ventes['Montant'].sum()}‚Ç¨")
print(f"Vente moyenne: {ventes['Montant'].mean():.2f}‚Ç¨")
print(f"Nombre de transactions: {len(ventes)}")

# Ventes par ville
print("\n=== Ventes par ville ===")
ventes_par_ville = ventes.groupby('Ville')['Montant'].sum().sort_values(ascending=False)
print(ventes_par_ville)

# Produits les plus vendus
print("\n=== Top 3 des produits ===")
top_produits = ventes.groupby('Produit')['Montant'].sum().nlargest(3)
print(top_produits)

# Filtrer les ventes > 200‚Ç¨
print("\n=== Ventes importantes (>200‚Ç¨) ===")
ventes_importantes = ventes[ventes['Montant'] > 200][['Date', 'Produit', 'Montant']]
print(ventes_importantes)
```

## Comparaison : Excel vs Pandas

Comprendre comment Pandas se compare √† Excel aide √† saisir ses avantages :

| Op√©ration | Excel | Pandas |
|-----------|-------|--------|
| **Ouvrir un fichier** | Clic sur le fichier | `pd.read_excel('fichier.xlsx')` |
| **Filtrer des lignes** | Menu Donn√©es > Filtrer | `df[df['Colonne'] > 100]` |
| **Cr√©er une colonne** | Formule =A1*B1 | `df['Nouvelle'] = df['A'] * df['B']` |
| **Calculer une somme** | =SOMME(A:A) | `df['Colonne'].sum()` |
| **Tableau crois√©** | Insertion > Tableau crois√© | `df.pivot_table()` |
| **Supprimer doublons** | Donn√©es > Supprimer doublons | `df.drop_duplicates()` |
| **Trier** | Donn√©es > Trier | `df.sort_values('Colonne')` |

### Avantages d'Excel

- Interface graphique intuitive
- Pas de code n√©cessaire
- Visualisation imm√©diate
- Facile pour les non-programmeurs
- Parfait pour de petites analyses rapides

### Avantages de Pandas

- **Automatisation** : R√©p√©tez l'analyse sur de nouveaux fichiers sans effort
- **Volum√©trie** : G√®re des millions de lignes (Excel limit√© √† ~1M)
- **Reproductibilit√©** : Le code documente exactement ce qui a √©t√© fait
- **Puissance** : Op√©rations complexes en quelques lignes
- **Version control** : Code versionnable avec Git
- **Performance** : Beaucoup plus rapide sur de gros volumes

### Quand utiliser quoi ?

**Utilisez Excel quand :**
- Vous avez moins de 100 000 lignes
- C'est une analyse ponctuelle
- Vous voulez un r√©sultat visuel rapide
- Vous partagez avec des non-programmeurs

**Utilisez Pandas quand :**
- Vous avez plus de 100 000 lignes
- Vous r√©p√©tez l'analyse r√©guli√®rement
- Vous devez automatiser le processus
- Vous travaillez avec plusieurs sources de donn√©es
- Vous voulez une analyse reproductible

## Cas d'usage de Pandas

### 1. Analyse financi√®re

```python
# Analyser des donn√©es boursi√®res
stocks = pd.read_csv('stocks.csv', parse_dates=['Date'])
stocks['Rendement'] = stocks['Close'].pct_change() * 100

# Calculer des moyennes mobiles
stocks['MA_50'] = stocks['Close'].rolling(window=50).mean()
stocks['MA_200'] = stocks['Close'].rolling(window=200).mean()

# Identifier des signaux d'achat/vente
stocks['Signal'] = np.where(stocks['MA_50'] > stocks['MA_200'], 'Achat', 'Vente')
```

### 2. Analyse marketing et CRM

```python
# Segmenter les clients
clients = pd.read_csv('clients.csv')

# Calculer la valeur vie client (CLV)
clv = clients.groupby('Client_ID').agg({
    'Montant_achat': 'sum',
    'Date_achat': 'count',
    'Date_derniere_visite': 'max'
})

# Cr√©er des segments
clients['Segment'] = pd.cut(clients['Total_achats'],
                             bins=[0, 100, 500, 1000, float('inf')],
                             labels=['Bronze', 'Argent', 'Or', 'Platine'])
```

### 3. Analyse de donn√©es web

```python
# Analyser les logs web
logs = pd.read_csv('web_logs.csv')
logs['DateTime'] = pd.to_datetime(logs['DateTime'])

# Trafic par heure
trafic_horaire = logs.groupby(logs['DateTime'].dt.hour).size()

# Pages les plus visit√©es
pages_populaires = logs['URL'].value_counts().head(10)

# Taux de conversion par source
conversion = logs.groupby('Source')['Conversion'].mean() * 100
```

### 4. Analyse RH

```python
# Analyser les donn√©es RH
employes = pd.read_excel('employes.xlsx')

# Salaire moyen par d√©partement
sal_dept = employes.groupby('D√©partement')['Salaire'].mean()

# Taux d'attrition
employes['Attrition'] = employes['Date_sortie'].notna()
taux_attrition = employes.groupby('Ann√©e')['Attrition'].mean() * 100

# Anciennet√© moyenne
employes['Anciennet√©'] = (pd.Timestamp.now() - employes['Date_embauche']).dt.days / 365
```

### 5. Analyse scientifique

```python
# Analyser des r√©sultats d'exp√©riences
experiences = pd.read_csv('resultats.csv')

# Statistiques par groupe
stats = experiences.groupby('Groupe').agg({
    'Mesure': ['mean', 'std', 'count'],
    'Efficacite': 'mean'
})

# Comparaison avant/apr√®s
resultats = experiences.pivot_table(
    values='Mesure',
    index='Sujet',
    columns='Phase',
    aggfunc='mean'
)
resultats['Amelioration'] = resultats['Apres'] - resultats['Avant']
```

## L'√©cosyst√®me Pandas

Pandas s'int√®gre dans un √©cosyst√®me riche de biblioth√®ques Python :

### Biblioth√®ques compl√©mentaires

1. **NumPy** : Calculs num√©riques de base (Pandas est construit sur NumPy)
2. **Matplotlib / Seaborn** : Visualisation de donn√©es
3. **Plotly** : Visualisations interactives
4. **Scikit-learn** : Machine Learning
5. **Statsmodels** : Mod√®les statistiques
6. **SQLAlchemy** : Interface avec bases de donn√©es SQL
7. **Beautiful Soup / Scrapy** : Web scraping

### Flux de travail typique

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression

# 1. Charger les donn√©es
df = pd.read_csv('donnees.csv')

# 2. Explorer
print(df.head())
print(df.describe())
print(df.info())

# 3. Nettoyer
df = df.dropna()
df = df.drop_duplicates()
df['Date'] = pd.to_datetime(df['Date'])

# 4. Transformer
df['Log_value'] = np.log(df['Value'])
df_groupe = df.groupby('Categorie').mean()

# 5. Visualiser
df['Value'].plot(kind='hist')
plt.show()

# 6. Mod√©liser (avec scikit-learn)
X = df[['feature1', 'feature2']]
y = df['target']
X_train, X_test, y_train, y_test = train_test_split(X, y)
model = LinearRegression()
model.fit(X_train, y_train)

# 7. Exporter
df.to_csv('resultats_clean.csv', index=False)
```

## Ressources et documentation

### Documentation officielle

- **Site officiel** : https://pandas.pydata.org/
- **Documentation** : https://pandas.pydata.org/docs/
- **Guide utilisateur** : https://pandas.pydata.org/docs/user_guide/index.html
- **API Reference** : https://pandas.pydata.org/docs/reference/index.html

### Apprendre Pandas

- **10 minutes to pandas** : Guide de d√©marrage rapide officiel
- **Pandas Cookbook** : Recettes pour des t√¢ches courantes
- **Livre "Python for Data Analysis"** : Par Wes McKinney (cr√©ateur de Pandas)
- **Kaggle Learn** : Cours interactifs gratuits
- **Real Python** : Tutoriels d√©taill√©s

### Communaut√©

- **GitHub** : https://github.com/pandas-dev/pandas
- **Stack Overflow** : Tag `pandas` (questions tr√®s actives)
- **PyData** : Conf√©rences et meetups
- **Twitter** : @pandas_dev

### Cheat Sheets

Des aide-m√©moires PDF sont disponibles :
- Pandas Cheat Sheet (DataCamp)
- Pandas Basics Cheat Sheet (Pandas.pydata.org)
- Data Wrangling with pandas (Cheat Sheet)

## Conseils pour d√©buter

### 1. Commencez petit

Ne vous laissez pas intimider par toutes les fonctionnalit√©s. Commencez par :
- Lire un fichier CSV
- Explorer avec `head()`, `describe()`, `info()`
- S√©lectionner des colonnes
- Filtrer des lignes
- Faire des calculs simples

```python
# Programme d√©butant typique
df = pd.read_csv('donnees.csv')
print(df.head())
print(df['colonne'].mean())
resultat = df[df['colonne'] > 100]
```

### 2. Utilisez la documentation et l'auto-compl√©tion

```python
# Dans un notebook Jupyter, utilisez ?
df.groupby?  # Affiche la documentation

# Utilisez l'auto-compl√©tion avec Tab
df.gr[Tab]  # Affiche toutes les m√©thodes commen√ßant par 'gr'
```

### 3. Explorez vos donn√©es

Prenez toujours le temps d'explorer avant d'analyser :

```python
# Ces 5 commandes vous donneront une bonne vue d'ensemble
print(df.head())        # Premi√®res lignes
print(df.info())        # Types et valeurs manquantes
print(df.describe())    # Statistiques descriptives
print(df.shape)         # Dimensions
print(df.columns)       # Noms des colonnes
```

### 4. √âvitez les boucles

Pandas est optimis√© pour les op√©rations vectoris√©es :

```python
# ‚ùå Lent : boucle Python
for i in range(len(df)):
    df.loc[i, 'nouvelle_col'] = df.loc[i, 'col1'] * 2

# ‚úÖ Rapide : op√©ration vectoris√©e
df['nouvelle_col'] = df['col1'] * 2
```

### 5. Faites des copies quand n√©cessaire

```python
# ‚úÖ Bon : cr√©er une copie
df_filtre = df[df['colonne'] > 100].copy()
df_filtre['nouvelle'] = 123  # N'affecte pas df original

# ‚ö†Ô∏è Attention : vue, pas copie
df_vue = df[df['colonne'] > 100]
# Modifications peuvent affecter l'original
```

### 6. Cha√Ænez les op√©rations

Pour un code plus lisible :

```python
# ‚úÖ Bon : cha√Ænage
resultat = (df
    .query('Valeur > 100')
    .groupby('Categorie')
    .agg({'Ventes': 'sum'})
    .sort_values('Ventes', ascending=False)
    .head(10)
)

# Au lieu de :
df_filtre = df.query('Valeur > 100')
df_groupe = df_filtre.groupby('Categorie')
df_agg = df_groupe.agg({'Ventes': 'sum'})
df_trie = df_agg.sort_values('Ventes', ascending=False)
resultat = df_trie.head(10)
```

## Performance et bonnes pratiques

### 1. Choisir le bon type de donn√©es

```python
# Optimiser les types pour √©conomiser de la m√©moire
df['Categorie'] = df['Categorie'].astype('category')  # Au lieu de 'object'
df['Valeur_entiere'] = df['Valeur_entiere'].astype('int32')  # Au lieu de 'int64'
```

### 2. Lire par morceaux pour les gros fichiers

```python
# Pour les fichiers tr√®s volumineux
chunks = []
for chunk in pd.read_csv('gros_fichier.csv', chunksize=10000):
    # Traiter chaque chunk
    chunk_filtre = chunk[chunk['colonne'] > 100]
    chunks.append(chunk_filtre)

df = pd.concat(chunks, ignore_index=True)
```

### 3. Utiliser les index intelligemment

```python
# D√©finir un index appropri√© acc√©l√®re les recherches
df.set_index('ID', inplace=True)

# Recherche rapide par index
resultat = df.loc[12345]  # Tr√®s rapide
```

### 4. √âviter les op√©rations co√ªteuses dans les boucles

```python
# ‚ùå Lent : agrandir un DataFrame dans une boucle
df = pd.DataFrame()
for i in range(10000):
    df = df.append({'A': i}, ignore_index=True)

# ‚úÖ Rapide : cr√©er une liste puis un DataFrame
data = []
for i in range(10000):
    data.append({'A': i})
df = pd.DataFrame(data)
```

## Structure de cette section

Cette section sur Pandas est organis√©e en trois parties principales :

### 13.2.1 DataFrames et Series
Vous apprendrez :
- Les deux structures de donn√©es fondamentales de Pandas
- Comment cr√©er et manipuler des Series et DataFrames
- Acc√®s, s√©lection et modification des donn√©es
- Op√©rations de base et statistiques

### 13.2.2 Nettoyage et transformation de donn√©es
Vous d√©couvrirez :
- Gestion des valeurs manquantes et doublons
- Transformation de types de donn√©es
- Manipulation de cha√Ænes de caract√®res et dates
- Renommage et r√©organisation
- Fusion et concat√©nation de donn√©es

### 13.2.3 GroupBy et agr√©gations
Vous ma√Ætriserez :
- Le concept Split-Apply-Combine
- Fonctions d'agr√©gation
- Groupements simples et multiples
- Transform, Filter et Apply
- Analyses par groupe

Ces trois sections vous donneront une base solide pour utiliser Pandas efficacement dans vos projets d'analyse de donn√©es, que ce soit pour le business, la science, ou tout autre domaine n√©cessitant la manipulation de donn√©es tabulaires.

## Conclusion de l'introduction

Pandas est un outil extraordinaire qui a r√©volutionn√© l'analyse de donn√©es en Python. Sa combinaison de puissance, de flexibilit√© et de simplicit√© en fait la biblioth√®que de choix pour manipuler des donn√©es structur√©es.

**Points cl√©s √† retenir :**

1. **Pandas** = biblioth√®que pour donn√©es tabulaires (comme Excel, mais en code)
2. **Deux structures** : Series (1D) et DataFrame (2D)
3. **Construit sur NumPy** : h√©rite de sa performance
4. **Tr√®s versatile** : lecture, nettoyage, transformation, analyse, export
5. **Bien int√©gr√©** : fonctionne avec tout l'√©cosyst√®me Python

**Ce que vous gagnerez en apprenant Pandas :**

- Automatisation de t√¢ches r√©p√©titives d'analyse
- Capacit√© √† g√©rer de gros volumes de donn√©es
- Analyses reproductibles et document√©es
- Comp√©tence tr√®s recherch√©e dans l'industrie
- Base pour le Machine Learning et la Data Science

Dans les sections suivantes, nous allons plonger dans les d√©tails pratiques de Pandas, en commen√ßant par ses structures de donn√©es fondamentales : les DataFrames et les Series.

**Pr√™t √† ma√Ætriser Pandas ?** Passons maintenant √† la section 13.2.1 pour explorer en profondeur les DataFrames et Series !

‚è≠Ô∏è [DataFrames et Series](/13-introduction-data-science/02.1-dataframes-et-series.md)
