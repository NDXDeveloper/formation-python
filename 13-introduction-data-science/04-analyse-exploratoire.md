üîù Retour au [Sommaire](/SOMMAIRE.md)

# 13.4 Introduction √† l'analyse exploratoire

## Qu'est-ce que l'analyse exploratoire des donn√©es (EDA) ?

L'**analyse exploratoire des donn√©es** (EDA pour Exploratory Data Analysis en anglais) est la premi√®re √©tape cruciale de tout projet de Data Science. C'est le processus d'investigation initial des donn√©es pour :

- **D√©couvrir des patterns** : identifier des tendances, des structures cach√©es
- **D√©tecter des anomalies** : rep√©rer les valeurs aberrantes, les erreurs
- **Tester des hypoth√®ses** : v√©rifier des suppositions initiales
- **Comprendre les relations** : voir comment les variables interagissent
- **R√©sumer l'information** : obtenir une vue d'ensemble des donn√©es

> "L'analyse exploratoire est une attitude, un √©tat d'esprit flexible, une volont√© de chercher ce que l'on pense √™tre dans les donn√©es, mais aussi ce que l'on ne s'attendait pas √† trouver." - John Tukey (inventeur de l'EDA)

## Pourquoi l'EDA est-elle essentielle ?

### 1. Comprendre avant de mod√©liser

Imaginez que vous devez construire une maison. Avant de commencer les travaux, vous devez :
- √âtudier le terrain
- Comprendre la nature du sol
- Identifier les contraintes
- Planifier en cons√©quence

C'est exactement la m√™me chose avec les donn√©es ! Avant de construire des mod√®les complexes, vous devez comprendre vos donn√©es.

### 2. √âviter les erreurs co√ªteuses

Sans EDA, vous risquez de :
- Utiliser des donn√©es erron√©es ou corrompues
- Ignorer des valeurs manquantes importantes
- Mal interpr√©ter les relations entre variables
- Construire des mod√®les sur des hypoth√®ses fausses

### 3. Gagner du temps

Bien que l'EDA prenne du temps au d√©but, elle vous en fait gagner √©norm√©ment par la suite en :
- √âvitant les impasses
- Identifiant rapidement les probl√®mes
- Guidant vos choix de mod√©lisation
- Anticipant les difficult√©s

### 4. Raconter une histoire

L'EDA vous aide √† comprendre le "narratif" de vos donn√©es, ce qui est essentiel pour communiquer vos r√©sultats.

## Les √©tapes de l'analyse exploratoire

L'EDA suit g√©n√©ralement ces √©tapes :

```
1. Collecte et importation des donn√©es
   ‚Üì
2. Premi√®res observations (aper√ßu des donn√©es)
   ‚Üì
3. Nettoyage des donn√©es
   ‚Üì
4. Analyse statistique descriptive
   ‚Üì
5. Visualisation
   ‚Üì
6. D√©tection d'anomalies
   ‚Üì
7. Analyse des corr√©lations
   ‚Üì
8. Formulation d'hypoth√®ses
```

Nous allons explorer chacune de ces √©tapes avec des exemples pratiques.

## 1. Collecte et importation des donn√©es

### Chargement d'un dataset

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Chargement depuis un fichier CSV
df = pd.read_csv('donnees.csv')

# Ou utilisation d'un dataset d'exemple
# Iris : classification de fleurs
df = sns.load_dataset('iris')
```

**Formats de donn√©es courants :**
- **CSV** : `pd.read_csv()`
- **Excel** : `pd.read_excel()`
- **JSON** : `pd.read_json()`
- **SQL** : `pd.read_sql()`
- **Parquet** : `pd.read_parquet()`

## 2. Premi√®res observations

### 2.1 Vue d'ensemble du dataset

```python
import pandas as pd
import seaborn as sns

# Chargement du dataset Iris
df = sns.load_dataset('iris')

# Afficher les premi√®res lignes
print("Premi√®res lignes :")
print(df.head())

# Afficher les derni√®res lignes
print("\nDerni√®res lignes :")
print(df.tail())

# Afficher un √©chantillon al√©atoire
print("\n√âchantillon al√©atoire :")
print(df.sample(5))
```

**Questions √† se poser :**
- Les donn√©es ont-elles l'air coh√©rentes ?
- Y a-t-il des colonnes inattendues ?
- Les types de donn√©es sont-ils corrects ?

### 2.2 Informations sur la structure

```python
# Dimensions du dataset
print(f"Nombre de lignes : {df.shape[0]}")
print(f"Nombre de colonnes : {df.shape[1]}")
print(f"Dimensions : {df.shape}")

# Informations d√©taill√©es
print("\nInformations sur le dataset :")
print(df.info())

# Types de donn√©es
print("\nTypes de donn√©es :")
print(df.dtypes)

# Noms des colonnes
print("\nNoms des colonnes :")
print(df.columns.tolist())
```

### 2.3 Valeurs manquantes

```python
# Comptage des valeurs manquantes
print("Valeurs manquantes par colonne :")
print(df.isnull().sum())

# Pourcentage de valeurs manquantes
print("\nPourcentage de valeurs manquantes :")
print((df.isnull().sum() / len(df)) * 100)

# Visualisation des valeurs manquantes
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 6))
sns.heatmap(df.isnull(), cbar=False, yticklabels=False, cmap='viridis')
plt.title('Carte des valeurs manquantes')
plt.show()
```

### 2.4 Valeurs dupliqu√©es

```python
# Nombre de doublons
print(f"Nombre de lignes dupliqu√©es : {df.duplicated().sum()}")

# Afficher les doublons
doublons = df[df.duplicated()]
print("\nLignes dupliqu√©es :")
print(doublons)

# Supprimer les doublons (si n√©cessaire)
df_sans_doublons = df.drop_duplicates()
```

## 3. Nettoyage des donn√©es

Le nettoyage est une √©tape cruciale qui peut prendre 60-80% du temps d'un projet.

### 3.1 Gestion des valeurs manquantes

```python
# Strat√©gie 1 : Suppression des lignes avec valeurs manquantes
df_clean = df.dropna()

# Strat√©gie 2 : Suppression des colonnes avec trop de valeurs manquantes
seuil = 0.5  # 50% de valeurs manquantes
df_clean = df.dropna(thresh=len(df) * seuil, axis=1)

# Strat√©gie 3 : Remplacement par la moyenne (pour variables num√©riques)
df['colonne'] = df['colonne'].fillna(df['colonne'].mean())

# Strat√©gie 4 : Remplacement par la m√©diane
df['colonne'] = df['colonne'].fillna(df['colonne'].median())

# Strat√©gie 5 : Remplacement par la valeur la plus fr√©quente
df['colonne'] = df['colonne'].fillna(df['colonne'].mode()[0])

# Strat√©gie 6 : Remplacement par une valeur sp√©cifique
df['colonne'] = df['colonne'].fillna(0)
```

### 3.2 Gestion des valeurs aberrantes (outliers)

```python
import numpy as np

# M√©thode 1 : R√®gle des 1.5 IQR (Inter-Quartile Range)
def detecter_outliers_iqr(df, colonne):
    Q1 = df[colonne].quantile(0.25)
    Q3 = df[colonne].quantile(0.75)
    IQR = Q3 - Q1

    limite_basse = Q1 - 1.5 * IQR
    limite_haute = Q3 + 1.5 * IQR

    outliers = df[(df[colonne] < limite_basse) | (df[colonne] > limite_haute)]
    return outliers

# M√©thode 2 : Z-score (pour distributions normales)
def detecter_outliers_zscore(df, colonne, seuil=3):
    z_scores = np.abs((df[colonne] - df[colonne].mean()) / df[colonne].std())
    outliers = df[z_scores > seuil]
    return outliers

# Visualisation des outliers avec box plot
plt.figure(figsize=(10, 6))
plt.boxplot(df['colonne_numerique'])
plt.title('D√©tection des valeurs aberrantes')
plt.ylabel('Valeur')
plt.show()
```

### 3.3 Conversion de types de donn√©es

```python
# Conversion en num√©rique
df['colonne'] = pd.to_numeric(df['colonne'], errors='coerce')

# Conversion en cat√©gorie
df['colonne_categorielle'] = df['colonne_categorielle'].astype('category')

# Conversion en datetime
df['date'] = pd.to_datetime(df['date'])

# Conversion en string
df['colonne'] = df['colonne'].astype(str)
```

## 4. Analyse statistique descriptive

L'analyse descriptive r√©sume les caract√©ristiques principales des donn√©es.

### 4.1 Variables num√©riques

```python
# Statistiques descriptives compl√®tes
print("Statistiques descriptives :")
print(df.describe())

# Statistiques pour une colonne sp√©cifique
print("\nStatistiques pour une colonne :")
print(df['sepal_length'].describe())

# Statistiques individuelles
moyenne = df['sepal_length'].mean()
mediane = df['sepal_length'].median()
mode = df['sepal_length'].mode()[0]
std = df['sepal_length'].std()
variance = df['sepal_length'].var()
minimum = df['sepal_length'].min()
maximum = df['sepal_length'].max()

print(f"Moyenne : {moyenne:.2f}")
print(f"M√©diane : {mediane:.2f}")
print(f"Mode : {mode:.2f}")
print(f"√âcart-type : {std:.2f}")
print(f"Variance : {variance:.2f}")
print(f"Min : {minimum:.2f}")
print(f"Max : {maximum:.2f}")

# Quartiles
Q1 = df['sepal_length'].quantile(0.25)
Q2 = df['sepal_length'].quantile(0.50)  # = m√©diane
Q3 = df['sepal_length'].quantile(0.75)

print(f"\nQ1 (25%) : {Q1:.2f}")
print(f"Q2 (50%) : {Q2:.2f}")
print(f"Q3 (75%) : {Q3:.2f}")
```

**Interpr√©tation des statistiques :**

- **Moyenne** : valeur centrale, sensible aux outliers
- **M√©diane** : valeur centrale, robuste aux outliers
- **Mode** : valeur la plus fr√©quente
- **√âcart-type** : mesure de dispersion (plus il est √©lev√©, plus les donn√©es sont dispers√©es)
- **Variance** : carr√© de l'√©cart-type
- **Min/Max** : valeurs extr√™mes
- **Quartiles** : divisent les donn√©es en 4 parties √©gales

### 4.2 Variables cat√©gorielles

```python
# Comptage des valeurs uniques
print("Valeurs uniques :")
print(df['species'].value_counts())

# Proportions
print("\nProportions :")
print(df['species'].value_counts(normalize=True))

# Nombre de valeurs uniques
print(f"\nNombre de cat√©gories : {df['species'].nunique()}")

# Mode (valeur la plus fr√©quente)
print(f"Cat√©gorie la plus fr√©quente : {df['species'].mode()[0]}")
```

### 4.3 Mesures de forme de distribution

```python
# Asym√©trie (Skewness)
# skewness > 0 : distribution asym√©trique √† droite (queue √† droite)
# skewness < 0 : distribution asym√©trique √† gauche (queue √† gauche)
# skewness ‚âà 0 : distribution sym√©trique
asymetrie = df['sepal_length'].skew()
print(f"Asym√©trie : {asymetrie:.2f}")

# Aplatissement (Kurtosis)
# kurtosis > 0 : distribution pointue (leptokurtique)
# kurtosis < 0 : distribution aplatie (platikurtique)
# kurtosis ‚âà 0 : distribution normale (m√©sokurtique)
aplatissement = df['sepal_length'].kurtosis()
print(f"Aplatissement : {aplatissement:.2f}")
```

## 5. Visualisation des donn√©es

La visualisation est le c≈ìur de l'EDA. "Un graphique vaut mille tableaux."

### 5.1 Distribution des variables num√©riques

```python
import matplotlib.pyplot as plt
import seaborn as sns

# Configuration de style
sns.set_style("whitegrid")

# Histogramme
plt.figure(figsize=(10, 6))
plt.hist(df['sepal_length'], bins=30, edgecolor='black', alpha=0.7)
plt.xlabel('Longueur du s√©pale')
plt.ylabel('Fr√©quence')
plt.title('Distribution de la longueur du s√©pale')
plt.axvline(df['sepal_length'].mean(), color='red', linestyle='--',
            label=f'Moyenne: {df["sepal_length"].mean():.2f}')
plt.legend()
plt.show()

# Courbe de densit√© (KDE)
plt.figure(figsize=(10, 6))
df['sepal_length'].plot(kind='kde')
plt.xlabel('Longueur du s√©pale')
plt.ylabel('Densit√©')
plt.title('Courbe de densit√©')
plt.show()

# Histogramme + KDE combin√©s
plt.figure(figsize=(10, 6))
sns.histplot(df['sepal_length'], kde=True, bins=30)
plt.title('Distribution avec courbe de densit√©')
plt.show()
```

### 5.2 Box plots pour d√©tecter les outliers

```python
# Box plot simple
plt.figure(figsize=(10, 6))
sns.boxplot(data=df['sepal_length'])
plt.title('Box plot - Longueur du s√©pale')
plt.show()

# Box plots multiples (par cat√©gorie)
plt.figure(figsize=(12, 6))
sns.boxplot(x='species', y='sepal_length', data=df)
plt.title('Distribution de la longueur du s√©pale par esp√®ce')
plt.show()

# Violin plot (combine box plot et KDE)
plt.figure(figsize=(12, 6))
sns.violinplot(x='species', y='sepal_length', data=df)
plt.title('Violin plot - Longueur du s√©pale par esp√®ce')
plt.show()
```

### 5.3 Variables cat√©gorielles

```python
# Diagramme √† barres
plt.figure(figsize=(10, 6))
df['species'].value_counts().plot(kind='bar')
plt.xlabel('Esp√®ce')
plt.ylabel('Nombre d\'observations')
plt.title('Distribution des esp√®ces')
plt.xticks(rotation=45)
plt.show()

# Diagramme circulaire
plt.figure(figsize=(8, 8))
df['species'].value_counts().plot(kind='pie', autopct='%1.1f%%')
plt.title('R√©partition des esp√®ces')
plt.ylabel('')
plt.show()
```

### 5.4 Matrices de distribution

```python
# Histogrammes multiples
df.hist(figsize=(15, 12), bins=30, edgecolor='black')
plt.suptitle('Distribution de toutes les variables num√©riques')
plt.tight_layout()
plt.show()

# Pairplot : visualisation de toutes les relations
sns.pairplot(df, hue='species', diag_kind='kde')
plt.suptitle('Matrice de relations entre variables', y=1.02)
plt.show()
```

## 6. Analyse des corr√©lations

Les corr√©lations r√©v√®lent les relations entre variables.

### 6.1 Matrice de corr√©lation

```python
# Calcul de la matrice de corr√©lation
correlation_matrix = df.select_dtypes(include=[np.number]).corr()

print("Matrice de corr√©lation :")
print(correlation_matrix)

# Visualisation avec heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm',
            center=0, square=True, linewidths=1)
plt.title('Matrice de corr√©lation')
plt.show()
```

**Interpr√©tation des corr√©lations :**
- **r = 1** : corr√©lation positive parfaite
- **r = 0.7 √† 0.9** : corr√©lation positive forte
- **r = 0.4 √† 0.7** : corr√©lation positive mod√©r√©e
- **r = 0.1 √† 0.4** : corr√©lation positive faible
- **r = 0** : pas de corr√©lation
- **r = -0.1 √† -0.4** : corr√©lation n√©gative faible
- **r = -0.4 √† -0.7** : corr√©lation n√©gative mod√©r√©e
- **r = -0.7 √† -0.9** : corr√©lation n√©gative forte
- **r = -1** : corr√©lation n√©gative parfaite

### 6.2 Nuages de points (Scatter plots)

```python
# Scatter plot simple
plt.figure(figsize=(10, 6))
plt.scatter(df['sepal_length'], df['sepal_width'], alpha=0.6)
plt.xlabel('Longueur du s√©pale')
plt.ylabel('Largeur du s√©pale')
plt.title('Relation entre longueur et largeur du s√©pale')
plt.show()

# Scatter plot avec couleurs par cat√©gorie
plt.figure(figsize=(10, 6))
for species in df['species'].unique():
    subset = df[df['species'] == species]
    plt.scatter(subset['sepal_length'], subset['sepal_width'],
                label=species, alpha=0.6)
plt.xlabel('Longueur du s√©pale')
plt.ylabel('Largeur du s√©pale')
plt.title('Relation entre longueur et largeur par esp√®ce')
plt.legend()
plt.show()

# Scatter plot avec ligne de r√©gression
sns.lmplot(x='sepal_length', y='sepal_width', data=df,
           hue='species', height=6, aspect=1.5)
plt.title('Relation avec ligne de r√©gression')
plt.show()
```

## 7. Analyse par groupes

Comparer les statistiques entre diff√©rents groupes.

### 7.1 Statistiques par groupe

```python
# Groupement et statistiques
stats_par_espece = df.groupby('species').agg({
    'sepal_length': ['mean', 'median', 'std', 'min', 'max'],
    'sepal_width': ['mean', 'median', 'std', 'min', 'max']
})

print("Statistiques par esp√®ce :")
print(stats_par_espece)

# R√©sum√© plus simple
print("\nMoyennes par esp√®ce :")
print(df.groupby('species').mean())
```

### 7.2 Visualisations comparatives

```python
# Bar plot des moyennes
df.groupby('species')['sepal_length'].mean().plot(kind='bar', figsize=(10, 6))
plt.xlabel('Esp√®ce')
plt.ylabel('Longueur moyenne du s√©pale')
plt.title('Comparaison des moyennes par esp√®ce')
plt.xticks(rotation=45)
plt.show()

# Box plots c√¥te √† c√¥te
fig, axes = plt.subplots(2, 2, figsize=(15, 12))

sns.boxplot(x='species', y='sepal_length', data=df, ax=axes[0, 0])
axes[0, 0].set_title('Longueur du s√©pale')

sns.boxplot(x='species', y='sepal_width', data=df, ax=axes[0, 1])
axes[0, 1].set_title('Largeur du s√©pale')

sns.boxplot(x='species', y='petal_length', data=df, ax=axes[1, 0])
axes[1, 0].set_title('Longueur du p√©tale')

sns.boxplot(x='species', y='petal_width', data=df, ax=axes[1, 1])
axes[1, 1].set_title('Largeur du p√©tale')

plt.tight_layout()
plt.show()
```

## 8. Exemple complet : EDA sur le dataset Titanic

Appliquons tous ces concepts sur un cas r√©el : le dataset Titanic.

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Chargement des donn√©es
titanic = sns.load_dataset('titanic')

print("=" * 80)
print("ANALYSE EXPLORATOIRE DU DATASET TITANIC")
print("=" * 80)

# 1. PREMI√àRES OBSERVATIONS
print("\n1. PREMI√àRES OBSERVATIONS")
print("-" * 80)
print(f"Dimensions : {titanic.shape[0]} lignes, {titanic.shape[1]} colonnes")
print("\nPremi√®res lignes :")
print(titanic.head())

print("\nTypes de donn√©es :")
print(titanic.dtypes)

# 2. VALEURS MANQUANTES
print("\n2. VALEURS MANQUANTES")
print("-" * 80)
missing = titanic.isnull().sum()
missing_percent = (missing / len(titanic)) * 100
missing_df = pd.DataFrame({
    'Colonne': missing.index,
    'Valeurs manquantes': missing.values,
    'Pourcentage': missing_percent.values
})
print(missing_df[missing_df['Valeurs manquantes'] > 0])

# Visualisation
plt.figure(figsize=(10, 6))
sns.heatmap(titanic.isnull(), cbar=False, yticklabels=False, cmap='viridis')
plt.title('Carte des valeurs manquantes - Titanic')
plt.show()

# 3. STATISTIQUES DESCRIPTIVES
print("\n3. STATISTIQUES DESCRIPTIVES")
print("-" * 80)
print(titanic.describe())

# 4. ANALYSE DE LA SURVIE (variable cible)
print("\n4. ANALYSE DE LA SURVIE")
print("-" * 80)
print(f"Taux de survie global : {titanic['survived'].mean():.2%}")
print(f"\nNombre de survivants : {titanic['survived'].sum()}")
print(f"Nombre de d√©c√©d√©s : {(1 - titanic['survived']).sum()}")

# Visualisation
fig, axes = plt.subplots(1, 2, figsize=(15, 5))

# Diagramme √† barres
titanic['survived'].value_counts().plot(kind='bar', ax=axes[0])
axes[0].set_title('Distribution de la survie')
axes[0].set_xlabel('Survie (0 = Non, 1 = Oui)')
axes[0].set_ylabel('Nombre de passagers')
axes[0].set_xticklabels(['D√©c√©d√©', 'Surv√©cu'], rotation=0)

# Diagramme circulaire
titanic['survived'].value_counts().plot(kind='pie', ax=axes[1],
                                        autopct='%1.1f%%',
                                        labels=['D√©c√©d√©', 'Surv√©cu'])
axes[1].set_title('Proportion de survie')
axes[1].set_ylabel('')

plt.tight_layout()
plt.show()

# 5. ANALYSE PAR SEXE
print("\n5. ANALYSE PAR SEXE")
print("-" * 80)
print(titanic.groupby('sex')['survived'].agg(['count', 'sum', 'mean']))

plt.figure(figsize=(10, 6))
sns.barplot(x='sex', y='survived', data=titanic)
plt.title('Taux de survie par sexe')
plt.ylabel('Taux de survie')
plt.xlabel('Sexe')
plt.show()

# 6. ANALYSE PAR CLASSE
print("\n6. ANALYSE PAR CLASSE")
print("-" * 80)
print(titanic.groupby('pclass')['survived'].agg(['count', 'sum', 'mean']))

plt.figure(figsize=(10, 6))
sns.barplot(x='pclass', y='survived', data=titanic)
plt.title('Taux de survie par classe')
plt.ylabel('Taux de survie')
plt.xlabel('Classe')
plt.show()

# 7. ANALYSE PAR √ÇGE
print("\n7. ANALYSE PAR √ÇGE")
print("-" * 80)
print(f"√Çge moyen : {titanic['age'].mean():.2f} ans")
print(f"√Çge m√©dian : {titanic['age'].median():.2f} ans")
print(f"√Çge min : {titanic['age'].min():.2f} ans")
print(f"√Çge max : {titanic['age'].max():.2f} ans")

fig, axes = plt.subplots(1, 2, figsize=(15, 5))

# Distribution de l'√¢ge
titanic['age'].hist(bins=30, ax=axes[0], edgecolor='black')
axes[0].set_title('Distribution de l\'√¢ge')
axes[0].set_xlabel('√Çge')
axes[0].set_ylabel('Fr√©quence')

# √Çge par survie
sns.boxplot(x='survived', y='age', data=titanic, ax=axes[1])
axes[1].set_title('Distribution de l\'√¢ge par survie')
axes[1].set_xticklabels(['D√©c√©d√©', 'Surv√©cu'])

plt.tight_layout()
plt.show()

# 8. ANALYSE CROIS√âE : Sexe, Classe et Survie
print("\n8. ANALYSE CROIS√âE")
print("-" * 80)

# Tableau crois√©
cross_tab = pd.crosstab([titanic['pclass'], titanic['sex']],
                        titanic['survived'],
                        margins=True)
print("Tableau crois√© Classe x Sexe x Survie :")
print(cross_tab)

# Visualisation
plt.figure(figsize=(12, 6))
sns.catplot(x='pclass', y='survived', hue='sex', data=titanic,
            kind='bar', height=6, aspect=1.5)
plt.title('Taux de survie par classe et par sexe')
plt.ylabel('Taux de survie')
plt.xlabel('Classe')
plt.show()

# 9. CORR√âLATIONS
print("\n9. MATRICE DE CORR√âLATION")
print("-" * 80)

# S√©lection des variables num√©riques
numeric_cols = titanic.select_dtypes(include=[np.number]).columns
correlation_matrix = titanic[numeric_cols].corr()

plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm',
            center=0, square=True, linewidths=1)
plt.title('Matrice de corr√©lation - Titanic')
plt.show()

# 10. INSIGHTS PRINCIPAUX
print("\n10. INSIGHTS PRINCIPAUX")
print("=" * 80)
print("1. Taux de survie global : ~38%")
print("2. Les femmes ont un taux de survie beaucoup plus √©lev√© (~74%) que les hommes (~19%)")
print("3. Les passagers de 1√®re classe ont surv√©cu davantage (~63%) que ceux de 3e classe (~24%)")
print("4. L'√¢ge influence la survie : les enfants ont un meilleur taux de survie")
print("5. Il y a des valeurs manquantes importantes dans 'age' et 'deck'")
print("6. Le facteur le plus discriminant semble √™tre le sexe, suivi de la classe")
print("=" * 80)
```

## 9. Checklist compl√®te de l'EDA

Utilisez cette checklist pour ne rien oublier :

### ‚úÖ Phase 1 : D√©couverte initiale
- [ ] Charger les donn√©es
- [ ] Afficher les premi√®res lignes (`head()`, `tail()`)
- [ ] V√©rifier les dimensions (`shape`)
- [ ] Lister les colonnes
- [ ] V√©rifier les types de donn√©es (`dtypes`)
- [ ] Afficher les informations g√©n√©rales (`info()`)

### ‚úÖ Phase 2 : Qualit√© des donn√©es
- [ ] Identifier les valeurs manquantes
- [ ] Calculer le pourcentage de valeurs manquantes
- [ ] D√©tecter les doublons
- [ ] Identifier les valeurs aberrantes
- [ ] V√©rifier la coh√©rence des donn√©es

### ‚úÖ Phase 3 : Statistiques descriptives
- [ ] Statistiques pour variables num√©riques (`describe()`)
- [ ] Distribution des variables cat√©gorielles (`value_counts()`)
- [ ] Calculer les mesures de tendance centrale (moyenne, m√©diane, mode)
- [ ] Calculer les mesures de dispersion (√©cart-type, variance)
- [ ] Calculer asym√©trie et aplatissement

### ‚úÖ Phase 4 : Visualisation univari√©e
- [ ] Histogrammes pour variables num√©riques
- [ ] Box plots pour d√©tecter les outliers
- [ ] Diagrammes √† barres pour variables cat√©gorielles
- [ ] Courbes de densit√© (KDE)

### ‚úÖ Phase 5 : Visualisation bivari√©e
- [ ] Scatter plots pour relations entre variables
- [ ] Box plots par cat√©gorie
- [ ] Diagrammes √† barres group√©es

### ‚úÖ Phase 6 : Visualisation multivari√©e
- [ ] Matrice de corr√©lation
- [ ] Pairplot
- [ ] Heatmap

### ‚úÖ Phase 7 : Analyse par groupes
- [ ] Grouper et calculer des statistiques
- [ ] Comparer les distributions par groupe
- [ ] Visualiser les diff√©rences entre groupes

### ‚úÖ Phase 8 : Synth√®se
- [ ] Documenter les insights principaux
- [ ] Identifier les probl√®mes de qualit√©
- [ ] Formuler des hypoth√®ses
- [ ] Planifier les √©tapes suivantes

## 10. Outils et biblioth√®ques essentiels

### Biblioth√®ques Python pour l'EDA

```python
# Manipulation de donn√©es
import pandas as pd
import numpy as np

# Visualisation
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

# Statistiques
from scipy import stats

# Outils sp√©cialis√©s pour l'EDA
import pandas_profiling  # Rapports automatiques
import sweetviz  # Comparaison de datasets
import dtale  # Interface interactive
```

### Pandas Profiling : EDA automatique

Pandas Profiling g√©n√®re un rapport complet d'EDA en une seule ligne :

```python
# Installation : pip install pandas-profiling
from pandas_profiling import ProfileReport

# G√©n√©ration du rapport
profile = ProfileReport(df, title='Rapport EDA', explorative=True)

# Sauvegarde en HTML
profile.to_file("rapport_eda.html")

# Affichage dans Jupyter
profile.to_widgets()
```

Le rapport inclut automatiquement :
- Aper√ßu du dataset
- Variables : types, valeurs manquantes, distribution
- Corr√©lations
- Valeurs manquantes
- √âchantillon de donn√©es
- Et bien plus !

### Sweetviz : Comparaison de datasets

```python
# Installation : pip install sweetviz
import sweetviz as sv

# Analyse d'un seul dataset
report = sv.analyze(df)
report.show_html("rapport_sweetviz.html")

# Comparaison de deux datasets (ex: train vs test)
compare = sv.compare([train_df, "Training"], [test_df, "Test"])
compare.show_html("comparaison.html")
```

## 11. Bonnes pratiques de l'EDA

### 1. Commencer large, puis zoomer

Ne vous focalisez pas imm√©diatement sur les d√©tails. Commencez par une vue d'ensemble, puis approfondissez progressivement.

### 2. Documenter vos d√©couvertes

Prenez des notes tout au long de votre exploration :
- Anomalies d√©tect√©es
- Hypoth√®ses formul√©es
- Questions soulev√©es
- D√©cisions de nettoyage

### 3. It√©rer

L'EDA n'est pas lin√©aire. Vous d√©couvrirez de nouvelles choses qui vous feront revenir en arri√®re.

### 4. Ne pas se pr√©cipiter

M√™me si c'est tentant de passer rapidement √† la mod√©lisation, une bonne EDA vous fera gagner √©norm√©ment de temps par la suite.

### 5. Combiner statistiques et visualisations

Les chiffres ne suffisent pas, les graphiques non plus. Utilisez les deux !

### 6. Garder un ≈ìil critique

Questionnez toujours vos donn√©es :
- Ces valeurs sont-elles logiques ?
- Y a-t-il des erreurs de saisie ?
- Les unit√©s sont-elles coh√©rentes ?

### 7. Penser au contexte m√©tier

Les donn√©es sans contexte m√©tier sont inutiles. Comprenez d'o√π viennent les donn√©es et ce qu'elles repr√©sentent.

## 12. Erreurs courantes √† √©viter

### ‚ùå Erreur 1 : Sauter l'EDA
"Je connais d√©j√† mes donn√©es, je passe directement √† la mod√©lisation."
‚Üí M√™me des donn√©es famili√®res peuvent r√©v√©ler des surprises

### ‚ùå Erreur 2 : Se fier uniquement aux statistiques
Les statistiques peuvent √™tre trompeuses sans visualisation (voir le quartet d'Anscombe).

### ‚ùå Erreur 3 : Ignorer les valeurs manquantes
Les valeurs manquantes contiennent de l'information ! Pourquoi manquent-elles ?

### ‚ùå Erreur 4 : Supprimer automatiquement les outliers
Les outliers peuvent √™tre des erreurs... ou les points les plus int√©ressants !

### ‚ùå Erreur 5 : Ne pas v√©rifier les doublons
Des doublons peuvent biaiser compl√®tement vos analyses.

### ‚ùå Erreur 6 : Confondre corr√©lation et causalit√©
"Ces variables sont corr√©l√©es" ‚â† "L'une cause l'autre"

### ‚ùå Erreur 7 : Surcharger les graphiques
Un graphique simple et clair vaut mieux qu'un graphique complexe et illisible.

## 13. Rapport d'EDA : structure type

Quand vous documentez votre EDA, suivez cette structure :

```
1. INTRODUCTION
   - Contexte et objectif
   - Source des donn√©es
   - Description du dataset

2. APER√áU DES DONN√âES
   - Dimensions
   - Variables et types
   - √âchantillon des donn√©es

3. QUALIT√â DES DONN√âES
   - Valeurs manquantes
   - Doublons
   - Incoh√©rences d√©tect√©es
   - Actions de nettoyage

4. ANALYSE DESCRIPTIVE
   - Variables num√©riques
   - Variables cat√©gorielles
   - Distributions

5. RELATIONS ENTRE VARIABLES
   - Corr√©lations
   - Analyses crois√©es
   - Visualisations

6. INSIGHTS PRINCIPAUX
   - D√©couvertes cl√©s
   - Patterns identifi√©s
   - Anomalies

7. CONCLUSIONS ET RECOMMANDATIONS
   - Synth√®se
   - Prochaines √©tapes
   - Recommandations pour la mod√©lisation
```

## Conclusion

L'analyse exploratoire des donn√©es est une comp√©tence fondamentale en Data Science. C'est un m√©lange d'art et de science qui n√©cessite :
- **Curiosit√©** : posez des questions sans cesse
- **Rigueur** : suivez une m√©thode syst√©matique
- **Cr√©ativit√©** : explorez sous diff√©rents angles
- **Esprit critique** : questionnez tout

Rappelez-vous : **l'EDA n'est jamais vraiment termin√©e**. M√™me apr√®s avoir construit des mod√®les, vous reviendrez souvent explorer vos donn√©es sous de nouveaux angles.

> "The data may not contain the answer. The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data." - John Tukey

## Ressources compl√©mentaires

### Livres
- **"Exploratory Data Analysis"** - John Tukey (le livre fondateur)
- **"The Art of Data Science"** - Roger Peng & Elizabeth Matsui
- **"Python for Data Analysis"** - Wes McKinney (cr√©ateur de Pandas)

### Cours en ligne
- [Exploratory Data Analysis with Python](https://www.coursera.org/learn/exploratory-data-analysis-python) - Coursera
- [Data Analysis with Python](https://www.freecodecamp.org/) - FreeCodeCamp

### Documentation
- [Pandas Documentation](https://pandas.pydata.org/docs/)
- [Seaborn Gallery](https://seaborn.pydata.org/examples/index.html)
- [Matplotlib Tutorials](https://matplotlib.org/stable/tutorials/index.html)

### Datasets pour pratiquer
- [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/)
- [Kaggle Datasets](https://www.kaggle.com/datasets)
- [Google Dataset Search](https://datasetsearch.research.google.com/)

---

*"Exploratory data analysis can never be the whole story, but nothing else can serve as the foundation stone." - John Tukey*

‚è≠Ô∏è Retour au [Sommaire](/SOMMAIRE.md)
