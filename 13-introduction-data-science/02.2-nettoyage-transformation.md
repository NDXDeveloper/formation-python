üîù Retour au [Sommaire](/SOMMAIRE.md)

# 13.2.2 Nettoyage et transformation de donn√©es

## Introduction

Dans le monde r√©el, les donn√©es sont rarement parfaites. Elles peuvent contenir des erreurs, des valeurs manquantes, des doublons, des formats incoh√©rents, et bien d'autres probl√®mes. Le **nettoyage de donn√©es** est une √©tape cruciale qui peut repr√©senter jusqu'√† 80% du temps d'un projet d'analyse de donn√©es.

Pandas offre des outils puissants pour nettoyer et transformer les donn√©es efficacement.

```python
import pandas as pd
import numpy as np
```

## Gestion des valeurs manquantes

### Comprendre les valeurs manquantes

Les valeurs manquantes (NaN - Not a Number) sont tr√®s courantes dans les datasets r√©els. Elles peuvent survenir pour diverses raisons :
- Donn√©es non collect√©es
- Erreurs de saisie
- Incompatibilit√© lors de fusion de donn√©es
- Fichiers corrompus

```python
# Cr√©er un DataFrame avec des valeurs manquantes
df = pd.DataFrame({
    'Nom': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],
    '√Çge': [25, np.nan, 35, 28, np.nan],
    'Ville': ['Paris', 'Lyon', None, 'Toulouse', 'Paris'],
    'Salaire': [35000, 42000, np.nan, 38000, 32000],
    'Email': ['alice@mail.com', None, 'charlie@mail.com', 'david@mail.com', None]
})

print("DataFrame avec valeurs manquantes:")
print(df)
```

**Sortie :**
```
       Nom   √Çge       Ville   Salaire            Email
0    Alice  25.0       Paris   35000.0  alice@mail.com
1      Bob   NaN        Lyon   42000.0             None
2  Charlie  35.0        None       NaN  charlie@mail.com
3    David  28.0    Toulouse   38000.0    david@mail.com
4      Eve   NaN       Paris   32000.0             None
```

### D√©tecter les valeurs manquantes

```python
# V√©rifier si des valeurs sont manquantes (renvoie True/False)
print("Valeurs manquantes (masque bool√©en):")
print(df.isnull())

# Alternative : isna() fait la m√™me chose
print("\nAvec isna():")
print(df.isna())

# V√©rifier les valeurs NON manquantes
print("\nValeurs pr√©sentes:")
print(df.notnull())
```

### Compter les valeurs manquantes

```python
# Nombre de valeurs manquantes par colonne
print("Nombre de NaN par colonne:")
print(df.isnull().sum())

# Pourcentage de valeurs manquantes
print("\nPourcentage de valeurs manquantes:")
print((df.isnull().sum() / len(df) * 100).round(2))

# Nombre total de valeurs manquantes
print(f"\nTotal de valeurs manquantes: {df.isnull().sum().sum()}")

# Lignes avec au moins une valeur manquante
lignes_avec_nan = df[df.isnull().any(axis=1)]
print(f"\nNombre de lignes avec NaN: {len(lignes_avec_nan)}")
```

### Supprimer les valeurs manquantes

#### Supprimer les lignes

```python
df = pd.DataFrame({
    'A': [1, 2, np.nan, 4],
    'B': [5, np.nan, np.nan, 8],
    'C': [9, 10, 11, 12]
})

print("DataFrame original:")
print(df)

# Supprimer toutes les lignes avec au moins un NaN
df_sans_nan = df.dropna()
print("\nSans aucune ligne contenant NaN:")
print(df_sans_nan)

# Supprimer seulement si TOUTES les valeurs sont NaN
df_sans_toutes_nan = df.dropna(how='all')
print("\nSans lignes enti√®rement NaN:")
print(df_sans_toutes_nan)

# Supprimer les lignes avec NaN dans des colonnes sp√©cifiques
df_sans_nan_colonne_a = df.dropna(subset=['A'])
print("\nSans NaN dans colonne A:")
print(df_sans_nan_colonne_a)

# Seuil : garder les lignes avec au moins N valeurs non-NaN
df_seuil = df.dropna(thresh=2)  # Au moins 2 valeurs non-NaN
print("\nLignes avec au moins 2 valeurs non-NaN:")
print(df_seuil)
```

#### Supprimer les colonnes

```python
df = pd.DataFrame({
    'A': [1, 2, 3, 4],
    'B': [np.nan, np.nan, np.nan, np.nan],
    'C': [5, 6, np.nan, 8]
})

print("DataFrame original:")
print(df)

# Supprimer les colonnes avec au moins un NaN
df_sans_col_nan = df.dropna(axis=1)
print("\nSans colonnes contenant NaN:")
print(df_sans_col_nan)

# Supprimer les colonnes enti√®rement NaN
df_sans_col_vide = df.dropna(axis=1, how='all')
print("\nSans colonnes enti√®rement NaN:")
print(df_sans_col_vide)
```

### Remplir les valeurs manquantes

#### Remplir avec une valeur constante

```python
df = pd.DataFrame({
    'Nom': ['Alice', 'Bob', 'Charlie'],
    '√Çge': [25, np.nan, 35],
    'Ville': ['Paris', None, 'Lyon'],
    'Score': [85, 90, np.nan]
})

print("DataFrame original:")
print(df)

# Remplir tous les NaN avec 0
df_rempli = df.fillna(0)
print("\nNaN remplac√©s par 0:")
print(df_rempli)

# Remplir avec une valeur sp√©cifique par colonne
df_rempli_dict = df.fillna({
    '√Çge': 30,
    'Ville': 'Inconnu',
    'Score': 0
})
print("\nNaN remplis avec valeurs sp√©cifiques:")
print(df_rempli_dict)

# Remplir seulement certaines colonnes
df_copie = df.copy()
df_copie['√Çge'].fillna(0, inplace=True)
print("\nSeulement colonne √Çge remplie:")
print(df_copie)
```

#### Remplir avec des statistiques

```python
df = pd.DataFrame({
    'A': [1, 2, np.nan, 4, 5, np.nan, 7],
    'B': [10, np.nan, 30, 40, np.nan, 60, 70],
    'C': [100, 200, 300, np.nan, 500, 600, 700]
})

print("DataFrame original:")
print(df)

# Remplir avec la moyenne
df_mean = df.fillna(df.mean())
print("\nNaN remplis avec la moyenne:")
print(df_mean)

# Remplir avec la m√©diane
df_median = df.fillna(df.median())
print("\nNaN remplis avec la m√©diane:")
print(df_median)

# Remplir avec le mode (valeur la plus fr√©quente)
df_mode = df.fillna(df.mode().iloc[0])
print("\nNaN remplis avec le mode:")
print(df_mode)
```

#### M√©thodes de propagation

```python
df = pd.DataFrame({
    'Valeur': [1, np.nan, np.nan, 4, np.nan, 6]
})

print("DataFrame original:")
print(df)

# Forward fill (ffill) : propager la derni√®re valeur valide
df_ffill = df.fillna(method='ffill')
print("\nForward fill (propagation avant):")
print(df_ffill)

# Backward fill (bfill) : propager la prochaine valeur valide
df_bfill = df.fillna(method='bfill')
print("\nBackward fill (propagation arri√®re):")
print(df_bfill)

# Limiter le nombre de propagations
df_ffill_limit = df.fillna(method='ffill', limit=1)
print("\nForward fill avec limite de 1:")
print(df_ffill_limit)
```

#### Interpolation

```python
df = pd.DataFrame({
    'Valeur': [1, np.nan, np.nan, 4, np.nan, 6]
})

print("DataFrame original:")
print(df)

# Interpolation lin√©aire
df_interpolated = df.interpolate()
print("\nInterpolation lin√©aire:")
print(df_interpolated)

# Interpolation polynomiale
df_poly = df.interpolate(method='polynomial', order=2)
print("\nInterpolation polynomiale:")
print(df_poly)
```

### Remplacer des valeurs sp√©cifiques

```python
df = pd.DataFrame({
    '√Çge': [25, -1, 35, 999, 28],
    'Ville': ['Paris', 'N/A', 'Lyon', 'Inconnu', 'Marseille'],
    'Score': [85, 0, 90, -999, 78]
})

print("DataFrame avec valeurs invalides:")
print(df)

# Remplacer une valeur sp√©cifique par NaN
df_clean = df.replace(-1, np.nan)
print("\n-1 remplac√© par NaN:")
print(df_clean)

# Remplacer plusieurs valeurs
df_clean = df.replace([-1, 999, -999], np.nan)
print("\nPlusieurs valeurs remplac√©es:")
print(df_clean)

# Remplacer par colonne
df_clean = df.replace({
    'Ville': {'N/A': np.nan, 'Inconnu': np.nan},
    'Score': {0: np.nan, -999: np.nan}
})
print("\nRemplacements par colonne:")
print(df_clean)

# Remplacer avec une regex (expressions r√©guli√®res)
df_clean = df.replace(to_replace=r'^N/A$', value=np.nan, regex=True)
print("\nRemplacement avec regex:")
print(df_clean)
```

## Gestion des doublons

### Identifier les doublons

```python
df = pd.DataFrame({
    'Nom': ['Alice', 'Bob', 'Alice', 'Charlie', 'Bob'],
    '√Çge': [25, 30, 25, 35, 30],
    'Ville': ['Paris', 'Lyon', 'Paris', 'Marseille', 'Lyon']
})

print("DataFrame avec doublons:")
print(df)

# Identifier les lignes dupliqu√©es (renvoie True/False)
print("\nLignes dupliqu√©es:")
print(df.duplicated())

# Afficher les lignes dupliqu√©es
print("\nLignes qui sont des doublons:")
print(df[df.duplicated()])

# Garder la premi√®re occurrence (marque les autres comme doublons)
print("\nDoublons (keep='first'):")
print(df.duplicated(keep='first'))

# Garder la derni√®re occurrence
print("\nDoublons (keep='last'):")
print(df.duplicated(keep='last'))

# Marquer TOUTES les occurrences comme doublons
print("\nDoublons (keep=False):")
print(df.duplicated(keep=False))
```

### Supprimer les doublons

```python
df = pd.DataFrame({
    'Nom': ['Alice', 'Bob', 'Alice', 'Charlie', 'Bob'],
    '√Çge': [25, 30, 25, 35, 30],
    'Ville': ['Paris', 'Lyon', 'Paris', 'Marseille', 'Lyon']
})

print("DataFrame original:")
print(df)

# Supprimer les doublons (garde la premi√®re occurrence)
df_sans_doublons = df.drop_duplicates()
print("\nSans doublons (premi√®re occurrence gard√©e):")
print(df_sans_doublons)

# Garder la derni√®re occurrence
df_last = df.drop_duplicates(keep='last')
print("\nSans doublons (derni√®re occurrence gard√©e):")
print(df_last)

# Consid√©rer seulement certaines colonnes
df_sans_doublons_nom = df.drop_duplicates(subset=['Nom'])
print("\nSans doublons sur colonne Nom:")
print(df_sans_doublons_nom)

# Consid√©rer plusieurs colonnes
df_sans_doublons_multiple = df.drop_duplicates(subset=['Nom', '√Çge'])
print("\nSans doublons sur Nom et √Çge:")
print(df_sans_doublons_multiple)
```

## Transformation de types de donn√©es

### V√©rifier les types

```python
df = pd.DataFrame({
    'Entier': [1, 2, 3],
    'Flottant': [1.5, 2.5, 3.5],
    'Texte': ['a', 'b', 'c'],
    'Booleen': [True, False, True]
})

# Afficher les types de chaque colonne
print("Types de donn√©es:")
print(df.dtypes)

# Informations d√©taill√©es
print("\nInformations:")
df.info()
```

### Convertir les types

```python
df = pd.DataFrame({
    'A': ['1', '2', '3', '4'],
    'B': ['1.5', '2.5', '3.5', '4.5'],
    'C': ['True', 'False', 'True', 'False']
})

print("Types originaux:")
print(df.dtypes)
print("\nDataFrame:")
print(df)

# Convertir en entier
df['A'] = df['A'].astype(int)
print("\nColonne A convertie en int:")
print(df['A'].dtype)

# Convertir en float
df['B'] = df['B'].astype(float)
print("Colonne B convertie en float:")
print(df['B'].dtype)

# Convertir en bool√©en
df['C'] = df['C'].map({'True': True, 'False': False})
print("Colonne C convertie en bool:")
print(df['C'].dtype)

print("\nDataFrame final:")
print(df)
```

### Conversion avec to_numeric

```python
df = pd.DataFrame({
    'Valeur': ['1', '2', '3', 'quatre', '5']
})

print("DataFrame original:")
print(df)

# Convertir en num√©rique (erreurs = NaN)
df['Valeur_num'] = pd.to_numeric(df['Valeur'], errors='coerce')
print("\nConversion avec erreurs -> NaN:")
print(df)

# Ignorer les erreurs (garde la valeur originale)
df['Valeur_num2'] = pd.to_numeric(df['Valeur'], errors='ignore')
print("\nConversion avec erreurs ignor√©es:")
print(df)
```

### Cat√©gories

```python
# Les cat√©gories sont efficaces pour les colonnes avec peu de valeurs uniques
df = pd.DataFrame({
    'Ville': ['Paris', 'Lyon', 'Paris', 'Marseille', 'Lyon', 'Paris'] * 1000
})

print(f"Taille en m√©moire (object): {df.memory_usage(deep=True).sum()} bytes")

# Convertir en cat√©gorie
df['Ville'] = df['Ville'].astype('category')
print(f"Taille en m√©moire (category): {df.memory_usage(deep=True).sum()} bytes")

print("\nType de Ville:")
print(df['Ville'].dtype)

print("\nCat√©gories uniques:")
print(df['Ville'].cat.categories)
```

## Manipulation de cha√Ænes de caract√®res

### M√©thodes de base

```python
df = pd.DataFrame({
    'Nom': ['alice', 'BOB', 'Charlie', 'DAVID'],
    'Email': ['alice@mail.com', 'bob@MAIL.com', 'charlie@mail.COM', 'david@mail.com']
})

print("DataFrame original:")
print(df)

# Convertir en majuscules
df['Nom_maj'] = df['Nom'].str.upper()
print("\nEn majuscules:")
print(df[['Nom', 'Nom_maj']])

# Convertir en minuscules
df['Email_min'] = df['Email'].str.lower()
print("\nEmail en minuscules:")
print(df[['Email', 'Email_min']])

# Capitaliser (premi√®re lettre en majuscule)
df['Nom_cap'] = df['Nom'].str.capitalize()
print("\nNom capitalis√©:")
print(df[['Nom', 'Nom_cap']])

# Title case (premi√®re lettre de chaque mot)
df['Nom_title'] = df['Nom'].str.title()
print("\nTitle case:")
print(df[['Nom', 'Nom_title']])
```

### Nettoyage de texte

```python
df = pd.DataFrame({
    'Texte': ['  Alice  ', 'Bob\n', '\tCharlie', '  David\n  ']
})

print("DataFrame original (avec espaces):")
print(repr(df['Texte'].tolist()))

# Supprimer les espaces aux extr√©mit√©s
df['Texte_clean'] = df['Texte'].str.strip()
print("\nApr√®s strip():")
print(repr(df['Texte_clean'].tolist()))

# Supprimer seulement √† gauche
df['Texte_lstrip'] = df['Texte'].str.lstrip()
print("\nApr√®s lstrip():")
print(repr(df['Texte_lstrip'].tolist()))

# Supprimer seulement √† droite
df['Texte_rstrip'] = df['Texte'].str.rstrip()
print("\nApr√®s rstrip():")
print(repr(df['Texte_rstrip'].tolist()))
```

### Recherche et remplacement

```python
df = pd.DataFrame({
    'Texte': ['Bonjour le monde', 'Python est g√©nial', 'Pandas pour tous', 'Bonjour Python']
})

print("DataFrame original:")
print(df)

# V√©rifier si contient une cha√Æne
df['Contient_Python'] = df['Texte'].str.contains('Python')
print("\nContient 'Python':")
print(df[['Texte', 'Contient_Python']])

# V√©rifier si commence par
df['Commence_Bonjour'] = df['Texte'].str.startswith('Bonjour')
print("\nCommence par 'Bonjour':")
print(df[['Texte', 'Commence_Bonjour']])

# V√©rifier si finit par
df['Finit_tous'] = df['Texte'].str.endswith('tous')
print("\nFinit par 'tous':")
print(df[['Texte', 'Finit_tous']])

# Remplacer
df['Texte_remplace'] = df['Texte'].str.replace('Python', 'Java')
print("\nPython remplac√© par Java:")
print(df[['Texte', 'Texte_remplace']])
```

### Extraction et division

```python
df = pd.DataFrame({
    'Email': ['alice@gmail.com', 'bob@yahoo.fr', 'charlie@hotmail.com']
})

print("DataFrame original:")
print(df)

# Extraire avant le @
df['Utilisateur'] = df['Email'].str.split('@').str[0]
print("\nUtilisateur extrait:")
print(df[['Email', 'Utilisateur']])

# Extraire apr√®s le @
df['Domaine'] = df['Email'].str.split('@').str[1]
print("\nDomaine extrait:")
print(df[['Email', 'Domaine']])

# Split en plusieurs colonnes
df[['User', 'Domain']] = df['Email'].str.split('@', expand=True)
print("\nSplit en colonnes:")
print(df)
```

### Longueur et comptage

```python
df = pd.DataFrame({
    'Texte': ['Bonjour', 'Python est super', 'Pandas', 'Data Science']
})

# Longueur de la cha√Æne
df['Longueur'] = df['Texte'].str.len()
print("Avec longueur:")
print(df)

# Compter les occurrences
df['Nombre_e'] = df['Texte'].str.count('e')
print("\nNombre de 'e':")
print(df[['Texte', 'Nombre_e']])
```

## Manipulation de dates

### Conversion en datetime

```python
df = pd.DataFrame({
    'Date_str': ['2024-01-01', '2024-02-15', '2024-03-30'],
    'Heure_str': ['10:30:00', '14:45:30', '09:15:00']
})

print("DataFrame original:")
print(df)
print("\nTypes:")
print(df.dtypes)

# Convertir en datetime
df['Date'] = pd.to_datetime(df['Date_str'])
print("\nApr√®s conversion:")
print(df)
print("\nTypes:")
print(df.dtypes)
```

### Diff√©rents formats de dates

```python
# Format europ√©en (jour/mois/ann√©e)
dates_eur = pd.Series(['15/01/2024', '20/02/2024', '10/03/2024'])
dates_conv = pd.to_datetime(dates_eur, format='%d/%m/%Y')
print("Dates europ√©ennes converties:")
print(dates_conv)

# Format am√©ricain (mois/jour/ann√©e)
dates_us = pd.Series(['01/15/2024', '02/20/2024', '03/10/2024'])
dates_conv = pd.to_datetime(dates_us, format='%m/%d/%Y')
print("\nDates am√©ricaines converties:")
print(dates_conv)

# Dates avec heure
dates_time = pd.Series(['2024-01-15 14:30:00', '2024-02-20 09:15:30'])
dates_conv = pd.to_datetime(dates_time)
print("\nDates avec heure:")
print(dates_conv)
```

### Extraire des composants de date

```python
df = pd.DataFrame({
    'Date': pd.to_datetime(['2024-01-15', '2024-06-20', '2024-12-25'])
})

print("DataFrame original:")
print(df)

# Extraire l'ann√©e
df['Ann√©e'] = df['Date'].dt.year
print("\nAvec ann√©e:")
print(df)

# Extraire le mois
df['Mois'] = df['Date'].dt.month
print("\nAvec mois:")
print(df)

# Nom du mois
df['Nom_mois'] = df['Date'].dt.month_name()
print("\nAvec nom du mois:")
print(df)

# Jour du mois
df['Jour'] = df['Date'].dt.day
print("\nAvec jour:")
print(df)

# Jour de la semaine (0 = lundi, 6 = dimanche)
df['Jour_semaine'] = df['Date'].dt.dayofweek
df['Nom_jour'] = df['Date'].dt.day_name()
print("\nAvec jour de la semaine:")
print(df[['Date', 'Jour_semaine', 'Nom_jour']])

# Trimestre
df['Trimestre'] = df['Date'].dt.quarter
print("\nAvec trimestre:")
print(df[['Date', 'Trimestre']])
```

### Calculs avec les dates

```python
df = pd.DataFrame({
    'Date_debut': pd.to_datetime(['2024-01-01', '2024-02-01', '2024-03-01']),
    'Date_fin': pd.to_datetime(['2024-01-15', '2024-02-29', '2024-03-31'])
})

print("DataFrame original:")
print(df)

# Calculer la diff√©rence (retourne un Timedelta)
df['Dur√©e'] = df['Date_fin'] - df['Date_debut']
print("\nAvec dur√©e:")
print(df)

# Dur√©e en jours
df['Dur√©e_jours'] = (df['Date_fin'] - df['Date_debut']).dt.days
print("\nDur√©e en jours:")
print(df)

# Ajouter des jours
df['Dans_10_jours'] = df['Date_debut'] + pd.Timedelta(days=10)
print("\nDate + 10 jours:")
print(df[['Date_debut', 'Dans_10_jours']])

# Ajouter des mois
df['Dans_1_mois'] = df['Date_debut'] + pd.DateOffset(months=1)
print("\nDate + 1 mois:")
print(df[['Date_debut', 'Dans_1_mois']])
```

## Renommage et r√©organisation

### Renommer les colonnes

```python
df = pd.DataFrame({
    'nom_client': ['Alice', 'Bob', 'Charlie'],
    'age_client': [25, 30, 35],
    'ville_client': ['Paris', 'Lyon', 'Marseille']
})

print("DataFrame original:")
print(df)

# Renommer des colonnes sp√©cifiques
df_renomme = df.rename(columns={
    'nom_client': 'Nom',
    'age_client': '√Çge',
    'ville_client': 'Ville'
})
print("\nColonnes renomm√©es:")
print(df_renomme)

# Renommer avec une fonction
df_upper = df.rename(columns=str.upper)
print("\nColonnes en majuscules:")
print(df_upper)

# Renommer l'index
df_index = df.rename(index={0: 'Premier', 1: 'Deuxi√®me', 2: 'Troisi√®me'})
print("\nIndex renomm√©:")
print(df_index)
```

### R√©organiser les colonnes

```python
df = pd.DataFrame({
    'D': [1, 2, 3],
    'A': [4, 5, 6],
    'C': [7, 8, 9],
    'B': [10, 11, 12]
})

print("DataFrame original:")
print(df)

# R√©organiser dans un ordre sp√©cifique
df_reorg = df[['A', 'B', 'C', 'D']]
print("\nColonnes r√©organis√©es:")
print(df_reorg)

# Mettre une colonne en premier
cols = ['D'] + [col for col in df.columns if col != 'D']
df_reorg2 = df[cols]
print("\nD en premier:")
print(df_reorg2)
```

### R√©initialiser et d√©finir l'index

```python
df = pd.DataFrame({
    'Nom': ['Alice', 'Bob', 'Charlie'],
    '√Çge': [25, 30, 35],
    'Ville': ['Paris', 'Lyon', 'Marseille']
}, index=['A', 'B', 'C'])

print("DataFrame original:")
print(df)

# R√©initialiser l'index (devient une colonne)
df_reset = df.reset_index()
print("\nIndex r√©initialis√©:")
print(df_reset)

# D√©finir une colonne comme index
df_index = df.reset_index().set_index('Nom')
print("\nNom comme index:")
print(df_index)

# R√©initialiser sans cr√©er de colonne
df_reset_drop = df.reset_index(drop=True)
print("\nIndex r√©initialis√© (sans garder l'ancien):")
print(df_reset_drop)
```

## Transformation de donn√©es avec apply, map, et replace

### apply() - Appliquer une fonction

```python
df = pd.DataFrame({
    'Nom': ['Alice', 'Bob', 'Charlie'],
    '√Çge': [25, 30, 35],
    'Salaire': [35000, 42000, 48000]
})

print("DataFrame original:")
print(df)

# Appliquer une fonction √† une colonne
def categoriser_age(age):
    if age < 30:
        return 'Jeune'
    elif age < 40:
        return 'Adulte'
    else:
        return 'Senior'

df['Cat√©gorie_√¢ge'] = df['√Çge'].apply(categoriser_age)
print("\nAvec cat√©gorie d'√¢ge:")
print(df)

# Fonction lambda
df['Salaire_mensuel'] = df['Salaire'].apply(lambda x: x / 12)
print("\nAvec salaire mensuel:")
print(df)

# apply sur plusieurs colonnes (axis=1 pour lignes)
def salaire_par_age(row):
    return row['Salaire'] / row['√Çge']

df['Ratio'] = df.apply(salaire_par_age, axis=1)
print("\nAvec ratio salaire/√¢ge:")
print(df)
```

### map() - Mapper des valeurs

```python
df = pd.DataFrame({
    'Ville': ['Paris', 'Lyon', 'Marseille', 'Paris', 'Lyon']
})

print("DataFrame original:")
print(df)

# Dictionnaire de mapping
code_postal = {
    'Paris': 75000,
    'Lyon': 69000,
    'Marseille': 13000
}

df['Code_postal'] = df['Ville'].map(code_postal)
print("\nAvec code postal:")
print(df)

# map avec une fonction
df['Ville_upper'] = df['Ville'].map(str.upper)
print("\nVille en majuscules:")
print(df)

# map pour transformer les valeurs
niveau_etudes = {'Bac': 1, 'Licence': 2, 'Master': 3}
df_etudes = pd.DataFrame({'Dipl√¥me': ['Bac', 'Master', 'Licence', 'Master']})
df_etudes['Niveau'] = df_etudes['Dipl√¥me'].map(niveau_etudes)
print("\nNiveau d'√©tudes:")
print(df_etudes)
```

### replace() - Remplacer des valeurs

```python
df = pd.DataFrame({
    'Note': ['A', 'B', 'C', 'A', 'D'],
    'Statut': ['Actif', 'Inactif', 'Actif', 'Suspendu', 'Actif']
})

print("DataFrame original:")
print(df)

# Remplacer une valeur par une autre
df_remplace = df.replace('Actif', 'En service')
print("\nActif remplac√©:")
print(df_remplace)

# Remplacer avec un dictionnaire
df_remplace = df.replace({
    'A': 'Excellent',
    'B': 'Bien',
    'C': 'Moyen',
    'D': 'Insuffisant'
})
print("\nNotes converties:")
print(df_remplace)

# Remplacer par colonne
df_remplace = df.replace({
    'Note': {'A': 20, 'B': 15, 'C': 10, 'D': 5},
    'Statut': {'Actif': 1, 'Inactif': 0, 'Suspendu': -1}
})
print("\nRemplacements par colonne:")
print(df_remplace)
```

## Reshaping : Pivoter et restructurer

### pivot() - Cr√©er un tableau crois√©

```python
df = pd.DataFrame({
    'Date': ['2024-01', '2024-01', '2024-02', '2024-02'],
    'Produit': ['A', 'B', 'A', 'B'],
    'Ventes': [100, 150, 120, 180]
})

print("DataFrame original:")
print(df)

# Pivoter : Date en index, Produit en colonnes
df_pivot = df.pivot(index='Date', columns='Produit', values='Ventes')
print("\nDataFrame pivot√©:")
print(df_pivot)
```

### pivot_table() - Tableau crois√© avec agr√©gation

```python
df = pd.DataFrame({
    'Date': ['2024-01', '2024-01', '2024-01', '2024-02', '2024-02', '2024-02'],
    'Produit': ['A', 'A', 'B', 'A', 'B', 'B'],
    'Ventes': [100, 110, 150, 120, 180, 190],
    'Quantit√©': [5, 6, 8, 7, 9, 10]
})

print("DataFrame original:")
print(df)

# Tableau crois√© avec somme
pivot = pd.pivot_table(df,
                       values='Ventes',
                       index='Date',
                       columns='Produit',
                       aggfunc='sum')
print("\nTableau crois√© (somme des ventes):")
print(pivot)

# Avec plusieurs fonctions d'agr√©gation
pivot = pd.pivot_table(df,
                       values='Ventes',
                       index='Date',
                       columns='Produit',
                       aggfunc=['sum', 'mean'])
print("\nAvec somme et moyenne:")
print(pivot)

# Avec totaux
pivot = pd.pivot_table(df,
                       values='Ventes',
                       index='Date',
                       columns='Produit',
                       aggfunc='sum',
                       margins=True,
                       margins_name='Total')
print("\nAvec lignes et colonnes de totaux:")
print(pivot)
```

### melt() - Passer de large √† long

```python
df = pd.DataFrame({
    'Produit': ['A', 'B'],
    'Jan': [100, 150],
    'Fev': [120, 180],
    'Mar': [110, 170]
})

print("DataFrame large:")
print(df)

# Transformer en format long
df_long = df.melt(id_vars=['Produit'],
                  var_name='Mois',
                  value_name='Ventes')
print("\nDataFrame long:")
print(df_long)
```

### stack() et unstack()

```python
# Cr√©er un DataFrame avec MultiIndex
df = pd.DataFrame({
    'A': [1, 2, 3],
    'B': [4, 5, 6],
    'C': [7, 8, 9]
}, index=['X', 'Y', 'Z'])

print("DataFrame original:")
print(df)

# stack : colonnes vers index (format long)
df_stacked = df.stack()
print("\nApr√®s stack (Series):")
print(df_stacked)

# unstack : index vers colonnes (format large)
df_unstacked = df_stacked.unstack()
print("\nApr√®s unstack:")
print(df_unstacked)
```

## Concat√©nation et fusion

### concat() - Concat√©ner des DataFrames

```python
df1 = pd.DataFrame({
    'A': [1, 2, 3],
    'B': [4, 5, 6]
})

df2 = pd.DataFrame({
    'A': [7, 8, 9],
    'B': [10, 11, 12]
})

print("DataFrame 1:")
print(df1)
print("\nDataFrame 2:")
print(df2)

# Concat√©ner verticalement (empiler)
df_concat = pd.concat([df1, df2])
print("\nConcat√©nation verticale:")
print(df_concat)

# R√©initialiser l'index
df_concat_reset = pd.concat([df1, df2], ignore_index=True)
print("\nAvec index r√©initialis√©:")
print(df_concat_reset)

# Concat√©ner horizontalement (c√¥te √† c√¥te)
df3 = pd.DataFrame({
    'C': [13, 14, 15],
    'D': [16, 17, 18]
})

df_concat_h = pd.concat([df1, df3], axis=1)
print("\nConcat√©nation horizontale:")
print(df_concat_h)
```

### merge() - Fusionner comme SQL

```python
# DataFrame des employ√©s
employes = pd.DataFrame({
    'ID': [1, 2, 3, 4],
    'Nom': ['Alice', 'Bob', 'Charlie', 'David'],
    'Dept_ID': [101, 102, 101, 103]
})

# DataFrame des d√©partements
departements = pd.DataFrame({
    'Dept_ID': [101, 102, 103],
    'D√©partement': ['Ventes', 'IT', 'RH']
})

print("Employ√©s:")
print(employes)
print("\nD√©partements:")
print(departements)

# Fusion inner (intersection)
df_merge = pd.merge(employes, departements, on='Dept_ID')
print("\nFusion inner:")
print(df_merge)

# Fusion left (tous les employ√©s)
employes2 = pd.DataFrame({
    'ID': [1, 2, 3, 4, 5],
    'Nom': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],
    'Dept_ID': [101, 102, 101, 103, 999]  # 999 n'existe pas
})

df_merge_left = pd.merge(employes2, departements, on='Dept_ID', how='left')
print("\nFusion left:")
print(df_merge_left)

# Fusion right
df_merge_right = pd.merge(employes, departements, on='Dept_ID', how='right')
print("\nFusion right:")
print(df_merge_right)

# Fusion outer (union)
df_merge_outer = pd.merge(employes2, departements, on='Dept_ID', how='outer')
print("\nFusion outer:")
print(df_merge_outer)
```

## Exemples pratiques complets

### Exemple 1 : Nettoyage d'un dataset de ventes

```python
# Dataset avec probl√®mes
df = pd.DataFrame({
    'Date': ['2024-01-01', '2024-01-02', None, '2024-01-04', '2024-01-05'],
    'Produit': ['Laptop', 'Souris', 'Clavier', 'Laptop', 'Souris'],
    'Quantit√©': [2, None, 5, 1, 8],
    'Prix': [800, 25, 60, 800, None],
    'Client': ['  Alice  ', 'BOB', 'Charlie', 'Alice', '  bob  ']
})

print("Dataset original (avec probl√®mes):")
print(df)

# 1. Nettoyer les noms de clients
df['Client'] = df['Client'].str.strip().str.title()

# 2. Convertir la date
df['Date'] = pd.to_datetime(df['Date'])

# 3. G√©rer les valeurs manquantes
df['Quantit√©'].fillna(df['Quantit√©'].median(), inplace=True)
df['Prix'].fillna(method='ffill', inplace=True)
df.dropna(subset=['Date'], inplace=True)

# 4. Calculer le montant
df['Montant'] = df['Quantit√©'] * df['Prix']

# 5. R√©organiser les colonnes
df = df[['Date', 'Client', 'Produit', 'Quantit√©', 'Prix', 'Montant']]

print("\nDataset nettoy√©:")
print(df)

# Analyse
print("\n--- Analyse ---")
print(f"Total des ventes: {df['Montant'].sum():.2f}‚Ç¨")
print(f"Nombre de transactions: {len(df)}")
print("\nVentes par client:")
print(df.groupby('Client')['Montant'].sum())
```

### Exemple 2 : Transformation de donn√©es d'enqu√™te

```python
# Donn√©es d'enqu√™te en format large
df = pd.DataFrame({
    'ID': [1, 2, 3],
    'Nom': ['Alice', 'Bob', 'Charlie'],
    'Q1_Satisfaction': [5, 4, 3],
    'Q2_Recommandation': [5, 5, 4],
    'Q3_Prix': [3, 4, 5]
})

print("Format large:")
print(df)

# Transformer en format long
df_long = df.melt(id_vars=['ID', 'Nom'],
                  var_name='Question',
                  value_name='Score')

print("\nFormat long:")
print(df_long)

# Nettoyer les noms de questions
df_long['Question'] = df_long['Question'].str.replace('Q\\d+_', '', regex=True)

print("\nQuestions nettoy√©es:")
print(df_long)

# Calculer la moyenne par question
moyenne_par_question = df_long.groupby('Question')['Score'].mean()
print("\nMoyenne par question:")
print(moyenne_par_question)

# Retourner au format large
df_pivot = df_long.pivot(index=['ID', 'Nom'],
                          columns='Question',
                          values='Score')
print("\nRetour au format large:")
print(df_pivot)
```

### Exemple 3 : Combinaison de plusieurs sources

```python
# Ventes janvier
ventes_jan = pd.DataFrame({
    'Produit': ['A', 'B', 'C'],
    'Ventes': [100, 150, 200],
    'Mois': ['Jan', 'Jan', 'Jan']
})

# Ventes f√©vrier
ventes_fev = pd.DataFrame({
    'Produit': ['A', 'B', 'C'],
    'Ventes': [120, 140, 210],
    'Mois': ['Fev', 'Fev', 'Fev']
})

# Informations produits
produits = pd.DataFrame({
    'Produit': ['A', 'B', 'C'],
    'Nom': ['Laptop', 'Souris', 'Clavier'],
    'Cat√©gorie': ['Ordinateur', 'Accessoire', 'Accessoire'],
    'Prix': [800, 25, 60]
})

print("Ventes janvier:")
print(ventes_jan)
print("\nVentes f√©vrier:")
print(ventes_fev)
print("\nInfos produits:")
print(produits)

# Combiner les ventes
ventes_total = pd.concat([ventes_jan, ventes_fev], ignore_index=True)
print("\nVentes combin√©es:")
print(ventes_total)

# Ajouter les infos produits
ventes_complet = pd.merge(ventes_total, produits, on='Produit')
print("\nVentes avec infos produits:")
print(ventes_complet)

# Calculer le chiffre d'affaires
ventes_complet['CA'] = ventes_complet['Ventes'] * ventes_complet['Prix']
print("\nAvec chiffre d'affaires:")
print(ventes_complet)

# Analyse par cat√©gorie et mois
analyse = ventes_complet.groupby(['Cat√©gorie', 'Mois'])['CA'].sum().unstack()
print("\nCA par cat√©gorie et mois:")
print(analyse)
```

### Exemple 4 : Nettoyage de donn√©es de capteurs

```python
# Donn√©es de capteurs avec valeurs aberrantes
np.random.seed(42)
dates = pd.date_range('2024-01-01', periods=20, freq='H')
temperatures = np.random.normal(20, 2, 20)
# Ajouter des valeurs aberrantes
temperatures[5] = -999  # Erreur de capteur
temperatures[15] = 150  # Erreur de capteur

df = pd.DataFrame({
    'DateTime': dates,
    'Temp√©rature': temperatures,
    'Humidit√©': np.random.normal(60, 5, 20)
})

print("Donn√©es brutes (avec erreurs):")
print(df)

# Identifier et corriger les valeurs aberrantes
# Valeurs physiquement impossibles
df.loc[df['Temp√©rature'] < -50, 'Temp√©rature'] = np.nan
df.loc[df['Temp√©rature'] > 60, 'Temp√©rature'] = np.nan

print("\nApr√®s nettoyage des valeurs impossibles:")
print(df)

# Remplir avec interpolation
df['Temp√©rature'].interpolate(inplace=True)

print("\nApr√®s interpolation:")
print(df[['DateTime', 'Temp√©rature']].head(10))

# Extraire les composants de date
df['Heure'] = df['DateTime'].dt.hour
df['Date'] = df['DateTime'].dt.date

# Statistiques par heure
stats_heure = df.groupby('Heure')['Temp√©rature'].agg(['mean', 'min', 'max'])
print("\nStatistiques par heure:")
print(stats_heure)
```

## Bonnes pratiques

### 1. Toujours faire une copie avant modification majeure

```python
# ‚úÖ Bon
df_clean = df.copy()
df_clean['Colonne'] = df_clean['Colonne'].fillna(0)

# ‚ùå Risqu√©
# df['Colonne'] = df['Colonne'].fillna(0)  # Modifie l'original
```

### 2. Documenter les transformations

```python
# ‚úÖ Bon : code document√©
# √âtape 1 : Supprimer les valeurs manquantes
df = df.dropna(subset=['Colonne_importante'])

# √âtape 2 : Normaliser les noms
df['Nom'] = df['Nom'].str.strip().str.title()

# √âtape 3 : Convertir les dates
df['Date'] = pd.to_datetime(df['Date'])
```

### 3. V√©rifier les donn√©es √† chaque √©tape

```python
# ‚úÖ Bon
print("Avant nettoyage:")
print(df.isnull().sum())

df = df.dropna()

print("\nApr√®s nettoyage:")
print(df.isnull().sum())
print(f"Nombre de lignes: {len(df)}")
```

### 4. Utiliser des m√©thodes appropri√©es

```python
# ‚ùå Moins performant
df['Nouvelle_col'] = [x * 2 for x in df['Ancienne_col']]

# ‚úÖ Meilleur (vectoris√©)
df['Nouvelle_col'] = df['Ancienne_col'] * 2
```

### 5. G√©rer les cas limites

```python
# ‚úÖ Bon : g√©rer les erreurs potentielles
df['Num√©rique'] = pd.to_numeric(df['Colonne'], errors='coerce')

# V√©rifier s'il y a des conversions √©chou√©es
nb_echecs = df['Num√©rique'].isnull().sum() - df['Colonne'].isnull().sum()
if nb_echecs > 0:
    print(f"Attention: {nb_echecs} valeurs n'ont pas pu √™tre converties")
```

## R√©sum√©

Le nettoyage et la transformation de donn√©es sont des √©tapes essentielles de l'analyse de donn√©es. Pandas offre des outils complets pour :

**Nettoyage :**
- G√©rer les valeurs manquantes (d√©tection, suppression, remplissage)
- Supprimer les doublons
- Corriger les types de donn√©es
- Nettoyer les cha√Ænes de caract√®res

**Transformation :**
- Manipuler les dates (conversion, extraction, calculs)
- Renommer et r√©organiser
- Appliquer des fonctions (apply, map, replace)
- Pivoter et restructurer (pivot, melt, stack/unstack)
- Combiner des donn√©es (concat, merge)

**Points cl√©s √† retenir :**
1. Toujours v√©rifier les donn√©es avant et apr√®s transformation
2. Documenter vos √©tapes de nettoyage
3. Utiliser des m√©thodes vectoris√©es pour de meilleures performances
4. G√©rer les cas limites et les erreurs potentielles
5. Faire des copies si n√©cessaire pour pr√©server les donn√©es originales

Dans la section suivante, nous explorerons les op√©rations de regroupement (GroupBy) et d'agr√©gation qui permettent d'analyser les donn√©es transform√©es de mani√®re plus approfondie.

‚è≠Ô∏è [GroupBy et agr√©gations](/13-introduction-data-science/02.3-groupby-et-agregations.md)
