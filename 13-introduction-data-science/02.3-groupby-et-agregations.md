üîù Retour au [Sommaire](/SOMMAIRE.md)

# 13.2.3 GroupBy et agr√©gations

## Introduction

L'une des op√©rations les plus puissantes dans l'analyse de donn√©es est la capacit√© de **regrouper** des donn√©es et d'effectuer des **calculs par groupe**. Par exemple :
- Calculer les ventes totales par ville
- Trouver la moyenne des notes par classe
- Compter le nombre de clients par cat√©gorie

Pandas offre la m√©thode `groupby()` qui permet d'effectuer ces op√©rations facilement et efficacement.

```python
import pandas as pd
import numpy as np
```

## Le concept Split-Apply-Combine

La m√©thode `groupby()` suit un paradigme en trois √©tapes appel√© **Split-Apply-Combine** :

1. **Split (Diviser)** : Les donn√©es sont divis√©es en groupes selon un crit√®re
2. **Apply (Appliquer)** : Une fonction est appliqu√©e ind√©pendamment √† chaque groupe
3. **Combine (Combiner)** : Les r√©sultats sont combin√©s en une structure de donn√©es

```python
# Visualisation conceptuelle
#
# Donn√©es originales:
#    Ville      Ventes
# 0  Paris      100
# 1  Lyon       150
# 2  Paris      120
# 3  Lyon       180
#
# SPLIT par Ville:
# Groupe Paris: [100, 120]
# Groupe Lyon:  [150, 180]
#
# APPLY (somme):
# Paris: 220
# Lyon:  330
#
# COMBINE:
# Ville
# Lyon     330
# Paris    220
```

## GroupBy de base

### Grouper par une colonne

```python
# Cr√©er un DataFrame d'exemple
df = pd.DataFrame({
    'Ville': ['Paris', 'Lyon', 'Paris', 'Lyon', 'Marseille', 'Paris'],
    'Produit': ['A', 'A', 'B', 'B', 'A', 'A'],
    'Ventes': [100, 150, 120, 180, 90, 110],
    'Quantit√©': [5, 8, 6, 9, 4, 5]
})

print("DataFrame original:")
print(df)

# Grouper par ville et calculer la somme
ventes_par_ville = df.groupby('Ville')['Ventes'].sum()
print("\nVentes totales par ville:")
print(ventes_par_ville)
```

**Sortie :**
```
Ville
Lyon         330
Marseille     90
Paris        330
Name: Ventes, dtype: int64
```

### Comprendre l'objet GroupBy

```python
# Cr√©er un objet GroupBy
groupe = df.groupby('Ville')
print("Type de l'objet:", type(groupe))
print("Nombre de groupes:", groupe.ngroups)
print("Noms des groupes:", list(groupe.groups.keys()))

# Voir le contenu de chaque groupe
print("\nContenu des groupes:")
for nom, groupe_df in groupe:
    print(f"\n--- Groupe: {nom} ---")
    print(groupe_df)
```

### Acc√©der √† un groupe sp√©cifique

```python
# Obtenir un groupe sp√©cifique
groupe_paris = df.groupby('Ville').get_group('Paris')
print("Groupe Paris:")
print(groupe_paris)
```

## Fonctions d'agr√©gation courantes

### sum() - Somme

```python
df = pd.DataFrame({
    'Cat√©gorie': ['A', 'B', 'A', 'B', 'A'],
    'Ventes': [100, 150, 120, 180, 90],
    'Quantit√©': [5, 8, 6, 9, 4]
})

# Somme des ventes par cat√©gorie
print("Somme par cat√©gorie:")
print(df.groupby('Cat√©gorie')['Ventes'].sum())

# Somme sur toutes les colonnes num√©riques
print("\nSomme sur toutes les colonnes:")
print(df.groupby('Cat√©gorie').sum())
```

### mean() - Moyenne

```python
# Moyenne des ventes par cat√©gorie
print("Moyenne par cat√©gorie:")
print(df.groupby('Cat√©gorie')['Ventes'].mean())
```

### count() - Comptage

```python
# Compter le nombre d'entr√©es par cat√©gorie
print("Nombre d'entr√©es par cat√©gorie:")
print(df.groupby('Cat√©gorie')['Ventes'].count())

# Alternative : size() compte aussi les valeurs NaN
print("\nAvec size():")
print(df.groupby('Cat√©gorie').size())
```

### min() et max() - Minimum et Maximum

```python
# Minimum et maximum par cat√©gorie
print("Ventes minimales par cat√©gorie:")
print(df.groupby('Cat√©gorie')['Ventes'].min())

print("\nVentes maximales par cat√©gorie:")
print(df.groupby('Cat√©gorie')['Ventes'].max())
```

### std() et var() - √âcart-type et Variance

```python
# √âcart-type des ventes par cat√©gorie
print("√âcart-type par cat√©gorie:")
print(df.groupby('Cat√©gorie')['Ventes'].std())

# Variance
print("\nVariance par cat√©gorie:")
print(df.groupby('Cat√©gorie')['Ventes'].var())
```

### median() - M√©diane

```python
# M√©diane des ventes par cat√©gorie
print("M√©diane par cat√©gorie:")
print(df.groupby('Cat√©gorie')['Ventes'].median())
```

## Agr√©gations multiples avec agg()

### Une fonction sur plusieurs colonnes

```python
df = pd.DataFrame({
    'Ville': ['Paris', 'Lyon', 'Paris', 'Lyon', 'Marseille'],
    'Produit': ['A', 'A', 'B', 'B', 'A'],
    'Ventes': [100, 150, 120, 180, 90],
    'Quantit√©': [5, 8, 6, 9, 4]
})

# Calculer la somme de plusieurs colonnes
resultat = df.groupby('Ville')[['Ventes', 'Quantit√©']].sum()
print("Somme des ventes et quantit√©s par ville:")
print(resultat)
```

### Plusieurs fonctions sur une colonne

```python
# Appliquer plusieurs fonctions d'agr√©gation
stats = df.groupby('Ville')['Ventes'].agg(['sum', 'mean', 'min', 'max', 'count'])
print("Statistiques des ventes par ville:")
print(stats)
```

### Fonctions diff√©rentes pour diff√©rentes colonnes

```python
# Agr√©gations personnalis√©es par colonne
resultat = df.groupby('Ville').agg({
    'Ventes': ['sum', 'mean'],
    'Quantit√©': ['sum', 'max']
})
print("Agr√©gations personnalis√©es:")
print(resultat)
```

### Nommer les colonnes agr√©g√©es

```python
# Utiliser des noms personnalis√©s pour les colonnes
resultat = df.groupby('Ville').agg(
    Ventes_totales=('Ventes', 'sum'),
    Ventes_moyennes=('Ventes', 'mean'),
    Quantit√©_totale=('Quantit√©', 'sum'),
    Quantit√©_max=('Quantit√©', 'max')
)
print("Avec noms personnalis√©s:")
print(resultat)
```

### Fonctions personnalis√©es

```python
# D√©finir une fonction personnalis√©e
def etendue(serie):
    """Calcule l'√©tendue (max - min)"""
    return serie.max() - serie.min()

# Appliquer la fonction personnalis√©e
resultat = df.groupby('Ville')['Ventes'].agg(['mean', etendue])
print("Avec fonction personnalis√©e:")
print(resultat)

# Fonction lambda
resultat = df.groupby('Ville')['Ventes'].agg(
    moyenne='mean',
    coefficient_variation=lambda x: x.std() / x.mean()
)
print("\nAvec lambda:")
print(resultat)
```

## Grouper par plusieurs colonnes

### GroupBy hi√©rarchique

```python
df = pd.DataFrame({
    'R√©gion': ['Nord', 'Nord', 'Sud', 'Sud', 'Nord', 'Sud'],
    'Ville': ['Paris', 'Lyon', 'Marseille', 'Toulouse', 'Paris', 'Marseille'],
    'Produit': ['A', 'A', 'A', 'B', 'B', 'B'],
    'Ventes': [100, 150, 90, 120, 110, 130]
})

print("DataFrame original:")
print(df)

# Grouper par R√©gion et Ville
ventes_region_ville = df.groupby(['R√©gion', 'Ville'])['Ventes'].sum()
print("\nVentes par R√©gion et Ville:")
print(ventes_region_ville)

# Avec plusieurs colonnes et agr√©gations
stats = df.groupby(['R√©gion', 'Ville']).agg({
    'Ventes': ['sum', 'mean'],
    'Produit': 'count'
})
print("\nStatistiques d√©taill√©es:")
print(stats)
```

### R√©initialiser l'index

```python
# Le r√©sultat a un MultiIndex, on peut le r√©initialiser
ventes_df = df.groupby(['R√©gion', 'Ville'])['Ventes'].sum().reset_index()
print("Avec index r√©initialis√©:")
print(ventes_df)
```

### Grouper et trier

```python
# Grouper et trier par la valeur agr√©g√©e
ventes_triees = (df.groupby(['R√©gion', 'Ville'])['Ventes']
                   .sum()
                   .sort_values(ascending=False)
                   .reset_index())
print("Tri√© par ventes d√©croissantes:")
print(ventes_triees)
```

## Transform : Appliquer des op√©rations en gardant la forme

La m√©thode `transform()` applique une fonction et retourne un r√©sultat de la m√™me taille que l'entr√©e.

```python
df = pd.DataFrame({
    'Ville': ['Paris', 'Lyon', 'Paris', 'Lyon', 'Paris'],
    'Ventes': [100, 150, 120, 180, 90]
})

print("DataFrame original:")
print(df)

# Calculer la moyenne par ville et l'ajouter comme colonne
df['Moyenne_ville'] = df.groupby('Ville')['Ventes'].transform('mean')
print("\nAvec moyenne par ville:")
print(df)

# Normaliser par rapport √† la moyenne du groupe
df['Ventes_normalis√©es'] = (df['Ventes'] - df['Moyenne_ville']) / df.groupby('Ville')['Ventes'].transform('std')
print("\nAvec ventes normalis√©es:")
print(df)

# Fonction personnalis√©e avec transform
df['Rang_dans_ville'] = df.groupby('Ville')['Ventes'].transform(lambda x: x.rank(method='dense'))
print("\nAvec rang dans chaque ville:")
print(df)
```

## Filter : Filtrer des groupes entiers

La m√©thode `filter()` permet de conserver ou supprimer des groupes entiers selon une condition.

```python
df = pd.DataFrame({
    'Ville': ['Paris', 'Lyon', 'Paris', 'Lyon', 'Marseille', 'Paris'],
    'Ventes': [100, 150, 120, 180, 50, 90]
})

print("DataFrame original:")
print(df)

# Garder seulement les villes avec des ventes totales > 200
villes_importantes = df.groupby('Ville').filter(lambda x: x['Ventes'].sum() > 200)
print("\nVilles avec ventes totales > 200:")
print(villes_importantes)

# Garder les villes avec au moins 3 entr√©es
villes_frequentes = df.groupby('Ville').filter(lambda x: len(x) >= 3)
print("\nVilles avec au moins 3 entr√©es:")
print(villes_frequentes)
```

## Apply : Maximum de flexibilit√©

La m√©thode `apply()` est la plus flexible et permet d'appliquer n'importe quelle fonction √† chaque groupe.

```python
df = pd.DataFrame({
    'Cat√©gorie': ['A', 'A', 'B', 'B', 'A', 'B'],
    'Valeur': [10, 15, 20, 25, 12, 22]
})

print("DataFrame original:")
print(df)

# Fonction simple
def calcul_range(groupe):
    return groupe['Valeur'].max() - groupe['Valeur'].min()

etendue = df.groupby('Cat√©gorie').apply(calcul_range)
print("\n√âtendue par cat√©gorie:")
print(etendue)

# Retourner un DataFrame
def stats_groupe(groupe):
    return pd.Series({
        'min': groupe['Valeur'].min(),
        'max': groupe['Valeur'].max(),
        'etendue': groupe['Valeur'].max() - groupe['Valeur'].min()
    })

stats = df.groupby('Cat√©gorie').apply(stats_groupe)
print("\nStatistiques par cat√©gorie:")
print(stats)

# Op√©ration plus complexe : normalisation par groupe
def normaliser(groupe):
    groupe['Valeur_norm'] = (groupe['Valeur'] - groupe['Valeur'].mean()) / groupe['Valeur'].std()
    return groupe

df_norm = df.groupby('Cat√©gorie').apply(normaliser)
print("\nAvec valeurs normalis√©es par groupe:")
print(df_norm)
```

## Op√©rations sur les index

### Grouper par niveau d'index

```python
# DataFrame avec MultiIndex
arrays = [
    ['A', 'A', 'B', 'B'],
    ['X', 'Y', 'X', 'Y']
]
index = pd.MultiIndex.from_arrays(arrays, names=['Groupe', 'Sous-groupe'])
df = pd.DataFrame({'Valeur': [10, 20, 30, 40]}, index=index)

print("DataFrame avec MultiIndex:")
print(df)

# Grouper par niveau d'index
par_groupe = df.groupby(level='Groupe')['Valeur'].sum()
print("\nSomme par Groupe:")
print(par_groupe)

par_sous_groupe = df.groupby(level='Sous-groupe')['Valeur'].sum()
print("\nSomme par Sous-groupe:")
print(par_sous_groupe)
```

### Grouper par fonction sur l'index

```python
df = pd.DataFrame({
    'Date': pd.date_range('2024-01-01', periods=10, freq='D'),
    'Ventes': [100, 120, 90, 110, 130, 95, 105, 115, 125, 100]
})
df.set_index('Date', inplace=True)

print("DataFrame avec dates:")
print(df)

# Grouper par mois
par_mois = df.groupby(df.index.month)['Ventes'].sum()
print("\nVentes par mois:")
print(par_mois)

# Grouper par jour de la semaine
par_jour = df.groupby(df.index.dayofweek)['Ventes'].mean()
print("\nVentes moyennes par jour de la semaine:")
print(par_jour)
```

## Agr√©gations avec valeurs manquantes

```python
df = pd.DataFrame({
    'Cat√©gorie': ['A', 'A', 'B', 'B', 'A', 'B'],
    'Valeur': [10, np.nan, 20, 25, 15, np.nan]
})

print("DataFrame avec NaN:")
print(df)

# Les agr√©gations ignorent les NaN par d√©faut
print("\nMoyenne par cat√©gorie (ignore NaN):")
print(df.groupby('Cat√©gorie')['Valeur'].mean())

# Compter en excluant les NaN
print("\nCompte (sans NaN):")
print(df.groupby('Cat√©gorie')['Valeur'].count())

# Compter tous les √©l√©ments (avec NaN)
print("\nCompte total (avec NaN):")
print(df.groupby('Cat√©gorie')['Valeur'].size())

# Somme (NaN devient 0)
print("\nSomme par cat√©gorie:")
print(df.groupby('Cat√©gorie')['Valeur'].sum())
```

## Exemples pratiques complets

### Exemple 1 : Analyse de ventes par r√©gion

```python
# Donn√©es de ventes
ventes = pd.DataFrame({
    'Date': pd.date_range('2024-01-01', periods=12, freq='MS'),
    'R√©gion': ['Nord', 'Sud', 'Est', 'Ouest'] * 3,
    'Produit': ['A', 'A', 'B', 'B'] * 3,
    'Ventes': [1000, 1200, 800, 900, 1100, 1300, 850, 950, 1050, 1250, 900, 1000],
    'Quantit√©': [50, 60, 40, 45, 55, 65, 42, 48, 52, 62, 45, 50]
})

print("Donn√©es de ventes:")
print(ventes.head())

# 1. Ventes totales par r√©gion
print("\n--- Ventes totales par r√©gion ---")
ventes_region = ventes.groupby('R√©gion')['Ventes'].sum().sort_values(ascending=False)
print(ventes_region)

# 2. Statistiques par produit
print("\n--- Statistiques par produit ---")
stats_produit = ventes.groupby('Produit').agg({
    'Ventes': ['sum', 'mean', 'min', 'max'],
    'Quantit√©': ['sum', 'mean']
})
print(stats_produit)

# 3. Performance par r√©gion et produit
print("\n--- Performance par r√©gion et produit ---")
perf = ventes.groupby(['R√©gion', 'Produit']).agg(
    Ventes_totales=('Ventes', 'sum'),
    Ventes_moyennes=('Ventes', 'mean'),
    Quantit√©_totale=('Quantit√©', 'sum')
).reset_index()
print(perf)

# 4. Trouver la meilleure r√©gion pour chaque produit
print("\n--- Meilleure r√©gion par produit ---")
meilleures = (ventes.groupby(['Produit', 'R√©gion'])['Ventes']
              .sum()
              .reset_index()
              .sort_values('Ventes', ascending=False)
              .groupby('Produit')
              .first())
print(meilleures)

# 5. Pourcentage des ventes par r√©gion
print("\n--- Pourcentage des ventes par r√©gion ---")
total_ventes = ventes['Ventes'].sum()
pct_region = (ventes.groupby('R√©gion')['Ventes'].sum() / total_ventes * 100).round(2)
print(pct_region)
```

### Exemple 2 : Analyse de notes d'√©tudiants

```python
# Donn√©es d'√©tudiants
notes = pd.DataFrame({
    '√âtudiant': ['Alice', 'Bob', 'Charlie', 'Alice', 'Bob', 'Charlie'] * 2,
    'Mati√®re': ['Math', 'Math', 'Math', 'Physique', 'Physique', 'Physique'] * 2,
    'Trimestre': ['T1', 'T1', 'T1', 'T1', 'T1', 'T1', 'T2', 'T2', 'T2', 'T2', 'T2', 'T2'],
    'Note': [15, 12, 18, 13, 14, 16, 16, 13, 17, 14, 15, 18]
})

print("Donn√©es de notes:")
print(notes)

# 1. Moyenne par √©tudiant
print("\n--- Moyenne g√©n√©rale par √©tudiant ---")
moy_etudiant = notes.groupby('√âtudiant')['Note'].mean().round(2)
print(moy_etudiant)

# 2. Moyenne par mati√®re
print("\n--- Moyenne par mati√®re ---")
moy_matiere = notes.groupby('Mati√®re')['Note'].mean().round(2)
print(moy_matiere)

# 3. √âvolution par √©tudiant et mati√®re
print("\n--- √âvolution par √©tudiant et mati√®re ---")
evolution = notes.groupby(['√âtudiant', 'Mati√®re', 'Trimestre'])['Note'].mean().unstack()
print(evolution)

# 4. Meilleure et moins bonne note par √©tudiant
print("\n--- Min et Max par √©tudiant ---")
minmax = notes.groupby('√âtudiant')['Note'].agg(['min', 'max', 'mean'])
print(minmax)

# 5. Classement des √©tudiants
print("\n--- Classement des √©tudiants ---")
classement = (notes.groupby('√âtudiant')['Note']
              .mean()
              .sort_values(ascending=False)
              .reset_index()
              .rename(columns={'Note': 'Moyenne'}))
classement['Rang'] = range(1, len(classement) + 1)
print(classement)

# 6. Progression entre T1 et T2
print("\n--- Progression T1 -> T2 ---")
notes_pivot = notes.pivot_table(values='Note',
                                 index='√âtudiant',
                                 columns='Trimestre',
                                 aggfunc='mean')
notes_pivot['Progression'] = notes_pivot['T2'] - notes_pivot['T1']
print(notes_pivot)
```

### Exemple 3 : Analyse de donn√©es e-commerce

```python
# Donn√©es de commandes
commandes = pd.DataFrame({
    'Date': pd.date_range('2024-01-01', periods=20, freq='D'),
    'Client': ['Client_A', 'Client_B', 'Client_A', 'Client_C'] * 5,
    'Cat√©gorie': ['√âlectronique', 'V√™tements', '√âlectronique', 'Livres'] * 5,
    'Montant': np.random.randint(50, 500, 20),
    'Produits': np.random.randint(1, 10, 20)
})

print("Donn√©es de commandes:")
print(commandes.head(10))

# 1. Chiffre d'affaires par client
print("\n--- CA par client ---")
ca_client = (commandes.groupby('Client')['Montant']
             .sum()
             .sort_values(ascending=False)
             .reset_index()
             .rename(columns={'Montant': 'CA_total'}))
print(ca_client)

# 2. Panier moyen par cat√©gorie
print("\n--- Panier moyen par cat√©gorie ---")
panier_moy = commandes.groupby('Cat√©gorie').agg(
    Montant_moyen=('Montant', 'mean'),
    Montant_total=('Montant', 'sum'),
    Nb_commandes=('Montant', 'count')
).round(2)
print(panier_moy)

# 3. Fr√©quence d'achat par client
print("\n--- Fr√©quence d'achat ---")
freq = commandes.groupby('Client').agg(
    Nb_commandes=('Date', 'count'),
    Premi√®re_commande=('Date', 'min'),
    Derni√®re_commande=('Date', 'max')
)
freq['Jours_entre_commandes'] = (freq['Derni√®re_commande'] - freq['Premi√®re_commande']).dt.days / freq['Nb_commandes']
print(freq)

# 4. Top 3 des cat√©gories par client
print("\n--- Top cat√©gories par client ---")
top_cat = (commandes.groupby(['Client', 'Cat√©gorie'])['Montant']
           .sum()
           .reset_index()
           .sort_values(['Client', 'Montant'], ascending=[True, False])
           .groupby('Client')
           .head(2))
print(top_cat)

# 5. Analyse temporelle : CA par semaine
commandes['Semaine'] = commandes['Date'].dt.isocalendar().week
print("\n--- CA par semaine ---")
ca_semaine = commandes.groupby('Semaine')['Montant'].sum()
print(ca_semaine)
```

### Exemple 4 : Analyse RH - Salaires par d√©partement

```python
# Donn√©es d'employ√©s
employes = pd.DataFrame({
    'Nom': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Frank', 'Grace', 'Henry'],
    'D√©partement': ['IT', 'Ventes', 'IT', 'RH', 'Ventes', 'IT', 'RH', 'Ventes'],
    'Poste': ['Dev', 'Manager', 'Dev', 'Recrut', 'Vendeur', 'Manager', 'Recrut', 'Vendeur'],
    'Salaire': [45000, 55000, 48000, 40000, 38000, 65000, 42000, 40000],
    'Anciennet√©': [2, 5, 3, 4, 1, 8, 6, 2]
})

print("Donn√©es employ√©s:")
print(employes)

# 1. Salaire moyen par d√©partement
print("\n--- Salaire moyen par d√©partement ---")
sal_dept = employes.groupby('D√©partement')['Salaire'].mean().round(2)
print(sal_dept)

# 2. Statistiques compl√®tes par d√©partement
print("\n--- Statistiques par d√©partement ---")
stats_dept = employes.groupby('D√©partement').agg({
    'Salaire': ['mean', 'min', 'max', 'std'],
    'Anciennet√©': 'mean',
    'Nom': 'count'
}).round(2)
stats_dept.columns = ['Sal_moyen', 'Sal_min', 'Sal_max', 'Sal_std', 'Anc_moy', 'Effectif']
print(stats_dept)

# 3. Masse salariale par d√©partement
print("\n--- Masse salariale ---")
masse_sal = employes.groupby('D√©partement').agg(
    Masse_salariale=('Salaire', 'sum'),
    Effectif=('Nom', 'count')
)
masse_sal['Salaire_moyen'] = masse_sal['Masse_salariale'] / masse_sal['Effectif']
print(masse_sal)

# 4. Salaire moyen par poste et d√©partement
print("\n--- Salaire par poste et d√©partement ---")
sal_poste = employes.groupby(['D√©partement', 'Poste'])['Salaire'].mean().unstack()
print(sal_poste)

# 5. Identifier les salaires au-dessus de la moyenne du d√©partement
print("\n--- Employ√©s au-dessus de la moyenne ---")
employes['Salaire_moy_dept'] = employes.groupby('D√©partement')['Salaire'].transform('mean')
employes['Au_dessus_moy'] = employes['Salaire'] > employes['Salaire_moy_dept']
print(employes[['Nom', 'D√©partement', 'Salaire', 'Salaire_moy_dept', 'Au_dessus_moy']])

# 6. Top 2 salaires par d√©partement
print("\n--- Top 2 salaires par d√©partement ---")
top_salaires = (employes.sort_values('Salaire', ascending=False)
                .groupby('D√©partement')
                .head(2)[['Nom', 'D√©partement', 'Salaire']])
print(top_salaires)
```

### Exemple 5 : Analyse de donn√©es de capteurs IoT

```python
# Donn√©es de capteurs
np.random.seed(42)
capteurs = pd.DataFrame({
    'DateTime': pd.date_range('2024-01-01', periods=48, freq='H'),
    'Capteur': ['Temp_1', 'Temp_2', 'Temp_1', 'Temp_2'] * 12,
    'Temp√©rature': np.random.normal(20, 3, 48),
    'Humidit√©': np.random.normal(60, 10, 48)
})

print("Donn√©es capteurs:")
print(capteurs.head(10))

# 1. Moyenne quotidienne par capteur
capteurs['Date'] = capteurs['DateTime'].dt.date
print("\n--- Moyenne quotidienne ---")
moy_jour = capteurs.groupby(['Date', 'Capteur']).agg({
    'Temp√©rature': 'mean',
    'Humidit√©': 'mean'
}).round(2)
print(moy_jour.head(10))

# 2. Min, Max, Moyenne par capteur
print("\n--- Statistiques par capteur ---")
stats = capteurs.groupby('Capteur').agg({
    'Temp√©rature': ['min', 'max', 'mean', 'std'],
    'Humidit√©': ['min', 'max', 'mean', 'std']
}).round(2)
print(stats)

# 3. Heures avec temp√©rature > 22¬∞C
print("\n--- Heures chaudes par capteur ---")
capteurs['Chaud'] = capteurs['Temp√©rature'] > 22
heures_chaudes = capteurs.groupby('Capteur')['Chaud'].sum()
print(heures_chaudes)

# 4. Plage horaire : moyenne par heure de la journ√©e
capteurs['Heure'] = capteurs['DateTime'].dt.hour
print("\n--- Temp√©rature moyenne par heure ---")
temp_heure = capteurs.groupby('Heure')['Temp√©rature'].mean().round(2)
print(temp_heure)

# 5. √âcart entre les deux capteurs
print("\n--- √âcart entre capteurs ---")
temp_pivot = capteurs.pivot_table(values='Temp√©rature',
                                   index='DateTime',
                                   columns='Capteur')
temp_pivot['√âcart'] = abs(temp_pivot['Temp_1'] - temp_pivot['Temp_2'])
print("\n√âcart moyen:", temp_pivot['√âcart'].mean().round(2))
print("√âcart maximum:", temp_pivot['√âcart'].max().round(2))
```

## Techniques avanc√©es

### Grouper avec des bins (intervalles)

```python
# Cr√©er des groupes d'√¢ge
df = pd.DataFrame({
    'Nom': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Frank'],
    '√Çge': [23, 35, 28, 45, 31, 52],
    'Salaire': [35000, 45000, 40000, 55000, 42000, 60000]
})

print("DataFrame original:")
print(df)

# Cr√©er des tranches d'√¢ge
df['Tranche_√¢ge'] = pd.cut(df['√Çge'], bins=[20, 30, 40, 60], labels=['20-30', '30-40', '40-60'])
print("\nAvec tranches d'√¢ge:")
print(df)

# Analyser par tranche
print("\nSalaire moyen par tranche d'√¢ge:")
print(df.groupby('Tranche_√¢ge')['Salaire'].mean())
```

### Grouper avec des conditions personnalis√©es

```python
# Grouper selon une condition
df = pd.DataFrame({
    'Produit': ['A', 'B', 'C', 'D', 'E'],
    'Prix': [10, 25, 15, 45, 20]
})

# Cr√©er des groupes personnalis√©s
def categoriser_prix(prix):
    if prix < 20:
        return '√âconomique'
    elif prix < 40:
        return 'Standard'
    else:
        return 'Premium'

df['Cat√©gorie'] = df['Prix'].apply(categoriser_prix)
print("Produits cat√©goris√©s:")
print(df)

print("\nNombre de produits par cat√©gorie:")
print(df.groupby('Cat√©gorie').size())
```

### Rolling et groupby

```python
# Moyenne mobile par groupe
df = pd.DataFrame({
    'Date': pd.date_range('2024-01-01', periods=10),
    'Ville': ['Paris', 'Lyon'] * 5,
    'Ventes': [100, 120, 110, 130, 105, 125, 115, 135, 120, 140]
})

print("DataFrame original:")
print(df)

# Moyenne mobile sur 3 jours par ville
df = df.sort_values(['Ville', 'Date'])
df['Moyenne_mobile'] = df.groupby('Ville')['Ventes'].transform(lambda x: x.rolling(3, min_periods=1).mean())
print("\nAvec moyenne mobile:")
print(df)
```

## Bonnes pratiques

### 1. Choisir la bonne m√©thode d'agr√©gation

```python
# ‚úÖ Bon : utiliser agg() pour plusieurs agr√©gations
stats = df.groupby('Cat√©gorie').agg({
    'Ventes': ['sum', 'mean'],
    'Quantit√©': 'sum'
})

# ‚ùå Moins efficace : cha√Æner plusieurs op√©rations
# somme = df.groupby('Cat√©gorie')['Ventes'].sum()
# moyenne = df.groupby('Cat√©gorie')['Ventes'].mean()
```

### 2. Utiliser reset_index() pour plus de clart√©

```python
# ‚úÖ Bon : r√©sultat sous forme de DataFrame
resultat = df.groupby('Ville')['Ventes'].sum().reset_index()
# Plus facile √† manipuler et √† visualiser

# ‚ùå Moins pratique : Series avec index
# resultat = df.groupby('Ville')['Ventes'].sum()
```

### 3. Nommer les colonnes agr√©g√©es

```python
# ‚úÖ Bon : noms explicites
resultat = df.groupby('Ville').agg(
    Total_ventes=('Ventes', 'sum'),
    Ventes_moyennes=('Ventes', 'mean'),
    Nb_transactions=('Ventes', 'count')
)

# ‚ùå Moins clair
# resultat = df.groupby('Ville')['Ventes'].agg(['sum', 'mean', 'count'])
```

### 4. V√©rifier les groupes avant l'agr√©gation

```python
# ‚úÖ Bon : v√©rifier les groupes
print("Nombre de groupes:", df.groupby('Cat√©gorie').ngroups)
print("Groupes:", list(df.groupby('Cat√©gorie').groups.keys()))
# Puis agr√©ger
resultat = df.groupby('Cat√©gorie')['Ventes'].sum()
```

### 5. G√©rer les valeurs manquantes

```python
# ‚úÖ Bon : g√©rer explicitement les NaN
# Option 1 : Nettoyer avant groupby
df_clean = df.dropna(subset=['Cat√©gorie', 'Ventes'])
resultat = df_clean.groupby('Cat√©gorie')['Ventes'].sum()

# Option 2 : Inclure les NaN comme groupe
resultat = df.groupby('Cat√©gorie', dropna=False)['Ventes'].sum()
```

## R√©sum√©

GroupBy et les agr√©gations sont des outils essentiels pour l'analyse de donn√©es avec Pandas. Voici les points cl√©s √† retenir :

**Concept de base :**
- Split-Apply-Combine : diviser, appliquer, combiner
- `groupby()` cr√©e des groupes selon un ou plusieurs crit√®res

**Fonctions d'agr√©gation principales :**
- `sum()`, `mean()`, `count()`, `min()`, `max()`
- `std()`, `var()`, `median()`
- `agg()` pour agr√©gations multiples et personnalis√©es

**M√©thodes avanc√©es :**
- `transform()` : op√©rations en gardant la forme originale
- `filter()` : filtrer des groupes entiers
- `apply()` : maximum de flexibilit√©

**Groupements :**
- Simple : une colonne
- Multiple : plusieurs colonnes (MultiIndex)
- Par index, par fonction, par bins

**Bonnes pratiques :**
1. Utiliser `agg()` pour plusieurs agr√©gations
2. Nommer les colonnes agr√©g√©es pour plus de clart√©
3. Utiliser `reset_index()` pour des DataFrames plus maniables
4. V√©rifier les groupes avant d'agr√©ger
5. G√©rer explicitement les valeurs manquantes

GroupBy est particuli√®rement utile pour :
- Analyses comparatives entre groupes
- Calculs de statistiques par cat√©gorie
- Transformations par groupe
- Filtrage de groupes selon des crit√®res

La ma√Ætrise de GroupBy vous permettra d'effectuer des analyses de donn√©es complexes de mani√®re efficace et √©l√©gante.

‚è≠Ô∏è [Visualisation avec Matplotlib et Plotly](/13-introduction-data-science/03-visualisation-matplotlib-plotly.md)
