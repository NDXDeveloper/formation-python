üîù Retour au [Sommaire](/SOMMAIRE.md)

# 12.4 Optimisation des performances

## Introduction

> "Premature optimization is the root of all evil" - Donald Knuth

Cette c√©l√®bre citation signifie qu'il ne faut pas **optimiser trop t√¥t**. Avant d'optimiser, vous devez :
1. **Faire fonctionner** votre code correctement
2. **Mesurer** o√π sont les vrais probl√®mes de performance
3. **Optimiser** seulement les parties critiques

L'optimisation pr√©matur√©e peut rendre votre code complexe et difficile √† maintenir pour des gains marginaux. Mais une fois que votre code fonctionne et que vous avez identifi√© les goulots d'√©tranglement, il est temps d'optimiser !

### Pourquoi optimiser ?

‚úÖ **Am√©liorer l'exp√©rience utilisateur** : application plus rapide et r√©active

‚úÖ **R√©duire les co√ªts** : moins de ressources serveur n√©cessaires

‚úÖ **Scalabilit√©** : g√©rer plus d'utilisateurs avec les m√™mes ressources

‚úÖ **√ânergie** : moins de consommation √©lectrique

### Les trois dimensions de l'optimisation

1. **Temps d'ex√©cution** : combien de temps prend votre code ?
2. **M√©moire** : combien de RAM votre code utilise ?
3. **Lisibilit√©** : votre code reste-t-il compr√©hensible ?

Il faut souvent trouver un **√©quilibre** entre ces trois aspects.

---

## R√®gle d'or : Mesurez avant d'optimiser !

Avant toute optimisation, vous devez **mesurer** pour savoir :
- Quelle partie du code est lente ?
- Combien de temps prend chaque fonction ?
- O√π sont les vrais goulots d'√©tranglement ?

### Mesure simple avec `time`

```python
import time

def fonction_lente():
    time.sleep(1)  # Simule un traitement long
    return "Termin√©"

# Mesurer le temps d'ex√©cution
start = time.time()
resultat = fonction_lente()
end = time.time()

print(f"Temps d'ex√©cution : {end - start:.4f} secondes")
# Temps d'ex√©cution : 1.0001 secondes
```

### Mesure avec `timeit` (plus pr√©cis)

```python
import timeit

# Mesurer une ligne de code
temps = timeit.timeit('"-".join(str(n) for n in range(100))', number=10000)
print(f"Temps moyen : {temps/10000:.6f} secondes")

# Comparer deux approches
def approche1():
    result = []
    for i in range(1000):
        result.append(i * 2)
    return result

def approche2():
    return [i * 2 for i in range(1000)]

# Comparer
temps1 = timeit.timeit(approche1, number=10000)
temps2 = timeit.timeit(approche2, number=10000)

print(f"Approche 1 : {temps1:.4f}s")
print(f"Approche 2 : {temps2:.4f}s")
print(f"Approche 2 est {temps1/temps2:.2f}x plus rapide")
```

### D√©corateur pour mesurer facilement

```python
import time
from functools import wraps

def measure_time(func):
    """D√©corateur qui mesure le temps d'ex√©cution"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        start = time.time()
        result = func(*args, **kwargs)
        end = time.time()
        print(f"{func.__name__} a pris {end - start:.4f} secondes")
        return result
    return wrapper

@measure_time
def traiter_donnees(n):
    return sum(range(n))

traiter_donnees(1000000)
# traiter_donnees a pris 0.0234 secondes
```

---

## Profiling : Trouver les goulots d'√©tranglement

Le **profiling** permet d'analyser en d√©tail o√π votre programme passe son temps.

### Profiling avec `cProfile`

```python
import cProfile
import pstats
from io import StringIO

def fonction_complexe():
    result = []
    for i in range(10000):
        for j in range(100):
            result.append(i * j)
    return result

def autre_fonction():
    return sum(range(1000000))

def main():
    fonction_complexe()
    autre_fonction()

# Profiler le code
profiler = cProfile.Profile()
profiler.enable()

main()

profiler.disable()

# Afficher les r√©sultats
stats = pstats.Stats(profiler)
stats.sort_stats('cumulative')
stats.print_stats(10)  # Top 10 des fonctions les plus lentes
```

### Profiling ligne par ligne avec `line_profiler`

Installation :
```bash
pip install line_profiler
```

Utilisation :
```python
# Ajouter le d√©corateur @profile (fourni par line_profiler)
@profile
def ma_fonction():
    total = 0
    for i in range(1000):
        total += i ** 2
    return total

# Ex√©cuter avec :
# kernprof -l -v script.py
```

### Memory Profiler

Pour analyser l'utilisation de la m√©moire :

```bash
pip install memory_profiler
```

```python
from memory_profiler import profile

@profile
def fonction_gourmande():
    # Cr√©er une grande liste
    big_list = [i for i in range(1000000)]
    return sum(big_list)

# Ex√©cuter avec :
# python -m memory_profiler script.py
```

---

## Optimisation des structures de donn√©es

Le choix de la **bonne structure de donn√©es** peut transformer un code O(n¬≤) en O(n) !

### Listes vs Sets vs Dictionnaires

```python
import time

# Donn√©es de test
data = list(range(10000))

# ‚ùå Recherche dans une liste : O(n)
def recherche_liste(item):
    return item in data

# ‚úÖ Recherche dans un set : O(1)
data_set = set(data)
def recherche_set(item):
    return item in data_set

# Comparer
start = time.time()
for i in range(1000):
    recherche_liste(9999)
print(f"Liste : {time.time() - start:.4f}s")

start = time.time()
for i in range(1000):
    recherche_set(9999)
print(f"Set : {time.time() - start:.4f}s")
# Set est BEAUCOUP plus rapide !
```

### Quand utiliser quelle structure ?

| Structure | Recherche | Insertion | Suppression | Usage |
|-----------|-----------|-----------|-------------|-------|
| **Liste** | O(n) | O(1)* | O(n) | Ordre important, acc√®s par index |
| **Set** | O(1) | O(1) | O(1) | Valeurs uniques, tests d'appartenance |
| **Dict** | O(1) | O(1) | O(1) | Paires cl√©-valeur, lookups rapides |
| **Tuple** | O(n) | - | - | Donn√©es immuables |
| **deque** | O(n) | O(1) | O(1) | Files, piles (ajout/retrait aux extr√©mit√©s) |

*O(1) uniquement pour append, O(n) pour insertion au milieu

### Exemple pratique : Optimisation avec un dictionnaire

```python
# ‚ùå Lent : recherche O(n) √† chaque fois
users = [
    {"id": 1, "name": "Alice"},
    {"id": 2, "name": "Bob"},
    {"id": 3, "name": "Charlie"}
]

def get_user_slow(user_id):
    for user in users:
        if user["id"] == user_id:
            return user
    return None

# ‚úÖ Rapide : recherche O(1)
users_dict = {
    1: {"id": 1, "name": "Alice"},
    2: {"id": 2, "name": "Bob"},
    3: {"id": 3, "name": "Charlie"}
}

def get_user_fast(user_id):
    return users_dict.get(user_id)

# Encore mieux : cr√©er l'index une seule fois
users_indexed = {user["id"]: user for user in users}
```

### Collections sp√©cialis√©es

```python
from collections import defaultdict, Counter, deque

# defaultdict : √©vite les v√©rifications d'existence
# ‚ùå Avec dict normal
word_count = {}
for word in ["apple", "banana", "apple"]:
    if word in word_count:
        word_count[word] += 1
    else:
        word_count[word] = 1

# ‚úÖ Avec defaultdict
from collections import defaultdict
word_count = defaultdict(int)
for word in ["apple", "banana", "apple"]:
    word_count[word] += 1  # Plus simple !

# Counter : encore plus simple pour compter
from collections import Counter
word_count = Counter(["apple", "banana", "apple"])
print(word_count)  # Counter({'apple': 2, 'banana': 1})

# deque : optimis√© pour ajout/retrait aux extr√©mit√©s
from collections import deque

# ‚ùå Liste : insert(0) est lent O(n)
liste = []
liste.insert(0, "√©l√©ment")  # Doit d√©placer tous les √©l√©ments !

# ‚úÖ deque : appendleft est rapide O(1)
file = deque()
file.appendleft("√©l√©ment")  # Rapide !
```

---

## Optimisation du code Python

### List comprehensions vs boucles for

Les list comprehensions sont g√©n√©ralement **plus rapides** que les boucles for √©quivalentes.

```python
import timeit

# ‚ùå Boucle for classique
def avec_boucle():
    result = []
    for i in range(1000):
        result.append(i * 2)
    return result

# ‚úÖ List comprehension
def avec_comprehension():
    return [i * 2 for i in range(1000)]

# ‚úÖ Encore plus rapide : map
def avec_map():
    return list(map(lambda x: x * 2, range(1000)))

print(f"Boucle : {timeit.timeit(avec_boucle, number=10000):.4f}s")
print(f"Comprehension : {timeit.timeit(avec_comprehension, number=10000):.4f}s")
print(f"Map : {timeit.timeit(avec_map, number=10000):.4f}s")
```

### √âviter les recherches r√©p√©t√©es

```python
# ‚ùå Lent : recherche dans la liste √† chaque it√©ration
def slow_function(items):
    result = []
    for item in items:
        if item in result:  # O(n) √† chaque fois !
            continue
        result.append(item)
    return result

# ‚úÖ Rapide : utiliser un set
def fast_function(items):
    seen = set()
    result = []
    for item in items:
        if item in seen:  # O(1) !
            continue
        seen.add(item)
        result.append(item)
    return result

# ‚úÖ Encore plus simple
def fastest_function(items):
    seen = set()
    result = []
    for item in items:
        if item not in seen:
            seen.add(item)
            result.append(item)
    return result

# ‚úÖ‚úÖ Le plus pythonique (pr√©serve l'ordre depuis Python 3.7+)
def pythonic_function(items):
    return list(dict.fromkeys(items))
```

### Utiliser les fonctions built-in

Les fonctions Python built-in (√©crites en C) sont **tr√®s rapides**.

```python
# ‚ùå Lent
def sum_manually(numbers):
    total = 0
    for num in numbers:
        total += num
    return total

# ‚úÖ Rapide : utiliser sum()
def sum_builtin(numbers):
    return sum(numbers)

# Autres fonctions built-in rapides
numbers = [1, 2, 3, 4, 5]

max_value = max(numbers)      # Plus rapide qu'une boucle
min_value = min(numbers)      # Plus rapide qu'une boucle
all_true = all(numbers)       # Plus rapide qu'une boucle
any_true = any(numbers)       # Plus rapide qu'une boucle
```

### √âviter les concat√©nations de strings dans les boucles

```python
# ‚ùå Tr√®s lent : les strings sont immuables en Python !
def concat_slow(words):
    result = ""
    for word in words:
        result += word + " "  # Cr√©e une nouvelle string √† chaque fois !
    return result

# ‚úÖ Rapide : utiliser join()
def concat_fast(words):
    return " ".join(words)

# Test
words = ["mot"] * 10000
import timeit
print(f"Lent : {timeit.timeit(lambda: concat_slow(words), number=10):.4f}s")
print(f"Rapide : {timeit.timeit(lambda: concat_fast(words), number=10):.4f}s")
```

### Variables locales vs globales

L'acc√®s aux variables locales est plus rapide que l'acc√®s aux variables globales.

```python
# ‚ùå Plus lent : acc√®s global
CONSTANT = 100

def with_global():
    total = 0
    for i in range(1000000):
        total += CONSTANT  # Acc√®s global
    return total

# ‚úÖ Plus rapide : variable locale
def with_local():
    constant = 100  # Variable locale
    total = 0
    for i in range(1000000):
        total += constant  # Acc√®s local
    return total

# Encore mieux : passer en param√®tre
def with_parameter(constant=100):
    total = 0
    for i in range(1000000):
        total += constant
    return total
```

---

## G√©n√©rateurs : √âconomiser de la m√©moire

Les **g√©n√©rateurs** permettent de traiter des donn√©es **√† la vol√©e** sans tout charger en m√©moire.

### Liste vs G√©n√©rateur

```python
import sys

# ‚ùå Liste : tout en m√©moire
def get_numbers_list(n):
    return [i for i in range(n)]

# ‚úÖ G√©n√©rateur : un √©l√©ment √† la fois
def get_numbers_generator(n):
    for i in range(n):
        yield i

# Comparaison m√©moire
liste = get_numbers_list(1000000)
print(f"Taille liste : {sys.getsizeof(liste) / 1024 / 1024:.2f} MB")

generateur = get_numbers_generator(1000000)
print(f"Taille g√©n√©rateur : {sys.getsizeof(generateur)} bytes")

# Le g√©n√©rateur est BEAUCOUP plus petit !
```

### Exemple pratique : Traiter un gros fichier

```python
# ‚ùå Lent et gourmand en m√©moire
def process_file_slow(filename):
    with open(filename, 'r') as f:
        lines = f.readlines()  # Charge TOUT en m√©moire !

    for line in lines:
        process_line(line)

# ‚úÖ Rapide et efficace
def process_file_fast(filename):
    with open(filename, 'r') as f:
        for line in f:  # Lit ligne par ligne
            process_line(line)

def process_line(line):
    # Traitement de la ligne
    pass
```

### Generator expressions

```python
# Liste : tout calcul√© imm√©diatement
squares_list = [x**2 for x in range(1000000)]

# G√©n√©rateur : calcul√© √† la demande
squares_gen = (x**2 for x in range(1000000))

# Utilisation
total = sum(squares_gen)  # Calcule √† la vol√©e, √©conomise la m√©moire
```

---

## Caching : M√©moriser les r√©sultats

Le **caching** (mise en cache) √©vite de recalculer les m√™mes choses plusieurs fois.

### Cache simple avec dictionnaire

```python
# Fonction co√ªteuse √† calculer
def fibonacci_slow(n):
    if n <= 1:
        return n
    return fibonacci_slow(n-1) + fibonacci_slow(n-2)

# Avec cache
fibonacci_cache = {}

def fibonacci_fast(n):
    if n in fibonacci_cache:
        return fibonacci_cache[n]

    if n <= 1:
        result = n
    else:
        result = fibonacci_fast(n-1) + fibonacci_fast(n-2)

    fibonacci_cache[n] = result
    return result

# Test
import time
start = time.time()
print(fibonacci_slow(35))  # Tr√®s lent !
print(f"Sans cache : {time.time() - start:.4f}s")

start = time.time()
print(fibonacci_fast(35))  # Tr√®s rapide !
print(f"Avec cache : {time.time() - start:.4f}s")
```

### Cache avec `@lru_cache`

Python fournit un d√©corateur pratique pour le caching :

```python
from functools import lru_cache

@lru_cache(maxsize=128)  # Cache les 128 derniers appels
def fibonacci(n):
    if n <= 1:
        return n
    return fibonacci(n-1) + fibonacci(n-2)

# Utilisation
print(fibonacci(100))  # Instantan√© gr√¢ce au cache !

# Voir les statistiques du cache
print(fibonacci.cache_info())
# CacheInfo(hits=98, misses=101, maxsize=128, currsize=101)

# Vider le cache si n√©cessaire
fibonacci.cache_clear()
```

### Cache avec `@cache` (Python 3.9+)

```python
from functools import cache

@cache  # Cache illimit√© (√©quivalent √† lru_cache(maxsize=None))
def calcul_lourd(a, b, c):
    # Calcul complexe
    return a ** b + c ** 2

# Premi√®re fois : calcule
result1 = calcul_lourd(2, 10, 5)

# Deuxi√®me fois : retourne la valeur en cache (instantan√©)
result2 = calcul_lourd(2, 10, 5)
```

### Exemple pratique : Cache pour API

```python
import time
from functools import lru_cache
from datetime import datetime, timedelta

@lru_cache(maxsize=100)
def fetch_user_data(user_id):
    """Simule un appel API lent"""
    print(f"Appel API pour user {user_id}...")
    time.sleep(2)  # Simule latence r√©seau
    return {"id": user_id, "name": f"User {user_id}"}

# Premier appel : lent (2 secondes)
start = time.time()
data = fetch_user_data(123)
print(f"Premier appel : {time.time() - start:.2f}s")

# Deuxi√®me appel : instantan√© (cache)
start = time.time()
data = fetch_user_data(123)
print(f"Deuxi√®me appel : {time.time() - start:.2f}s")
```

---

## Optimisation des boucles

### D√©placer le code invariant hors de la boucle

```python
import math

# ‚ùå Lent : calcule sqrt(2) √† chaque it√©ration
def slow_loop():
    result = []
    for i in range(1000):
        result.append(i * math.sqrt(2))  # sqrt(2) recalcul√© 1000 fois !
    return result

# ‚úÖ Rapide : calcule sqrt(2) une seule fois
def fast_loop():
    sqrt_2 = math.sqrt(2)  # Calcul√© une seule fois
    result = []
    for i in range(1000):
        result.append(i * sqrt_2)
    return result

# ‚úÖ‚úÖ Encore mieux : list comprehension
def fastest_loop():
    sqrt_2 = math.sqrt(2)
    return [i * sqrt_2 for i in range(1000)]
```

### √âviter les appels de m√©thodes dans les conditions

```python
# ‚ùå Lent : appelle len() √† chaque it√©ration
def slow_iteration(items):
    i = 0
    while i < len(items):  # len() appel√© √† chaque fois !
        print(items[i])
        i += 1

# ‚úÖ Rapide : calcule len() une fois
def fast_iteration(items):
    length = len(items)
    i = 0
    while i < length:
        print(items[i])
        i += 1

# ‚úÖ‚úÖ Pythonique : utiliser for
def pythonic_iteration(items):
    for item in items:
        print(item)
```

### Utiliser enumerate au lieu des indices

```python
items = ["a", "b", "c", "d"]

# ‚ùå Lent
for i in range(len(items)):
    print(f"{i}: {items[i]}")

# ‚úÖ Rapide et lisible
for i, item in enumerate(items):
    print(f"{i}: {item}")
```

---

## NumPy pour les calculs num√©riques

Pour les **calculs num√©riques intensifs**, NumPy est **10-100x plus rapide** que le Python pur !

```python
import numpy as np
import time

# ‚ùå Lent : boucle Python pure
def python_sum(n):
    numbers = list(range(n))
    total = 0
    for num in numbers:
        total += num ** 2
    return total

# ‚úÖ Rapide : NumPy vectoris√©
def numpy_sum(n):
    numbers = np.arange(n)
    return np.sum(numbers ** 2)

# Comparaison
n = 1000000

start = time.time()
result1 = python_sum(n)
print(f"Python pur : {time.time() - start:.4f}s")

start = time.time()
result2 = numpy_sum(n)
print(f"NumPy : {time.time() - start:.4f}s")
# NumPy est BEAUCOUP plus rapide !
```

### Op√©rations vectoris√©es

```python
import numpy as np

# ‚ùå Lent : boucle
data = [1, 2, 3, 4, 5]
result = []
for x in data:
    result.append(x * 2 + 10)

# ‚úÖ Rapide : vectoris√©
data_np = np.array([1, 2, 3, 4, 5])
result_np = data_np * 2 + 10  # Appliqu√© √† tous les √©l√©ments en une fois !

print(result_np)  # [12 14 16 18 20]
```

---

## Multiprocessing et Threading

Python a le **GIL** (Global Interpreter Lock) qui emp√™che le vrai parall√©lisme avec des threads pour le code Python pur. Solutions :

### Threading pour les op√©rations I/O

Bon pour : requ√™tes r√©seau, lecture/√©criture fichiers

```python
import time
import threading

def download_file(url):
    """Simule un t√©l√©chargement"""
    print(f"D√©but t√©l√©chargement : {url}")
    time.sleep(2)  # Simule latence r√©seau
    print(f"Fin t√©l√©chargement : {url}")

urls = [f"http://example.com/file{i}" for i in range(5)]

# ‚ùå S√©quentiel : 10 secondes
start = time.time()
for url in urls:
    download_file(url)
print(f"S√©quentiel : {time.time() - start:.2f}s")

# ‚úÖ Avec threads : ~2 secondes
start = time.time()
threads = []
for url in urls:
    thread = threading.Thread(target=download_file, args=(url,))
    thread.start()
    threads.append(thread)

for thread in threads:
    thread.join()

print(f"Avec threads : {time.time() - start:.2f}s")
```

### Multiprocessing pour le CPU intensif

Bon pour : calculs math√©matiques, traitement d'images, machine learning

```python
from multiprocessing import Pool
import time

def calcul_lourd(n):
    """Calcul CPU-intensif"""
    result = 0
    for i in range(n):
        result += i ** 2
    return result

numbers = [10000000, 10000000, 10000000, 10000000]

# ‚ùå S√©quentiel
start = time.time()
results = [calcul_lourd(n) for n in numbers]
print(f"S√©quentiel : {time.time() - start:.2f}s")

# ‚úÖ Parall√®le
start = time.time()
with Pool(processes=4) as pool:
    results = pool.map(calcul_lourd, numbers)
print(f"Parall√®le : {time.time() - start:.2f}s")
```

### Quand utiliser quoi ?

| Type de t√¢che | Solution | Raison |
|---------------|----------|--------|
| **I/O (r√©seau, fichiers)** | `threading` | GIL n'est pas un probl√®me |
| **CPU intensif** | `multiprocessing` | Contourne le GIL |
| **Async I/O** | `asyncio` | Plus efficace que threads |
| **Simple** | S√©quentiel | Pas de complexit√© ajout√©e |

---

## Asyncio pour l'I/O asynchrone

`asyncio` est encore plus efficace que `threading` pour l'I/O car il utilise moins de ressources.

```python
import asyncio
import time

async def fetch_data(url):
    """Simule une requ√™te asynchrone"""
    print(f"D√©but fetch : {url}")
    await asyncio.sleep(2)  # I/O non-bloquant
    print(f"Fin fetch : {url}")
    return f"Donn√©es de {url}"

async def main():
    urls = [f"http://api.example.com/{i}" for i in range(5)]

    # Lancer toutes les requ√™tes en parall√®le
    tasks = [fetch_data(url) for url in urls]
    results = await asyncio.gather(*tasks)

    return results

# Ex√©cution
start = time.time()
results = asyncio.run(main())
print(f"Temps total : {time.time() - start:.2f}s")
# ~2 secondes au lieu de 10 !
```

---

## Optimisation de la m√©moire

### Utiliser __slots__ pour les classes

```python
import sys

# ‚ùå Classe normale : utilise un dict interne
class PersonNormal:
    def __init__(self, name, age):
        self.name = name
        self.age = age

# ‚úÖ Avec __slots__ : plus compact
class PersonSlots:
    __slots__ = ['name', 'age']

    def __init__(self, name, age):
        self.name = name
        self.age = age

# Comparaison m√©moire
p1 = PersonNormal("Alice", 30)
p2 = PersonSlots("Alice", 30)

print(f"Sans slots : {sys.getsizeof(p1.__dict__)} bytes")
print(f"Avec slots : {sys.getsizeof(p2)} bytes")

# Avec des milliers d'instances, l'√©conomie est significative !
```

### G√©n√©rateurs au lieu de listes

```python
# ‚ùå Liste : tout en m√©moire
def get_squares_list(n):
    return [i**2 for i in range(n)]

# ‚úÖ G√©n√©rateur : √©conomise la m√©moire
def get_squares_gen(n):
    return (i**2 for i in range(n))

# Pour de grandes valeurs de n, la diff√©rence est √©norme
```

### Lib√©rer la m√©moire explicitement

```python
import gc

# Traiter de grandes donn√©es
def process_large_data():
    large_list = [i for i in range(10000000)]
    result = sum(large_list)

    # Lib√©rer la m√©moire
    del large_list
    gc.collect()  # Force le garbage collector

    return result
```

---

## Outils d'optimisation Python

### PyPy : Interpr√©teur Python plus rapide

**PyPy** est un interpr√©teur Python alternatif avec un compilateur JIT (Just-In-Time) qui peut √™tre **2-10x plus rapide** que CPython.

Installation :
```bash
# Linux/Mac
pip install pypy

# Ou t√©l√©charger depuis pypy.org
```

Utilisation :
```bash
pypy mon_script.py  # Au lieu de python mon_script.py
```

**Quand utiliser PyPy ?**
- Calculs intensifs
- Boucles longues
- Code pur Python (pas compatible avec tous les packages C)

### Cython : Compiler Python en C

**Cython** permet de compiler du code Python en C pour des gains de performance √©normes.

```python
# fichier: calcul.pyx
def calcul_lourd(int n):
    cdef int i
    cdef long result = 0

    for i in range(n):
        result += i * i

    return result
```

```bash
# Compiler
cython calcul.pyx
gcc -shared -pthread -fPIC -fwrapv -O2 -Wall -fno-strict-aliasing \
    -I/usr/include/python3.9 -o calcul.so calcul.c
```

### Numba : JIT compilation

**Numba** compile les fonctions Python en code machine √† la vol√©e.

```python
from numba import jit
import numpy as np

# Sans Numba
def function_slow(x):
    result = 0
    for i in range(len(x)):
        result += x[i] ** 2
    return result

# Avec Numba
@jit(nopython=True)
def function_fast(x):
    result = 0
    for i in range(len(x)):
        result += x[i] ** 2
    return result

x = np.arange(1000000)

# function_fast sera beaucoup plus rapide apr√®s le premier appel
```

---

## Bonnes pratiques d'optimisation

### 1. Profiler d'abord, optimiser ensuite

```python
# Ne faites JAMAIS d'optimisation sans mesurer
import cProfile

cProfile.run('ma_fonction()')
# Identifiez les vrais goulots d'√©tranglement
```

### 2. Commencer par les algorithmes

Un meilleur algorithme bat toujours les micro-optimisations.

```python
# ‚ùå O(n¬≤) : lent m√™me optimis√©
def find_duplicates_slow(items):
    duplicates = []
    for i, item in enumerate(items):
        for j, other in enumerate(items):
            if i != j and item == other and item not in duplicates:
                duplicates.append(item)
    return duplicates

# ‚úÖ O(n) : rapide
def find_duplicates_fast(items):
    seen = set()
    duplicates = set()
    for item in items:
        if item in seen:
            duplicates.add(item)
        seen.add(item)
    return list(duplicates)
```

### 3. Utiliser les bonnes structures de donn√©es

```python
# Choisir la structure adapt√©e au cas d'usage
if need_fast_lookup:
    use_dict_or_set()
elif need_ordered:
    use_list()
elif need_unique_ordered:
    use_dict()  # Python 3.7+
elif need_fast_queue:
    use_deque()
```

### 4. Lazy evaluation

Ne calculez que ce dont vous avez besoin.

```python
# ‚ùå Calcule tout
def get_all_results():
    return [expensive_operation(i) for i in range(1000)]

# ‚úÖ Calcule √† la demande
def get_results_lazy():
    return (expensive_operation(i) for i in range(1000))

# Utilisation
for result in get_results_lazy():
    if condition_met(result):
        break  # Arr√™te t√¥t, n'a pas tout calcul√© !
```

### 5. √âviter les optimisations pr√©matur√©es

```python
# ‚ùå Trop optimis√©, illisible
def complex_optimized(data):
    return reduce(lambda x, y: x + y[0] * y[1],
                  zip(data, range(len(data))), 0)

# ‚úÖ Simple et lisible (optimiser seulement si n√©cessaire)
def simple_readable(data):
    total = 0
    for i, value in enumerate(data):
        total += value * i
    return total

# Si vraiment n√©cessaire apr√®s profiling :
def optimized_if_needed(data):
    return sum(value * i for i, value in enumerate(data))
```

---

## Checklist d'optimisation

Suivez cette checklist dans l'ordre :

### ‚úÖ √âtape 1 : Fonctionnalit√©
- [ ] Mon code fonctionne correctement ?
- [ ] J'ai des tests ?
- [ ] Le code est lisible ?

### ‚úÖ √âtape 2 : Mesure
- [ ] J'ai identifi√© que j'ai un probl√®me de performance ?
- [ ] J'ai profil√© mon code (cProfile, line_profiler) ?
- [ ] Je connais les fonctions/lignes lentes ?

### ‚úÖ √âtape 3 : Algorithme
- [ ] Mon algorithme est-il optimal (complexit√©) ?
- [ ] Puis-je utiliser une meilleure structure de donn√©es ?
- [ ] Y a-t-il des calculs redondants ?

### ‚úÖ √âtape 4 : Python
- [ ] J'utilise les built-ins quand possible ?
- [ ] J'utilise des comprehensions ?
- [ ] J'√©vite les concat√©nations de strings ?
- [ ] Mes variables locales au lieu de globales ?

### ‚úÖ √âtape 5 : Caching
- [ ] Puis-je mettre en cache des r√©sultats ?
- [ ] @lru_cache serait-il utile ?

### ‚úÖ √âtape 6 : M√©moire
- [ ] Puis-je utiliser des g√©n√©rateurs ?
- [ ] __slots__ pour les classes ?
- [ ] Lib√©ration explicite de m√©moire ?

### ‚úÖ √âtape 7 : Parall√©lisme
- [ ] Threading pour I/O ?
- [ ] Multiprocessing pour CPU ?
- [ ] Asyncio pour I/O async ?

### ‚úÖ √âtape 8 : Outils avanc√©s
- [ ] NumPy pour calculs num√©riques ?
- [ ] PyPy comme interpr√©teur ?
- [ ] Cython/Numba pour code critique ?

---

## Exemples d'optimisations r√©elles

### Exemple 1 : Traitement de fichier CSV

```python
import csv
import pandas as pd

# ‚ùå Lent : charge tout en m√©moire
def process_csv_slow(filename):
    with open(filename, 'r') as f:
        data = list(csv.reader(f))

    total = 0
    for row in data:
        total += int(row[2])  # Colonne prix
    return total

# ‚úÖ Rapide : traitement ligne par ligne
def process_csv_fast(filename):
    total = 0
    with open(filename, 'r') as f:
        reader = csv.reader(f)
        next(reader)  # Skip header
        for row in reader:
            total += int(row[2])
    return total

# ‚úÖ‚úÖ Le plus rapide : pandas (optimis√© en C)
def process_csv_pandas(filename):
    df = pd.read_csv(filename)
    return df.iloc[:, 2].sum()
```

### Exemple 2 : Recherche dans des donn√©es

```python
# Donn√©es : liste de transactions
transactions = [
    {"id": 1, "user_id": 101, "amount": 50},
    {"id": 2, "user_id": 102, "amount": 75},
    # ... des milliers ...
]

# ‚ùå O(n) √† chaque recherche
def get_user_total_slow(user_id):
    total = 0
    for transaction in transactions:
        if transaction["user_id"] == user_id:
            total += transaction["amount"]
    return total

# ‚úÖ O(1) apr√®s indexation
from collections import defaultdict

# Cr√©er un index une seule fois
user_totals = defaultdict(int)
for transaction in transactions:
    user_totals[transaction["user_id"]] += transaction["amount"]

def get_user_total_fast(user_id):
    return user_totals[user_id]
```

### Exemple 3 : G√©n√©ration de rapport

```python
# ‚ùå Lent et gourmand
def generate_report_slow(data):
    report = ""
    for item in data:
        report += f"Nom: {item['name']}\n"  # Concat√©nation lente !
        report += f"Valeur: {item['value']}\n"
        report += "-" * 40 + "\n"
    return report

# ‚úÖ Rapide
def generate_report_fast(data):
    lines = []
    for item in data:
        lines.append(f"Nom: {item['name']}")
        lines.append(f"Valeur: {item['value']}")
        lines.append("-" * 40)
    return "\n".join(lines)

# ‚úÖ‚úÖ Plus pythonique
def generate_report_pythonic(data):
    return "\n".join(
        f"Nom: {item['name']}\nValeur: {item['value']}\n{'-'*40}"
        for item in data
    )
```

---

## R√©sum√©

L'optimisation en Python suit cette philosophie :

1. **Faites fonctionner** votre code d'abord ‚úÖ
2. **Mesurez** les performances üìä
3. **Optimisez** les vrais goulots üöÄ
4. **Mesurez** √† nouveau pour v√©rifier üìà

### R√®gles d'or

‚úÖ **Profiler avant d'optimiser** : ne devinez pas, mesurez !

‚úÖ **Algorithme d'abord** : O(n) bat toujours O(n¬≤) optimis√©

‚úÖ **Bonnes structures de donn√©es** : dict/set pour lookup, list pour ordre

‚úÖ **Built-ins et stdlib** : ils sont √©crits en C et tr√®s rapides

‚úÖ **√âviter les pi√®ges** : concat√©nation de strings, recherches r√©p√©t√©es

‚úÖ **G√©n√©rateurs** : √©conomisez la m√©moire pour les grands volumes

‚úÖ **Caching** : @lru_cache pour √©viter les recalculs

‚úÖ **Parall√©lisme** : threading (I/O), multiprocessing (CPU), asyncio (async I/O)

‚úÖ **Outils sp√©cialis√©s** : NumPy (calcul), Pandas (donn√©es), PyPy (interpr√©teur)

### N'oubliez pas

> "Premature optimization is the root of all evil" - Donald Knuth

**Mais** :

> "Premature pessimization is equally evil" - Herb Sutter

√âcrivez du code propre et lisible. Optimisez seulement quand n√©cessaire, l√† o√π √ßa compte vraiment ! üéØ

‚è≠Ô∏è [D√©ploiement et distribution](/12-projets-et-bonnes-pratiques/05-deploiement-et-distribution.md)
